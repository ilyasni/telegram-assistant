#!/usr/bin/env python3
"""
–ü–æ–ª–Ω—ã–π E2E —Ç–µ—Å—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞ –∞–ª—å–±–æ–º–æ–≤ —Å vision –∞–Ω–∞–ª–∏–∑–æ–º –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ S3
Context7: –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ—Ç –∞–ª—å–±–æ–º–∞ –¥–æ S3

–¢–µ—Å—Ç–∏—Ä—É–µ—Ç:
1. –°–æ–∑–¥–∞–Ω–∏–µ –∞–ª—å–±–æ–º–∞ –≤ –ë–î
2. –≠–º–∏—Å—Å–∏—é albums.parsed —Å–æ–±—ã—Ç–∏—è
3. –°–æ–∑–¥–∞–Ω–∏–µ vision.analyzed —Å–æ–±—ã—Ç–∏–π –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∞–ª—å–±–æ–º–∞
4. –û–±—Ä–∞–±–æ—Ç–∫—É album_assembler_task
5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ vision summary –≤ S3
6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ enrichment –≤ –ë–î
"""

import asyncio
import os
import sys
import json
from datetime import datetime, timezone
from uuid import uuid4

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
project_root = '/opt/telegram-assistant'
sys.path.insert(0, project_root)
sys.path.insert(0, '/app')

import structlog
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker
from sqlalchemy import text
import redis.asyncio as redis

logger = structlog.get_logger()

async def get_existing_album():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∞–ª—å–±–æ–º–∞ –∏–∑ –ë–î."""
    print("\nüì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∞–ª—å–±–æ–º–∞...")
    
    db_url = os.getenv("DATABASE_URL", "postgresql+asyncpg://postgres:postgres@supabase-db:5432/postgres")
    if db_url.startswith("postgresql://") or db_url.startswith("postgres://"):
        db_url = db_url.replace("postgresql://", "postgresql+asyncpg://", 1).replace("postgres://", "postgresql+asyncpg://", 1)
    
    engine = create_async_engine(db_url)
    async_session = async_sessionmaker(engine, expire_on_commit=False)
    
    try:
        async with async_session() as session:
            # –ü–æ–ª—É—á–∞–µ–º –∞–ª—å–±–æ–º —Å –ø–æ—Å—Ç–∞–º–∏
            result = await session.execute(text("""
                SELECT 
                    mg.id as album_id,
                    mg.grouped_id,
                    mg.channel_id,
                    mg.user_id,
                    mg.items_count,
                    mg.caption_text,
                    array_agg(mgi.post_id ORDER BY mgi.position) as post_ids,
                    mg.user_id as tenant_id
                FROM media_groups mg
                JOIN media_group_items mgi ON mg.id = mgi.group_id
                GROUP BY mg.id, mg.grouped_id, mg.channel_id, mg.user_id, mg.items_count, mg.caption_text
                LIMIT 1
            """))
            
            row = result.fetchone()
            if row:
                album_id = row[0]
                grouped_id = row[1]
                channel_id = str(row[2])
                user_id = str(row[3])
                items_count = row[4]
                caption_text = row[5]
                post_ids = row[6] if row[6] else []
                tenant_id = str(row[7]) if row[7] else "default"
                
                print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω –∞–ª—å–±–æ–º:")
                print(f"     Album ID: {album_id}")
                print(f"     Grouped ID: {grouped_id}")
                print(f"     Items: {items_count}")
                print(f"     Posts: {len(post_ids)}")
                print(f"     Channel ID: {channel_id}")
                print(f"     User ID: {user_id}")
                print(f"     Tenant ID: {tenant_id}")
                
                return {
                    'album_id': album_id,
                    'grouped_id': grouped_id,
                    'channel_id': channel_id,
                    'user_id': user_id,
                    'tenant_id': tenant_id,
                    'items_count': items_count,
                    'caption_text': caption_text,
                    'post_ids': post_ids
                }
            else:
                print("  ‚ö†Ô∏è  –ê–ª—å–±–æ–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return None
                
    finally:
        await engine.dispose()


async def emit_albums_parsed_event(album_data: dict):
    """–≠–º–∏—Å—Å–∏—è —Å–æ–±—ã—Ç–∏—è albums.parsed –¥–ª—è –∞–ª—å–±–æ–º–∞."""
    print("\nüì§ –≠–º–∏—Å—Å–∏—è —Å–æ–±—ã—Ç–∏—è albums.parsed...")
    
    redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://redis:6379/0"), decode_responses=False)
    
    try:
        event = {
            "schema_version": "v1",
            "trace_id": f"test_album_vision_{int(datetime.now(timezone.utc).timestamp())}",
            "occurred_at": datetime.now(timezone.utc).isoformat(),
            "idempotency_key": f"{str(album_data['tenant_id'])}:{str(album_data['channel_id'])}:{album_data['grouped_id']}",
            "user_id": str(album_data['user_id']),
            "channel_id": str(album_data['channel_id']),
            "album_id": album_data['album_id'],
            "grouped_id": album_data['grouped_id'],
            "tenant_id": str(album_data['tenant_id']),
            "album_kind": "photo",
            "items_count": album_data['items_count'],
            "caption_text": album_data['caption_text'],
            "post_ids": json.dumps([str(p) for p in album_data['post_ids']]),  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º UUID –≤ —Å—Ç—Ä–æ–∫–∏
            "content_hash": f"test_hash_{album_data['grouped_id']}"
        }
        
        # Context7: –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º —Å–æ–±—ã—Ç–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–∂–∏–¥–∞–µ—Ç album_assembler_task
        # Task –æ–∂–∏–¥–∞–µ—Ç JSON –≤ –ø–æ–ª–µ 'data'
        event_json = json.dumps(event, ensure_ascii=False, default=str)
        event_payload = {
            'event': 'albums.parsed',
            'data': event_json,
            'idempotency_key': event['idempotency_key']
        }
        
        stream_key = "stream:albums:parsed"
        message_id = await redis_client.xadd(stream_key, event_payload, maxlen=10000)
        
        print(f"  ‚úÖ –°–æ–±—ã—Ç–∏–µ albums.parsed —ç–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–æ: {message_id}")
        return message_id
        
    finally:
        await redis_client.aclose()


async def save_vision_results_to_db(album_data: dict):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ vision —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–î –¥–ª—è –ø–æ—Å—Ç–æ–≤ –∞–ª—å–±–æ–º–∞."""
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ vision —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–î...")
    
    db_url = os.getenv("DATABASE_URL", "postgresql+asyncpg://postgres:postgres@supabase-db:5432/postgres")
    if db_url.startswith("postgresql://") or db_url.startswith("postgres://"):
        db_url = db_url.replace("postgresql://", "postgresql+asyncpg://", 1).replace("postgres://", "postgresql+asyncpg://", 1)
    
    engine = create_async_engine(db_url)
    async_session = async_sessionmaker(engine, expire_on_commit=False)
    
    try:
        async with async_session() as session:
            for idx, post_id in enumerate(album_data['post_ids'][:3]):  # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 3 –ø–æ—Å—Ç–∞
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º vision —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ post_enrichment
                # Context7: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –ø–æ–ª–µ–º data (JSONB) + legacy –ø–æ–ª—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                vision_data = {
                    "model": "GigaChat-Pro",
                    "provider": "gigachat",
                    "analyzed_at": datetime.now(timezone.utc).isoformat(),
                    "classification": "photo",
                    "description": f"Test vision description for album post {idx + 1}",
                    "is_meme": idx == 0,
                    "labels": [f"tag_{idx}_a", f"tag_{idx}_b"],
                    "ocr": {
                        "text": f"Test OCR text {idx + 1}" if idx == 0 else None,
                        "engine": "gigachat"
                    } if idx == 0 else None
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (data), –∏ –≤ legacy –ø–æ–ª—è—Ö –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                await session.execute(text("""
                    INSERT INTO post_enrichment (
                        post_id,
                        kind,
                        provider,
                        data,
                        status,
                        vision_description,
                        vision_classification,
                        vision_is_meme,
                        vision_ocr_text,
                        vision_analyzed_at
                    ) VALUES (
                        :post_id,
                        'vision',
                        'gigachat',
                        CAST(:data AS jsonb),
                        'ok',
                        :description,
                        CAST(:classification AS jsonb),
                        :is_meme,
                        :ocr_text,
                        NOW()
                    )
                    ON CONFLICT (post_id, kind)
                    DO UPDATE SET
                        data = EXCLUDED.data,
                        status = EXCLUDED.status,
                        vision_description = EXCLUDED.vision_description,
                        vision_classification = EXCLUDED.vision_classification,
                        vision_is_meme = EXCLUDED.vision_is_meme,
                        vision_ocr_text = EXCLUDED.vision_ocr_text,
                        vision_analyzed_at = EXCLUDED.vision_analyzed_at
                """), {
                    "post_id": post_id,
                    "data": json.dumps(vision_data),
                    "description": vision_data["description"],
                    "classification": json.dumps({"tags": vision_data["labels"], "confidence": 0.95}),
                    "is_meme": vision_data["is_meme"],
                    "ocr_text": vision_data["ocr"]["text"] if vision_data["ocr"] else None
                })
                
                print(f"  ‚úÖ Vision —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è post {str(post_id)[:8]}...")
            
            await session.commit()
            
    finally:
        await engine.dispose()


async def emit_vision_analyzed_events(album_data: dict):
    """–≠–º–∏—Å—Å–∏—è vision.analyzed —Å–æ–±—ã—Ç–∏–π –¥–ª—è –ø–æ—Å—Ç–æ–≤ –∞–ª—å–±–æ–º–∞."""
    print("\nüì§ –≠–º–∏—Å—Å–∏—è vision.analyzed —Å–æ–±—ã—Ç–∏–π –¥–ª—è –ø–æ—Å—Ç–æ–≤ –∞–ª—å–±–æ–º–∞...")
    
    redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://redis:6379/0"), decode_responses=False)
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ö–µ–º—É —Å–æ–±—ã—Ç–∏—è
        try:
            from events.schemas.posts_vision_v1 import VisionAnalyzedEventV1, MediaFile, VisionAnalysisResult
        except ImportError:
            from worker.events.schemas.posts_vision_v1 import VisionAnalyzedEventV1, MediaFile, VisionAnalysisResult
        
        message_ids = []
        
        for idx, post_id in enumerate(album_data['post_ids'][:3]):  # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 3 –ø–æ—Å—Ç–∞
            # –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–µ vision —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            vision_result = VisionAnalysisResult(
                provider="gigachat",
                model="GigaChat-Pro",
                schema_version="1.0",
                classification={
                    "type": "photo",
                    "confidence": 0.95,
                    "tags": [f"tag_{idx}_a", f"tag_{idx}_b"]
                },
                description=f"Test vision description for album post {idx + 1}",
                ocr_text=f"Test OCR text for album post {idx + 1}" if idx == 0 else None,
                is_meme=(idx == 0),
                tokens_used=150,
                file_id="test_file_id",
                analyzed_at=datetime.now(timezone.utc)
            )
            
            post_id_str = str(post_id)
            media_file = MediaFile(
                sha256=f"test_sha256_{post_id_str[:8]}_{idx}",
                s3_key=f"media/test/{post_id_str[:2]}/{post_id_str}.jpg",
                mime_type="image/jpeg",
                size_bytes=1000
            )
            
            analyzed_event = VisionAnalyzedEventV1(
                tenant_id=str(album_data['tenant_id']),
                post_id=post_id_str,
                media=[media_file],
                vision=vision_result.model_dump(),
                analysis_duration_ms=500,
                idempotency_key=f"{str(album_data['tenant_id'])}:{post_id_str}:vision_analyzed",
                trace_id=f"test_vision_{int(datetime.now(timezone.utc).timestamp())}"
            )
            
            event_json = analyzed_event.model_dump_json()
            message_id = await redis_client.xadd(
                "stream:posts:vision:analyzed",
                {
                    "event": "posts.vision.analyzed",
                    "data": event_json,
                    "idempotency_key": analyzed_event.idempotency_key
                }
            )
            
            message_ids.append(message_id)
            print(f"  ‚úÖ Vision.analyzed —ç–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è post {post_id_str[:8]}...: {message_id}")
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–æ–±—ã—Ç–∏—è–º–∏
            await asyncio.sleep(0.2)
        
        print(f"  ‚úÖ –í—Å–µ–≥–æ —ç–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(message_ids)} vision.analyzed —Å–æ–±—ã—Ç–∏–π")
        return message_ids
        
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ —ç–º–∏—Å—Å–∏–∏ vision.analyzed: {e}")
        import traceback
        traceback.print_exc()
        return []
    finally:
        await redis_client.aclose()


async def wait_for_album_assembly(album_id: int, timeout: int = 60):
    """–û–∂–∏–¥–∞–Ω–∏–µ —Å–±–æ—Ä–∫–∏ –∞–ª—å–±–æ–º–∞."""
    print(f"\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ —Å–±–æ—Ä–∫–∏ –∞–ª—å–±–æ–º–∞ {album_id} (timeout: {timeout}s)...")
    
    redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://redis:6379/0"), decode_responses=True)
    
    try:
        start_time = datetime.now(timezone.utc)
        assembled_stream = "stream:album:assembled"
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π
        initial_count = await redis_client.xlen(assembled_stream)
        print(f"  üìä –ù–∞—á–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π album.assembled: {initial_count}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∞–ª—å–±–æ–º–∞ –≤ Redis
        state_key = f"album:state:{album_id}"
        
        while True:
            elapsed = (datetime.now(timezone.utc) - start_time).total_seconds()
            if elapsed > timeout:
                print(f"  ‚ö†Ô∏è  Timeout: –∞–ª—å–±–æ–º –Ω–µ —Å–æ–±—Ä–∞–Ω –∑–∞ {timeout}s")
                break
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∞–ª—å–±–æ–º–∞
            state_json = await redis_client.get(state_key)
            if state_json:
                state = json.loads(state_json)
                items_count = state.get('items_count', 0)
                items_analyzed = len(state.get('items_analyzed', []))
                
                print(f"  üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {items_analyzed}/{items_count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ ({elapsed:.1f}s)")
                
                if items_analyzed >= items_count:
                    print(f"  ‚úÖ –í—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
                    break
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–±—ã—Ç–∏–µ album.assembled
            current_count = await redis_client.xlen(assembled_stream)
            if current_count > initial_count:
                print(f"  ‚úÖ –°–æ–±—ã—Ç–∏–µ album.assembled –ø–æ–ª—É—á–µ–Ω–æ!")
                break
            
            await asyncio.sleep(2)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        final_count = await redis_client.xlen(assembled_stream)
        if final_count > initial_count:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–±—ã—Ç–∏–µ
            messages = await redis_client.xrevrange(assembled_stream, count=1)
            if messages:
                msg_id, fields = messages[0]
                print(f"  ‚úÖ –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–±—ã—Ç–∏–µ album.assembled: {msg_id}")
                return True
        
        return False
        
    finally:
        await redis_client.aclose()


async def check_album_s3_and_db(album_id: int):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–ª—å–±–æ–º–∞ –≤ S3 –∏ –ë–î."""
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–ª—å–±–æ–º–∞ {album_id} –≤ S3 –∏ –ë–î...")
    
    db_url = os.getenv("DATABASE_URL", "postgresql+asyncpg://postgres:postgres@supabase-db:5432/postgres")
    if db_url.startswith("postgresql://") or db_url.startswith("postgres://"):
        db_url = db_url.replace("postgresql://", "postgresql+asyncpg://", 1).replace("postgres://", "postgresql+asyncpg://", 1)
    
    engine = create_async_engine(db_url)
    async_session = async_sessionmaker(engine, expire_on_commit=False)
    
    try:
        async with async_session() as session:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º enrichment –≤ –ë–î
            result = await session.execute(text("""
                SELECT 
                    mg.id,
                    mg.meta->'enrichment'->>'s3_key' as s3_key,
                    mg.meta->'enrichment'->>'vision_summary' IS NOT NULL as has_vision_summary,
                    mg.meta->'enrichment'->>'assembly_completed_at' as assembly_completed_at,
                    mg.meta->'enrichment' as enrichment_json
                FROM media_groups mg
                WHERE mg.id = :album_id
            """), {"album_id": album_id})
            
            row = result.fetchone()
            if row and row[1]:  # s3_key exists
                print(f"  ‚úÖ –ê–ª—å–±–æ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ë–î —Å enrichment:")
                print(f"     S3 Key: {row[1]}")
                print(f"     Vision Summary: {'‚úÖ' if row[2] else '‚ùå'}")
                print(f"     Assembly completed: {row[4] if row[4] else 'N/A'}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º S3
                try:
                    from api.services.s3_storage import S3StorageService
                    
                    s3_config = {
                        'endpoint_url': os.getenv('S3_ENDPOINT_URL', 'https://s3.cloud.ru'),
                        'access_key_id': os.getenv('S3_ACCESS_KEY_ID'),
                        'secret_access_key': os.getenv('S3_SECRET_ACCESS_KEY'),
                        'bucket_name': os.getenv('S3_BUCKET_NAME'),
                        'region': os.getenv('S3_REGION', 'ru-central-1')
                    }
                    
                    if s3_config.get('access_key_id') and s3_config.get('secret_access_key'):
                        s3 = S3StorageService(**s3_config)
                        
                        try:
                            response = s3.s3_client.head_object(
                                Bucket=s3_config['bucket_name'],
                                Key=row[1]
                            )
                            size_bytes = response['ContentLength']
                            print(f"  ‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω –≤ S3: {size_bytes} bytes")
                            
                            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                            response = s3.s3_client.get_object(
                                Bucket=s3_config['bucket_name'],
                                Key=row[1]
                            )
                            content = response['Body'].read()
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∂–∞—Ç–∏–µ
                            if row[1].endswith('.gz'):
                                import gzip
                                content = gzip.decompress(content)
                            
                            data = json.loads(content.decode('utf-8'))
                            print(f"  ‚úÖ –î–∞–Ω–Ω—ã–µ –≤–∞–ª–∏–¥–Ω—ã:")
                            print(f"     Album ID: {data.get('album_id')}")
                            print(f"     Items analyzed: {data.get('items_analyzed')}/{data.get('items_count')}")
                            print(f"     Vision summary: {'‚úÖ' if data.get('vision_summary') else '‚ùå'}")
                            
                            return True
                        except Exception as e:
                            print(f"  ‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ S3: {e}")
                            return False
                    else:
                        print("  ‚ö†Ô∏è  S3 credentials –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
                        return False
                except ImportError:
                    print("  ‚ö†Ô∏è  S3StorageService –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è")
                    return False
            else:
                print(f"  ‚ö†Ô∏è  –ê–ª—å–±–æ–º –Ω–µ –∏–º–µ–µ—Ç enrichment –≤ –ë–î")
                return False
                
    finally:
        await engine.dispose()


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("=" * 80)
    print("üß™ –ü–æ–ª–Ω—ã–π E2E —Ç–µ—Å—Ç: –ê–ª—å–±–æ–º ‚Üí Vision ‚Üí S3")
    print("=" * 80)
    
    # 1. –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞–ª—å–±–æ–º
    album_data = await get_existing_album()
    if not album_data:
        print("\n‚ùå –ê–ª—å–±–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞–π—Ç–µ –∞–ª—å–±–æ–º —Å–Ω–∞—á–∞–ª–∞:")
        print("   docker exec telegram-assistant-worker-1 python3 /opt/telegram-assistant/scripts/create_test_album.py")
        return
    
    # 2. –≠–º–∏—Ç–∏—Ä—É–µ–º albums.parsed —Å–æ–±—ã—Ç–∏–µ
    await emit_albums_parsed_event(album_data)
    
    # 3. –ñ–¥—ë–º –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    print("\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–ª—å–±–æ–º–∞ (3s)...")
    await asyncio.sleep(3)
    
    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º vision —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î (album_assembler_task —á–∏—Ç–∞–µ—Ç –∏–∑ post_enrichment)
    await save_vision_results_to_db(album_data)
    
    # 5. –≠–º–∏—Ç–∏—Ä—É–µ–º vision.analyzed —Å–æ–±—ã—Ç–∏—è
    await emit_vision_analyzed_events(album_data)
    
    # 6. –û–∂–∏–¥–∞–µ–º —Å–±–æ—Ä–∫–∏ –∞–ª—å–±–æ–º–∞
    assembled = await wait_for_album_assembly(album_data['album_id'], timeout=60)
    
    if assembled:
        # 7. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ S3 –∏ –ë–î
        saved = await check_album_s3_and_db(album_data['album_id'])
        
        if saved:
            print("\n" + "=" * 80)
            print("‚úÖ –ü–û–õ–ù–´–ô E2E –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù!")
            print("=" * 80)
            print("\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            print("   ‚úÖ –ê–ª—å–±–æ–º —Å–æ–∑–¥–∞–Ω –≤ –ë–î")
            print("   ‚úÖ –°–æ–±—ã—Ç–∏–µ albums.parsed —ç–º–∏—Ç–∏—Ä–æ–≤–∞–Ω–æ")
            print("   ‚úÖ Vision.analyzed —Å–æ–±—ã—Ç–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
            print("   ‚úÖ –ê–ª—å–±–æ–º —Å–æ–±—Ä–∞–Ω (album.assembled)")
            print("   ‚úÖ Vision summary —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ S3")
            print("   ‚úÖ Enrichment —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ –ë–î")
        else:
            print("\n‚ö†Ô∏è  –ê–ª—å–±–æ–º —Å–æ–±—Ä–∞–Ω, –Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ S3")
    else:
        print("\n‚ö†Ô∏è  –ê–ª—å–±–æ–º –Ω–µ —Å–æ–±—Ä–∞–Ω –∑–∞ –æ—Ç–≤–µ–¥—ë–Ω–Ω–æ–µ –≤—Ä–µ–º—è")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ album_assembler_task:")
        print("   docker logs telegram-assistant-worker-1 | grep -i 'album\|assembler'")


if __name__ == "__main__":
    asyncio.run(main())

