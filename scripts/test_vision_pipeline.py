#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Vision + S3 –ø–∞–π–ø–ª–∞–π–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –ø–æ—Å—Ç–µ
Context7 best practice: trace_id, error handling, –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–≤–æ—Ç
[C7-ID: TEST-VISION-PIPELINE-001]
"""

import sys
import os
import asyncio
import json
from datetime import datetime, timezone
from uuid import UUID
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, str(Path(__file__).parent.parent))

async def test_vision_pipeline(post_id: str = None):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ Vision –ø–∞–π–ø–ª–∞–π–Ω–∞."""
    
    # –ò–º–ø–æ—Ä—Ç—ã
    from worker.event_bus import EventPublisher
    from worker.events.schemas import VisionUploadedEventV1, MediaFile
    from api.services.s3_storage import S3StorageService
    from worker.services.storage_quota import StorageQuotaService
    from config import settings
    import redis.asyncio as redis
    from sqlalchemy import create_engine, text
    import hashlib
    import structlog
    
    logger = structlog.get_logger()
    
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    redis_client = await redis.from_url(settings.redis_url, decode_responses=False)
    event_publisher = EventPublisher(redis_client)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç –∏–∑ –ë–î
    engine = create_engine(settings.database_url)
    with engine.connect() as conn:
        if post_id:
            query = text("""
                SELECT 
                    p.id::text as post_id,
                    p.channel_id::text as channel_id,
                    p.telegram_message_id,
                    p.media_urls,
                    p.content,
                    (SELECT COUNT(*) FROM post_media_map WHERE post_media_map.post_id = p.id) as media_count
                FROM posts p
                WHERE p.id::text = :post_id
            """)
            result = conn.execute(query, {"post_id": post_id})
        else:
            query = text("""
                SELECT 
                    p.id::text as post_id,
                    p.channel_id::text as channel_id,
                    p.telegram_message_id,
                    p.media_urls,
                    p.content,
                    (SELECT COUNT(*) FROM post_media_map WHERE post_media_map.post_id = p.id) as media_count
                FROM posts p
                WHERE p.media_urls IS NOT NULL 
                  AND jsonb_array_length(COALESCE(p.media_urls, '[]'::jsonb)) > 0
                ORDER BY p.created_at DESC
                LIMIT 1
            """)
            result = conn.execute(query)
        
        post = result.fetchone()
        if not post:
            print("‚ùå –ü–æ—Å—Ç —Å –º–µ–¥–∏–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î")
            await redis_client.close()
            return
        
        post_id = post.post_id
        channel_id = post.channel_id
        media_urls = post.media_urls or []
        media_count = post.media_count
    
    print("=" * 70)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï VISION + S3 –ü–ê–ô–ü–õ–ê–ô–ù–ê")
    print("=" * 70)
    print(f"\nüìã –ü–æ—Å—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"  Post ID: {post_id}")
    print(f"  Channel ID: {channel_id}")
    print(f"  Telegram Message ID: {post.telegram_message_id}")
    print(f"  Media URLs: {len(media_urls)} items")
    print(f"  Media Count (DB): {media_count}")
    
    # Trace ID –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    import uuid
    trace_id = f"test_{uuid.uuid4().hex[:16]}"
    tenant_id = os.getenv("S3_DEFAULT_TENANT_ID", "877193ef-be80-4977-aaeb-8009c3d772ee")
    
    print(f"\nüîç Trace ID: {trace_id}")
    print(f"   Tenant ID: {tenant_id}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ S3 –∫–≤–æ—Ç—ã –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
    print(f"\nüìä –ü—Ä–æ–≤–µ—Ä–∫–∞ S3 –∫–≤–æ—Ç...")
    try:
        s3_service = S3StorageService(
            endpoint_url=os.getenv("S3_ENDPOINT_URL", "https://s3.cloud.ru"),
            access_key_id=os.getenv("S3_ACCESS_KEY_ID", ""),
            secret_access_key=os.getenv("S3_SECRET_ACCESS_KEY", ""),
            bucket_name=os.getenv("S3_BUCKET_NAME", "test-467940"),
            region=os.getenv("S3_REGION", "ru-central-1")
        )
        
        quota_service = StorageQuotaService(s3_service)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–≤–æ—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –º–µ–¥–∏–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ 1 MB)
        quota_check = await quota_service.check_quota_before_upload(
            tenant_id=tenant_id,
            size_bytes=1024 * 1024,  # 1 MB
            content_type="media"
        )
        
        if not quota_check.allowed:
            print(f"‚ö†Ô∏è  –ö–≤–æ—Ç–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∞: {quota_check.reason}")
            print(f"   –¢–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {quota_check.current_usage_gb:.2f} GB")
            print(f"   –õ–∏–º–∏—Ç: {quota_check.tenant_limit_gb:.2f} GB")
            await redis_client.close()
            return
        
        print(f"‚úÖ –ö–≤–æ—Ç–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ ({quota_check.current_usage_gb:.2f} GB / {quota_check.tenant_limit_gb:.2f} GB)")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–≤–æ—Ç—É: {e}")
        print("   –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–≤–æ—Ç—ã...")
    
    # –î–ª—è —Ç–µ—Å—Ç–∞ —Å–æ–∑–¥–∞—ë–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–µ –º–µ–¥–∏–∞ —Å–æ–±—ã—Ç–∏–µ
    # –í —Ä–µ–∞–ª—å–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏ –º–µ–¥–∏–∞ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ S3 —á–µ—Ä–µ–∑ MediaProcessor
    print(f"\nüì§ –°–æ–∑–¥–∞–Ω–∏–µ VisionUploadedEventV1...")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π SHA256 (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –±—É–¥–µ—Ç –∏–∑ Telegram –º–µ–¥–∏–∞)
    test_sha256 = hashlib.sha256(f"test_media_{post_id}".encode()).hexdigest()
    
    media_file = MediaFile(
        sha256=test_sha256,
        s3_key=f"media/{tenant_id}/{test_sha256[:2]}/{test_sha256}.jpg",
        mime_type="image/jpeg",
        size_bytes=512000,  # 500 KB
        telegram_file_id="test_telegram_file_id_12345"
    )
    
    event = VisionUploadedEventV1(
        schema_version="v1",
        trace_id=trace_id,
        idempotency_key=f"{tenant_id}:{post_id}:{media_file.sha256}",
        tenant_id=tenant_id,
        post_id=post_id,
        channel_id=channel_id,
        media_files=[media_file],
        uploaded_at=datetime.now(timezone.utc)
    )
    
    print(f"   Media SHA256: {media_file.sha256}")
    print(f"   S3 Key: {media_file.s3_key}")
    print(f"   Size: {media_file.size_bytes / 1024:.1f} KB")
    
    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è
    print(f"\nüöÄ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏—è –≤ stream:posts:vision:uploaded...")
    
    try:
        message_id = await event_publisher.publish_event("posts.vision.uploaded", event)
        print(f"‚úÖ –°–æ–±—ã—Ç–∏–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ")
        print(f"   Message ID: {message_id}")
        print(f"   Stream: stream:posts:vision:uploaded")
        
        print(f"\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Vision worker (30 —Å–µ–∫—É–Ω–¥)...")
        await asyncio.sleep(30)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–î...")
        with engine.connect() as conn:
            result = conn.execute(text("""
                SELECT 
                    pe.vision_analyzed_at,
                    pe.vision_provider,
                    pe.vision_model,
                    pe.vision_is_meme,
                    pe.vision_classification,
                    pe.vision_tokens_used,
                    pe.s3_vision_keys,
                    pe.s3_media_keys
                FROM post_enrichment pe
                WHERE pe.post_id::text = :post_id
            """), {"post_id": post_id})
            
            enrichment = result.fetchone()
            
            if enrichment and enrichment.vision_analyzed_at:
                print(f"‚úÖ Vision –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω!")
                print(f"   Analyzed At: {enrichment.vision_analyzed_at}")
                print(f"   Provider: {enrichment.vision_provider}")
                print(f"   Model: {enrichment.vision_model}")
                print(f"   Is Meme: {enrichment.vision_is_meme}")
                print(f"   Tokens Used: {enrichment.vision_tokens_used}")
                print(f"   S3 Vision Keys: {enrichment.s3_vision_keys}")
                print(f"   S3 Media Keys: {enrichment.s3_media_keys}")
                
                if enrichment.vision_classification:
                    print(f"   Classification: {enrichment.vision_classification}")
            else:
                print(f"‚ö†Ô∏è  Vision –∞–Ω–∞–ª–∏–∑ –µ—â—ë –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")
                print(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ worker –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ API
        print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ Vision API endpoint...")
        import httpx
        async with httpx.AsyncClient(timeout=10.0) as client:
            try:
                response = await client.get(
                    f"http://api:8000/api/v1/vision/posts/{post_id}",
                    headers={"X-Trace-ID": trace_id}
                )
                if response.status_code == 200:
                    data = response.json()
                    print(f"‚úÖ API endpoint —Ä–∞–±–æ—Ç–∞–µ—Ç")
                    print(f"   Provider: {data.get('provider')}")
                    print(f"   Is Meme: {data.get('is_meme')}")
                    print(f"   Media Count: {data.get('media_count')}")
                elif response.status_code == 404:
                    print(f"‚ö†Ô∏è  Vision –∞–Ω–∞–ª–∏–∑ –µ—â—ë –Ω–µ –≥–æ—Ç–æ–≤ (404)")
                else:
                    print(f"‚ö†Ô∏è  API –æ—Ç–≤–µ—Ç–∏–ª: {response.status_code}")
            except Exception as e:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å API: {e}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å–æ–±—ã—Ç–∏—è: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await redis_client.close()
        engine.dispose()
    
    print(f"\n" + "=" * 70)
    print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 70)
    print(f"\nüìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print(f"  1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ worker: docker compose logs worker | grep vision")
    print(f"  2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Prometheus metrics: curl http://localhost:9090/metrics | grep vision")
    print(f"  3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ S3 bucket usage: curl http://localhost:8000/api/v1/storage/quota")
    print(f"  4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Vision API: curl http://localhost:8000/api/v1/vision/posts/{post_id}")


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Test Vision pipeline")
    parser.add_argument("--post-id", type=str, help="Post ID to test (optional)")
    args = parser.parse_args()
    
    asyncio.run(test_vision_pipeline(post_id=args.post_id))

