#!/usr/bin/env python3
"""
Context7: –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Vision + S3 Pipeline –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/test_vision_pipeline.py --check-status
    python scripts/test_vision_pipeline.py --trigger-vision --post-id <uuid>
    python scripts/test_vision_pipeline.py --full-test
"""

import asyncio
import os
import sys
import argparse
import json
from datetime import datetime
from typing import Optional, List, Dict, Any
from uuid import UUID

# Context7: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π –¥–ª—è cross-service –∏–º–ø–æ—Ä—Ç–æ–≤
# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ: worker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, api –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä, –∏–ª–∏ dev (host)
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))

# Worker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: /app
if os.path.exists('/app'):
    if '/app' not in sys.path:
        sys.path.insert(0, '/app')
    # –î–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ api: /opt/telegram-assistant/api
    api_mount = '/opt/telegram-assistant/api'
    if api_mount not in sys.path and os.path.exists(api_mount):
        sys.path.insert(0, api_mount)

# Dev –æ–∫—Ä—É–∂–µ–Ω–∏–µ: project_root
elif project_root and os.path.exists(project_root):
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    worker_root = os.path.join(project_root, 'worker')
    api_root = os.path.join(project_root, 'api')
    if worker_root not in sys.path and os.path.exists(worker_root):
        sys.path.insert(0, worker_root)
    if api_root not in sys.path and os.path.exists(api_root):
        sys.path.insert(0, api_root)

# Context7: –ò–º–ø–æ—Ä—Ç—ã –¥–µ–ª–∞–µ–º –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ - —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω—ã
# S3StorageService –∏ StorageQuotaService –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–π
# VisionUploadedEventV1 –∏ MediaFile –Ω—É–∂–Ω—ã –≤—Å–µ–≥–¥–∞
try:
    # Worker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: –∏–º–ø–æ—Ä—Ç—ã –∏–∑ /app/events
    from events.schemas.posts_vision_v1 import VisionUploadedEventV1, MediaFile
except ImportError:
    try:
        # Worker dev: –∏–º–ø–æ—Ä—Ç—ã –∏–∑ worker.events
        from worker.events.schemas.posts_vision_v1 import VisionUploadedEventV1, MediaFile
    except ImportError:
        # Fallback
        from events.schemas.posts_vision_v1 import VisionUploadedEventV1, MediaFile

import asyncpg
import redis.asyncio as redis
from sqlalchemy import create_engine, select, func
from sqlalchemy.orm import Session


def get_db_connection_string() -> str:
    """Context7: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î (–∏—Å–ø–æ–ª—å–∑—É–µ–º DATABASE_URL –∫–∞–∫ worker)."""
    # Context7: Worker –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DATABASE_URL
    database_url = os.getenv("DATABASE_URL")
    
    if database_url:
        # –£–±–∏—Ä–∞–µ–º +asyncpg –¥–ª—è asyncpg (–µ—Å–ª–∏ –µ—Å—Ç—å)
        return database_url.replace("postgresql+asyncpg://", "postgresql://")
    
    # Fallback: —Å–æ–±–∏—Ä–∞–µ–º –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    db_host = os.getenv("DB_HOST", os.getenv("POSTGRES_HOST", "supabase-db"))
    db_port = os.getenv("DB_PORT", os.getenv("POSTGRES_PORT", "5432"))
    db_user = os.getenv("POSTGRES_USER", "postgres")
    db_password = os.getenv("POSTGRES_PASSWORD", "") or os.getenv("DB_PASSWORD", "")
    db_name = os.getenv("POSTGRES_DB", os.getenv("DB_NAME", "postgres"))
    
    if not db_password:
        raise ValueError("DATABASE_URL –∏–ª–∏ POSTGRES_PASSWORD –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    
    return f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"


def get_redis_url() -> str:
    """Context7: –ü–æ–ª—É—á–µ–Ω–∏–µ URL Redis."""
    return os.getenv("REDIS_URL", "redis://redis:6379")


async def check_database_status() -> Dict[str, Any]:
    """
    Context7: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ë–î - –ø–æ—Å—Ç—ã —Å –º–µ–¥–∏–∞, media_objects, vision –∞–Ω–∞–ª–∏–∑.
    
    Returns:
        Dict —Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –ë–î
    """
    print("üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ë–î...")
    
    conn = await asyncpg.connect(get_db_connection_string())
    
    try:
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_posts = await conn.fetchval("SELECT COUNT(*) FROM posts")
        posts_with_media = await conn.fetchval(
            "SELECT COUNT(*) FROM posts WHERE has_media = true"
        )
        media_objects = await conn.fetchval("SELECT COUNT(*) FROM media_objects")
        post_media_links = await conn.fetchval("SELECT COUNT(*) FROM post_media_map")
        vision_analyzed = await conn.fetchval(
            "SELECT COUNT(*) FROM post_enrichment WHERE vision_analyzed_at IS NOT NULL"
        )
        
        # –ü–æ—Å—Ç—ã —Å –º–µ–¥–∏–∞ –±–µ–∑ vision –∞–Ω–∞–ª–∏–∑–∞
        posts_without_vision = await conn.fetchval("""
            SELECT COUNT(*)
            FROM posts p
            LEFT JOIN post_enrichment pe ON p.id = pe.post_id
            WHERE p.has_media = true
            AND (pe.vision_analyzed_at IS NULL OR pe.post_id IS NULL)
            LIMIT 100
        """)
        
        # –ü—Ä–∏–º–µ—Ä—ã –ø–æ—Å—Ç–æ–≤ —Å –º–µ–¥–∏–∞
        sample_posts = await conn.fetch("""
            SELECT p.id, p.channel_id, p.telegram_message_id, p.has_media, p.created_at,
                   (SELECT COUNT(*) FROM post_media pm WHERE pm.post_id = p.id) as media_count
            FROM posts p
            WHERE p.has_media = true
            ORDER BY p.created_at DESC
            LIMIT 5
        """)
        
        result = {
            "total_posts": total_posts,
            "posts_with_media": posts_with_media,
            "media_objects": media_objects,
            "post_media_links": post_media_links,
            "vision_analyzed": vision_analyzed,
            "posts_without_vision": posts_without_vision,
            "sample_posts": [
                {
                    "id": str(row["id"]),
                    "channel_id": str(row["channel_id"]),
                    "telegram_message_id": row["telegram_message_id"],
                    "has_media": row["has_media"],
                    "media_count": row["media_count"] or 0,
                    "created_at": row["created_at"].isoformat() if row["created_at"] else None
                }
                for row in sample_posts
            ]
        }
        
        print(f"‚úÖ –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {total_posts}")
        print(f"‚úÖ –ü–æ—Å—Ç–æ–≤ —Å –º–µ–¥–∏–∞: {posts_with_media}")
        print(f"‚úÖ Media objects –≤ –ë–î: {media_objects}")
        print(f"‚úÖ Post-media links: {post_media_links}")
        print(f"‚úÖ Vision analyzed: {vision_analyzed}")
        print(f"‚ö†Ô∏è  –ü–æ—Å—Ç–æ–≤ —Å –º–µ–¥–∏–∞ –±–µ–∑ vision –∞–Ω–∞–ª–∏–∑–∞: {posts_without_vision}")
        
        return result
        
    finally:
        await conn.close()


async def check_storage_quota() -> Dict[str, Any]:
    """
    Context7: –ü—Ä–æ–≤–µ—Ä–∫–∞ Storage Quota (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç S3StorageService).
    
    Returns:
        Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–≤–æ—Ç–µ
    """
    print("\nüíæ –ü—Ä–æ–≤–µ—Ä–∫–∞ Storage Quota...")
    
    # Context7: –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    try:
        # –í–∞—Ä–∏–∞–Ω—Ç 1: –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç —á–µ—Ä–µ–∑ api (–∫–æ–≥–¥–∞ api –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ sys.path)
        from api.services.s3_storage import S3StorageService
    except ImportError:
        # –í–∞—Ä–∏–∞–Ω—Ç 2: –∏–º–ø–æ—Ä—Ç –∏–∑ /app/services (API –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å volume mount)
        app_services_path = '/app/services'
        if app_services_path not in sys.path and os.path.exists(app_services_path):
            sys.path.insert(0, '/app')
        try:
            from services.s3_storage import S3StorageService
        except ImportError:
            # –í–∞—Ä–∏–∞–Ω—Ç 3: —á–µ—Ä–µ–∑ /opt/telegram-assistant/api (dev volume mount)
            api_path = '/opt/telegram-assistant/api'
            if api_path not in sys.path and os.path.exists(api_path):
                sys.path.insert(0, api_path)
            try:
                from api.services.s3_storage import S3StorageService
            except ImportError:
                raise ImportError("S3StorageService –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ api –≤ worker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.")
    
    try:
        # Worker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä: –∏–º–ø–æ—Ä—Ç—ã –∏–∑ /app/services
        from services.storage_quota import StorageQuotaService
    except ImportError:
        try:
            # Worker dev: –∏–º–ø–æ—Ä—Ç—ã –∏–∑ worker.services
            from worker.services.storage_quota import StorageQuotaService
        except ImportError:
            # Fallback
            worker_path = '/opt/telegram-assistant/worker'
            if worker_path not in sys.path and os.path.exists(worker_path):
                sys.path.insert(0, worker_path)
            from services.storage_quota import StorageQuotaService
    
    try:
        s3_service = S3StorageService()
        quota_service = StorageQuotaService(s3_service)
        
        status = quota_service.get_quota_status()
        
        result = {
            "used_gb": status.used_gb,
            "limit_gb": status.limit_gb,
            "usage_percent": status.usage_percent,
            "emergency_threshold_gb": status.emergency_threshold_gb,
            "is_critical": status.usage_percent >= 93.0,
            "is_warning": status.usage_percent >= 85.0
        }
        
        print(f"‚úÖ Storage usage: {result['used_gb']:.2f} GB / {result['limit_gb']:.2f} GB ({result['usage_percent']:.1f}%)")
        
        if result['is_critical']:
            print("‚ö†Ô∏è  –ö–†–ò–¢–ò–ß–ù–û: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ > 93%")
        elif result['is_warning']:
            print("‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ > 85%")
        
        return result
        
    except ImportError as e:
        print(f"‚ö†Ô∏è  S3StorageService –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Ç—Ä–µ–±—É–µ—Ç—Å—è –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ api): {e}")
        print("   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É Storage Quota")
        return {"error": "S3StorageService –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω", "skipped": True}
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ quota: {e}")
        return {"error": str(e)}


async def check_redis_streams() -> Dict[str, Any]:
    """
    Context7: –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis Streams –¥–ª—è Vision —Å–æ–±—ã—Ç–∏–π.
    
    Returns:
        Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç—Ä–∏–º–∞—Ö
    """
    print("\nüì® –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis Streams...")
    
    try:
        redis_url = get_redis_url()
        redis_client = redis.from_url(redis_url, decode_responses=True)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∏–º–∞ posts:vision
        stream_name = "posts:vision"
        stream_key = f"stream:{stream_name}"
        
        try:
            stream_info = await redis_client.xinfo_stream(stream_key)
            length = stream_info.get("length", 0)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
            last_events = await redis_client.xrevrange(stream_key, count=5)
            
            result = {
                "stream_exists": True,
                "length": length,
                "last_events_count": len(last_events),
                "sample_events": [
                    {
                        "event_id": event_id,
                        "data": {k: v for k, v in data.items() if k != "trace_id"}
                    }
                    for event_id, data in last_events[:2]
                ]
            }
            
            print(f"‚úÖ Stream {stream_name}: {length} —Å–æ–±—ã—Ç–∏–π")
            
        except Exception as e:
            if "no such key" in str(e).lower():
                result = {"stream_exists": False, "length": 0}
                print(f"‚ö†Ô∏è  Stream {stream_name} –Ω–µ –Ω–∞–π–¥–µ–Ω (–æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è –Ω–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º)")
            else:
                raise
        
        await redis_client.close()
        return result
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Redis: {e}")
        return {"error": str(e)}


async def trigger_vision_event_for_post(post_id: UUID) -> Dict[str, Any]:
    """
    Context7: –≠–º–∏—Å—Å–∏—è VisionUploadedEvent –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø–æ—Å—Ç–∞ —Å –º–µ–¥–∏–∞.
    
    Args:
        post_id: UUID –ø–æ—Å—Ç–∞
        
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –æ–ø–µ—Ä–∞—Ü–∏–∏
    """
    print(f"\nüöÄ –≠–º–∏—Å—Å–∏—è VisionUploadedEvent –¥–ª—è –ø–æ—Å—Ç–∞ {post_id}...")
    
    conn = await asyncpg.connect(get_db_connection_string())
    redis_url = get_redis_url()
    redis_client = redis.from_url(redis_url, decode_responses=False)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å—Ç–µ
        post_data = await conn.fetchrow("""
            SELECT p.id, p.channel_id, p.telegram_message_id, p.has_media,
                   (SELECT COUNT(*) FROM post_media pm WHERE pm.post_id = p.id) as media_count
            FROM posts p
            WHERE p.id = $1
        """, post_id)
        
        if not post_data:
            return {"error": f"–ü–æ—Å—Ç {post_id} –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        
        if not post_data["has_media"] or (post_data["media_count"] or 0) == 0:
            return {"error": f"–ü–æ—Å—Ç {post_id} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ–¥–∏–∞ (has_media={post_data['has_media']}, count={post_data['media_count']})"}
        
        # –ü–æ–ª—É—á–∞–µ–º media objects –¥–ª—è –ø–æ—Å—Ç–∞ (—Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ post_media_map, –ø–æ—Ç–æ–º —á–µ—Ä–µ–∑ post_media)
        media_objects = await conn.fetch("""
            SELECT mo.file_sha256, mo.mime, mo.size_bytes, mo.s3_key, pmm.position, pmm.role
            FROM post_media_map pmm
            JOIN media_objects mo ON pmm.file_sha256 = mo.file_sha256
            WHERE pmm.post_id = $1
            ORDER BY pmm.position
        """, post_id)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –≤ post_media_map, –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ post_media (legacy)
        if not media_objects:
            post_media_records = await conn.fetch("""
                SELECT pm.id, pm.media_type, pm.sha256, pm.file_size_bytes, pm.media_url
                FROM post_media pm
                WHERE pm.post_id = $1
                ORDER BY pm.id
            """, post_id)
            
            if not post_media_records:
                return {
                    "error": f"Media objects –¥–ª—è –ø–æ—Å—Ç–∞ {post_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
                    "hint": "–ü–æ—Å—Ç –∏–º–µ–µ—Ç has_media=true, –Ω–æ –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ post_media_map –∏–ª–∏ post_media. –ú–µ–¥–∏–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ–ª—å–∫–æ –≤ Telegram."
                }
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ post_media –±–µ–∑ media_objects - –º–µ–¥–∏–∞ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ S3
            return {
                "error": f"Media –¥–ª—è –ø–æ—Å—Ç–∞ {post_id} –µ—Å—Ç—å –≤ post_media, –Ω–æ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ S3",
                "hint": "–ú–µ–¥–∏–∞ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ MediaProcessor. –ò—Å–ø–æ–ª—å–∑—É–π telethon-ingest –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞.",
                "post_media_count": len(post_media_records)
            }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º MediaFile –æ–±—ä–µ–∫—Ç—ã
        media_files = [
            MediaFile(
                sha256=row["file_sha256"],
                s3_key=row["s3_key"],
                mime_type=row["mime"],
                size_bytes=row["size_bytes"]
            )
            for row in media_objects
        ]
        
        # –°–æ–∑–¥–∞—ë–º —Å–æ–±—ã—Ç–∏–µ
        event = VisionUploadedEventV1(
            post_id=str(post_id),
            tenant_id=str(post_data["tenant_id"]) if post_data["tenant_id"] else os.getenv("S3_DEFAULT_TENANT_ID", ""),
            media_files=media_files,
            trace_id=f"test-{datetime.utcnow().isoformat()}",
            timestamp=datetime.utcnow()
        )
        
        # –≠–º–∏—Ç–∏—Ä—É–µ–º –≤ Redis Stream
        stream_key = "stream:posts:vision"
        event_data = event.model_dump(mode="json")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º UUID –∏ datetime –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è Redis
        for key, value in event_data.items():
            if isinstance(value, (UUID, datetime)):
                event_data[key] = str(value)
            elif isinstance(value, list):
                event_data = {k: json.dumps(v) if isinstance(v, (dict, list)) else str(v) for k, v in event_data.items()}
                break
        
        event_id = await redis_client.xadd(
            stream_key,
            event_data,
            maxlen=10000  # Context7: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Å—Ç—Ä–∏–º–∞
        )
        
        result = {
            "success": True,
            "event_id": event_id.decode() if isinstance(event_id, bytes) else event_id,
            "post_id": str(post_id),
            "media_files_count": len(media_files),
            "stream_key": stream_key
        }
        
        print(f"‚úÖ –°–æ–±—ã—Ç–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {result['event_id']}")
        print(f"‚úÖ Media files: {len(media_files)}")
        
        return result
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–º–∏—Å—Å–∏–∏ —Å–æ–±—ã—Ç–∏—è: {e}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}
        
    finally:
        await conn.close()
        await redis_client.close()


async def full_pipeline_test() -> Dict[str, Any]:
    """
    Context7: –ü–æ–ª–Ω—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞.
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    print("\n" + "="*80)
    print("üß™ –ü–û–õ–ù–´–ô –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢ VISION + S3 PIPELINE")
    print("="*80)
    
    results = {}
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î
    results["database"] = await check_database_status()
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ Storage Quota
    results["storage_quota"] = await check_storage_quota()
    
    # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis Streams
    results["redis_streams"] = await check_redis_streams()
    
    # 4. –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ—Å—Ç—ã —Å –º–µ–¥–∏–∞ –±–µ–∑ vision –∞–Ω–∞–ª–∏–∑–∞ - —ç–º–∏—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ
    if results["database"].get("posts_without_vision", 0) > 0:
        sample_post_id = results["database"]["sample_posts"][0]["id"]
        print(f"\nüîÑ –¢—Ä–∏–≥–≥–µ—Ä Vision —Å–æ–±—ã—Ç–∏—è –¥–ª—è –ø–æ—Å—Ç–∞ {sample_post_id}...")
        results["triggered_event"] = await trigger_vision_event_for_post(UUID(sample_post_id))
        
        # –ñ–¥—ë–º –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        print("\n‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏—è (10 —Å–µ–∫—É–Ω–¥)...")
        await asyncio.sleep(10)
        
        # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ë–î
        print("\nüìä –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ë–î –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        results["database_after"] = await check_database_status()
    else:
        print("\n‚ö†Ô∏è  –ù–µ—Ç –ø–æ—Å—Ç–æ–≤ —Å –º–µ–¥–∏–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    return results


async def main():
    """Context7: –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    parser = argparse.ArgumentParser(description="–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Vision + S3 Pipeline")
    parser.add_argument("--check-status", action="store_true", help="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ —Å—Ç–∞—Ç—É—Å–∞")
    parser.add_argument("--trigger-vision", action="store_true", help="–≠–º–∏—Å—Å–∏—è Vision —Å–æ–±—ã—Ç–∏—è")
    parser.add_argument("--post-id", type=str, help="UUID –ø–æ—Å—Ç–∞ –¥–ª—è —Ç—Ä–∏–≥–≥–µ—Ä–∞")
    parser.add_argument("--full-test", action="store_true", help="–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞")
    
    args = parser.parse_args()
    
    if args.check_status:
        await check_database_status()
        try:
            await check_storage_quota()
        except Exception as e:
            print(f"\n‚ö†Ô∏è  Storage Quota –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞: {e}")
        await check_redis_streams()
    elif args.trigger_vision:
        if not args.post_id:
            print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è --post-id –¥–ª—è —Ç—Ä–∏–≥–≥–µ—Ä–∞")
            sys.exit(1)
        result = await trigger_vision_event_for_post(UUID(args.post_id))
        print("\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(json.dumps(result, indent=2, default=str))
    elif args.full_test:
        results = await full_pipeline_test()
        print("\n" + "="*80)
        print("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–Å–¢")
        print("="*80)
        print(json.dumps(results, indent=2, default=str))
    else:
        parser.print_help()


if __name__ == "__main__":
    asyncio.run(main())
