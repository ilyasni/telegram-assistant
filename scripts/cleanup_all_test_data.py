#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞—Å—Ç—Ä—è–≤—à–∏—Ö –æ—á–µ—Ä–µ–¥–µ–π.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Context7 best practices –¥–ª—è:
- PostgreSQL –º–∞—Å—Å–æ–≤—ã—Ö —É–¥–∞–ª–µ–Ω–∏–π —Å FK constraints
- Redis Streams –æ—á–∏—Å—Ç–∫–∏ (XAUTOCLAIM, XTRIM, XDEL)
- Qdrant —É–¥–∞–ª–µ–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–π
- Neo4j –º–∞—Å—Å–æ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —É–¥–∞–ª–µ–Ω–∏—è
- Prometheus TSDB –æ—á–∏—Å—Ç–∫–∏ –º–µ—Ç—Ä–∏–∫

–°–æ—Ö—Ä–∞–Ω—è–µ—Ç:
- users, identities, tenants
- telegram_sessions (–∞–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏)
- channels (–∫–∞–Ω–∞–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)
- user_channel (–ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ –∫–∞–Ω–∞–ª—ã)
- Grafana –¥–∞—à–±–æ—Ä–¥—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (—Ç–æ–ª—å–∫–æ –º–µ—Ç—Ä–∏–∫–∏ –≤ Prometheus —É–¥–∞–ª—è—é—Ç—Å—è)

–í–ê–ñ–ù–û: Grafana –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Prometheus –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö.
–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ Prometheus, –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ Grafana –∏—Å—á–µ–∑–Ω—É—Ç,
–Ω–æ –¥–∞—à–±–æ—Ä–¥—ã, –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ datasources –æ—Å—Ç–∞–Ω—É—Ç—Å—è –Ω–µ—Ç—Ä–æ–Ω—É—Ç—ã–º–∏.
"""

import asyncio
import os
import sys
import argparse
from typing import Dict, List, Optional
from sqlalchemy import create_engine, text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
import structlog
import redis.asyncio as redis
from qdrant_client import QdrantClient as QdrantSDK
from qdrant_client.http.exceptions import UnexpectedResponse
from neo4j import AsyncGraphDatabase
try:
    import httpx
except ImportError:
    httpx = None  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –¥–ª—è Prometheus

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append('/opt/telegram-assistant')

logger = structlog.get_logger()

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

# Redis Streams –∏–∑ worker/event_bus.py
REDIS_STREAMS = [
    'stream:posts:parsed',
    'stream:posts:tagged',
    'stream:posts:enriched',
    'stream:posts:indexed',
    'stream:posts:crawl',
    'stream:posts:deleted',
    'stream:posts:vision:uploaded',
    'stream:posts:vision:analyzed',
    'stream:albums:parsed',
    'stream:album:assembled',
    # DLQ —Å—Ç—Ä–∏–º—ã
    'stream:posts:parsed:dlq',
    'stream:posts:tagged:dlq',
    'stream:posts:enriched:dlq',
    'stream:posts:indexed:dlq',
    'stream:posts:crawl:dlq',
    'stream:posts:deleted:dlq',
    'stream:posts:vision:analyzed:dlq',
    'stream:albums:parsed:dlq',
    'stream:album:assembled:dlq',
]

# –¢–∞–±–ª–∏—Ü—ã –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (—Å —É—á–µ—Ç–æ–º FK dependencies)
POSTGRES_TABLES = [
    # –ó–∞–≤–∏—Å–∏–º—ã–µ —Ç–∞–±–ª–∏—Ü—ã –æ—Ç posts (—É–¥–∞–ª—è–µ–º —Å–Ω–∞—á–∞–ª–∞)
    "post_media_map",
    "post_reactions",
    "post_forwards",
    "post_replies",
    "post_media",
    "post_enrichment",
    "indexing_status",
    # –ê–ª—å–±–æ–º—ã (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç posts –∏ channels/users)
    "media_group_items",
    "media_groups",
    # –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ—Å—Ç–æ–≤ (–≤ –∫–æ–Ω—Ü–µ)
    "posts",
]

# –¢–µ—Å—Ç–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ (Context7: –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º)
TEST_CHANNEL_PATTERNS = [
    ("title", "Test E2E Channel"),
    ("username", "test_e2e_channel"),
]

# ============================================================================
# POSTGRESQL –û–ß–ò–°–¢–ö–ê
# ============================================================================

async def cleanup_postgres(
    db_url: str,
    dry_run: bool = False
) -> Dict[str, Dict[str, int]]:
    """
    Context7 best practice: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏.
    –£–¥–∞–ª–µ–Ω–∏–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ —Å —É—á–µ—Ç–æ–º FK constraints.
    """
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É PostgreSQL", dry_run=dry_run)
    
    engine = create_async_engine(db_url)
    stats = {"before": {}, "after": {}}
    
    try:
        async with AsyncSession(engine) as session:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
            logger.info("–°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –î–û –æ—á–∏—Å—Ç–∫–∏...")
            for table in POSTGRES_TABLES:
                try:
                    result = await session.execute(
                        text(f"SELECT COUNT(*) FROM {table}")
                    )
                    count = result.scalar()
                    stats["before"][table] = count
                    logger.info(f"–¢–∞–±–ª–∏—Ü–∞ {table}: {count} –∑–∞–ø–∏—Å–µ–π")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è {table}", error=str(e))
                    stats["before"][table] = 0
            
            if dry_run:
                logger.info("DRY-RUN: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
                stats["after"] = stats["before"].copy()
                return stats
            
            # Context7: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ—Å—Ç–∏
            logger.info("–ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ...")
            
            for table in POSTGRES_TABLES:
                try:
                    logger.info(f"–û—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É {table}...")
                    
                    # Context7: DELETE –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                    await session.execute(text(f"DELETE FROM {table}"))
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    result = await session.execute(
                        text(f"SELECT COUNT(*) FROM {table}")
                    )
                    remaining = result.scalar()
                    stats["after"][table] = remaining
                    
                    deleted = stats["before"][table] - remaining
                    logger.info(
                        f"–¢–∞–±–ª–∏—Ü–∞ {table}: —É–¥–∞–ª–µ–Ω–æ {deleted}, –æ—Å—Ç–∞–ª–æ—Å—å {remaining}"
                    )
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Ç–∞–±–ª–∏—Ü—ã {table}", error=str(e))
                    await session.rollback()
                    raise
            
            # –û—á–∏—â–∞–µ–º –ø–æ–ª–µ grouped_id –≤ posts (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å NULL –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è media_groups)
            try:
                await session.execute(
                    text("UPDATE posts SET grouped_id = NULL WHERE grouped_id IS NOT NULL")
                )
                logger.info("–û—á–∏—â–µ–Ω–æ –ø–æ–ª–µ posts.grouped_id")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å posts.grouped_id", error=str(e))
            
            # Context7: –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ (–ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
            try:
                logger.info("–û—á–∏—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã...")
                
                # –°–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (user_channel, posts —É–∂–µ —É–¥–∞–ª–µ–Ω—ã –≤—ã—à–µ)
                # –ù–æ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å user_channel –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
                test_channels_result = await session.execute(text("""
                    SELECT id FROM channels 
                    WHERE title = 'Test E2E Channel' OR username = 'test_e2e_channel'
                """))
                test_channel_ids = [row[0] for row in test_channels_result.fetchall()]
                
                if test_channel_ids:
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(test_channel_ids)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤")
                    
                    # –£–¥–∞–ª—è–µ–º user_channel –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
                    await session.execute(text("""
                        DELETE FROM user_channel 
                        WHERE channel_id = ANY(:channel_ids)
                    """), {"channel_ids": test_channel_ids})
                    
                    # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã
                    deleted_channels = await session.execute(text("""
                        DELETE FROM channels 
                        WHERE title = 'Test E2E Channel' OR username = 'test_e2e_channel'
                        RETURNING id
                    """))
                    deleted_count = len(deleted_channels.fetchall())
                    logger.info(f"–£–¥–∞–ª–µ–Ω–æ {deleted_count} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤")
                else:
                    logger.info("–¢–µ—Å—Ç–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–∞–Ω–∞–ª—ã", error=str(e))
            
            # –ö–æ–º–º–∏—Ç–∏–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
            await session.commit()
            
            logger.info("PostgreSQL –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ PostgreSQL", error=str(e))
        raise
    finally:
        await engine.dispose()
    
    return stats

# ============================================================================
# REDIS STREAMS –û–ß–ò–°–¢–ö–ê
# ============================================================================

async def cleanup_redis_streams(
    redis_url: str,
    dry_run: bool = False
) -> Dict[str, Dict[str, int]]:
    """
    Context7 best practice: –û—á–∏—Å—Ç–∫–∞ Redis Streams —á–µ—Ä–µ–∑ XTRIM, XAUTOCLAIM, XACK.
    """
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É Redis Streams", dry_run=dry_run)
    
    redis_client = None
    stats = {}
    
    try:
        redis_client = await redis.from_url(redis_url, decode_responses=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        await redis_client.ping()
        logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        
        for stream_name in REDIS_STREAMS:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∏–º–∞
                stream_length = await redis_client.xlen(stream_name)
                
                if stream_length == 0:
                    logger.info(f"–°—Ç—Ä–∏–º {stream_name}: –ø—É—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    stats[stream_name] = {"before": 0, "after": 0}
                    continue
                
                stats[stream_name] = {"before": stream_length, "after": 0}
                logger.info(f"–°—Ç—Ä–∏–º {stream_name}: {stream_length} —Å–æ–æ–±—â–µ–Ω–∏–π")
                
                if dry_run:
                    logger.info(f"DRY-RUN: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–∏—Å—Ç–∫—É {stream_name}")
                    stats[stream_name]["after"] = stream_length
                    continue
                
                # Context7: –û—á–∏—Å—Ç–∫–∞ PEL —á–µ—Ä–µ–∑ XAUTOCLAIM –¥–ª—è –≤—Å–µ—Ö consumer groups
                # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –¥–ª—è —ç—Ç–æ–≥–æ —Å—Ç—Ä–∏–º–∞
                try:
                    groups_info = await redis_client.xinfo_groups(stream_name)
                    
                    for group_info in groups_info:
                        group_name = group_info['name']
                        pending_count = group_info.get('pending', 0)
                        
                        if pending_count > 0:
                            logger.info(
                                f"–ì—Ä—É–ø–ø–∞ {group_name} –≤ {stream_name}: "
                                f"{pending_count} pending —Å–æ–æ–±—â–µ–Ω–∏–π"
                            )
                            
                            # Context7: XAUTOCLAIM –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö pending —Å–æ–æ–±—â–µ–Ω–∏–π
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π idle time (0) –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö
                            claimed = await redis_client.xautoclaim(
                                stream_name,
                                group_name,
                                "cleanup_worker",
                                min_idle_time=0,
                                start_id="0-0",
                                count=100
                            )
                            
                            # ACK –≤—Å–µ—Ö claimed —Å–æ–æ–±—â–µ–Ω–∏–π
                            if claimed and len(claimed) > 1:
                                message_ids = claimed[1]
                                if message_ids:
                                    await redis_client.xack(stream_name, group_name, *message_ids)
                                    logger.info(
                                        f"–û—á–∏—â–µ–Ω–æ {len(message_ids)} pending —Å–æ–æ–±—â–µ–Ω–∏–π "
                                        f"–∏–∑ –≥—Ä—É–ø–ø—ã {group_name}"
                                    )
                
                except Exception as e:
                    logger.warning(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å PEL –¥–ª—è {stream_name}",
                        error=str(e)
                    )
                
                # Context7: XTRIM –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Å—Ç—Ä–∏–º–∞ (—É–¥–∞–ª—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º MAXLEN 0 –¥–ª—è –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏
                await redis_client.xtrim(stream_name, maxlen=0, approximate=False)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                final_length = await redis_client.xlen(stream_name)
                stats[stream_name]["after"] = final_length
                
                logger.info(
                    f"–°—Ç—Ä–∏–º {stream_name}: –æ—á–∏—â–µ–Ω–æ "
                    f"{stream_length - final_length} —Å–æ–æ–±—â–µ–Ω–∏–π"
                )
                
            except Exception as e:
                # –ï—Å–ª–∏ —Å—Ç—Ä–∏–º –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
                if "no such key" in str(e).lower():
                    logger.debug(f"–°—Ç—Ä–∏–º {stream_name} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    stats[stream_name] = {"before": 0, "after": 0}
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç—Ä–∏–º–∞ {stream_name}", error=str(e))
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É —Å –¥—Ä—É–≥–∏–º–∏ —Å—Ç—Ä–∏–º–∞–º–∏
        
        logger.info("Redis Streams –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ Redis Streams", error=str(e))
        raise
    finally:
        if redis_client:
            await redis_client.close()
    
    return stats

# ============================================================================
# QDRANT –û–ß–ò–°–¢–ö–ê
# ============================================================================

async def cleanup_qdrant(
    qdrant_url: str,
    dry_run: bool = False
) -> Dict[str, int]:
    """
    Context7 best practice: –ü–æ–ª–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π —á–µ—Ä–µ–∑ API.
    """
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É Qdrant", dry_run=dry_run)
    
    stats = {}
    
    try:
        # Qdrant SDK —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π, –Ω–æ –º—ã –º–æ–∂–µ–º –æ–±–µ—Ä–Ω—É—Ç—å –≤ asyncio
        client = QdrantSDK(url=qdrant_url)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–ª–ª–µ–∫—Ü–∏–π
        collections = client.get_collections()
        
        collection_names = [col.name for col in collections.collections]
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –∫–æ–ª–ª–µ–∫—Ü–∏–π: {len(collection_names)}")
        
        for collection_name in collection_names:
            try:
                collection_info = client.get_collection(collection_name)
                points_count = collection_info.points_count
                
                stats[collection_name] = points_count
                logger.info(
                    f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name}: {points_count} —Ç–æ—á–µ–∫"
                )
                
                if dry_run:
                    logger.info(f"DRY-RUN: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ {collection_name}")
                    continue
                
                # Context7: –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ DELETE /collections/{name}
                client.delete_collection(collection_name)
                logger.info(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É–¥–∞–ª–µ–Ω–∞")
                
            except UnexpectedResponse:
                logger.warning(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} —É–∂–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {collection_name}",
                    error=str(e)
                )
        
        logger.info("Qdrant –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ Qdrant", error=str(e))
        raise
    
    return stats

# ============================================================================
# NEO4J –û–ß–ò–°–¢–ö–ê
# ============================================================================

async def cleanup_prometheus(
    prometheus_url: str = "http://prometheus:9090",
    dry_run: bool = False
) -> Dict[str, str]:
    """
    Context7 best practice: –û—á–∏—Å—Ç–∫–∞ Prometheus TSDB —á–µ—Ä–µ–∑ Admin API.
    –£–¥–∞–ª—è–µ—Ç –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
    
    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: Grafana –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Prometheus –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö.
    –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ Prometheus, Grafana –Ω–µ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏,
    –Ω–æ –¥–∞—à–±–æ—Ä–¥—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–Ω—É—Ç—Å—è.
    """
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É Prometheus TSDB", dry_run=dry_run)
    
    stats = {}
    
    try:
        if httpx is None:
            logger.warning("httpx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –æ—á–∏—Å—Ç–∫–∞ Prometheus –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
            stats["error"] = "httpx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
            stats["status"] = "skipped"
            return stats
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Prometheus
            try:
                response = await client.get(f"{prometheus_url}/api/v1/status/config")
                response.raise_for_status()
                logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Prometheus —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Prometheus: {e}")
                stats["error"] = str(e)
                return stats
            
            if dry_run:
                logger.info("DRY-RUN: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–∏—Å—Ç–∫—É Prometheus TSDB")
                stats["status"] = "dry_run"
                return stats
            
            # Context7: –û—á–∏—Å—Ç–∫–∞ —á–µ—Ä–µ–∑ Admin API
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º /api/v1/admin/tsdb/clean_tombstones –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è tombstone markers
            # –î–ª—è –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /api/v1/admin/tsdb/delete_series
            
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å–µ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫
            # Context7: Prometheus Admin API —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            logger.info("–£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–µ—Ä–∏–π –º–µ—Ç—Ä–∏–∫...")
            
            # Context7: Prometheus Admin API delete_series —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º GET –∑–∞–ø—Ä–æ—Å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ match[] (POST —Ç–æ–∂–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è, –Ω–æ GET –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–µ–Ω)
            try:
                # –í–∞—Ä–∏–∞–Ω—Ç 1: GET —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ match[]
                delete_response = await client.get(
                    f"{prometheus_url}/api/v1/admin/tsdb/delete_series",
                    params={"match[]": '{__name__=~".+"}'},  # –£–¥–∞–ª—è–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
                    timeout=60.0
                )
                
                if delete_response.status_code != 200:
                    # –í–∞—Ä–∏–∞–Ω—Ç 2: POST –∑–∞–ø—Ä–æ—Å
                    logger.info("–ü—Ä–æ–±—É–µ–º POST –∑–∞–ø—Ä–æ—Å...")
                    delete_response = await client.post(
                        f"{prometheus_url}/api/v1/admin/tsdb/delete_series",
                        params={"match[]": '{__name__=~".+"}'},
                        timeout=60.0
                    )
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ Admin API: {e}")
                # Context7: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ - –æ—á–∏—Å—Ç–∫–∞ —á–µ—Ä–µ–∑ —É–¥–∞–ª–µ–Ω–∏–µ volume
                # –ù–æ —ç—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ Docker, –ø–æ—ç—Ç–æ–º—É –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                stats["error"] = f"Admin API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}"
                stats["status"] = "partial"
                logger.warning(
                    "Prometheus Admin API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. "
                    "–ú–µ—Ç—Ä–∏–∫–∏ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –¥–æ –∏—Å—Ç–µ—á–µ–Ω–∏—è retention (200h). "
                    "–î–ª—è –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å volume prometheus_data"
                )
                return stats
            
            if delete_response.status_code == 200:
                logger.info("–°–µ—Ä–∏–∏ –º–µ—Ç—Ä–∏–∫ —É–¥–∞–ª–µ–Ω—ã, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è cleanup tombstones...")
                stats["delete_series"] = "success"
                
                # –û—á–∏—â–∞–µ–º tombstone markers
                cleanup_response = await client.post(
                    f"{prometheus_url}/api/v1/admin/tsdb/clean_tombstones",
                    timeout=60.0
                )
                
                if cleanup_response.status_code == 200:
                    logger.info("Prometheus TSDB –æ—á–∏—â–µ–Ω")
                    stats["clean_tombstones"] = "success"
                    stats["status"] = "completed"
                else:
                    logger.warning(
                        f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ tombstones: {cleanup_response.status_code}"
                    )
                    stats["clean_tombstones"] = f"error_{cleanup_response.status_code}"
            else:
                logger.warning(
                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–µ—Ä–∏–π: {delete_response.status_code}"
                )
                stats["delete_series"] = f"error_{delete_response.status_code}"
                stats["status"] = "partial"
                
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ Prometheus", error=str(e))
        stats["error"] = str(e)
        stats["status"] = "failed"
    
    return stats

async def cleanup_neo4j(
    neo4j_uri: str,
    neo4j_user: str,
    neo4j_password: str,
    dry_run: bool = False
) -> Dict[str, int]:
    """
    Context7 best practice: –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —É–∑–ª–æ–≤ –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ MATCH (n) DETACH DELETE n.
    """
    logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ—á–∏—Å—Ç–∫—É Neo4j", dry_run=dry_run)
    
    stats = {}
    driver = None
    
    try:
        driver = AsyncGraphDatabase.driver(
            neo4j_uri,
            auth=(neo4j_user, neo4j_password)
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        await driver.verify_connectivity()
        logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Neo4j —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        
        async with driver.session() as session:
            # –°—á–∏—Ç–∞–µ–º —É–∑–ª—ã –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
            result = await session.run("MATCH (n) RETURN count(n) as node_count")
            record = await result.single()
            node_count = record["node_count"] if record else 0
            
            result = await session.run("MATCH ()-[r]->() RETURN count(r) as rel_count")
            record = await result.single()
            rel_count = record["rel_count"] if record else 0
            
            stats["nodes"] = node_count
            stats["relationships"] = rel_count
            
            logger.info(
                f"–ù–∞–π–¥–µ–Ω–æ —É–∑–ª–æ–≤: {node_count}, –æ—Ç–Ω–æ—à–µ–Ω–∏–π: {rel_count}"
            )
            
            if dry_run:
                logger.info("DRY-RUN: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö")
                return stats
            
            # Context7: MATCH (n) DETACH DELETE n - —É–¥–∞–ª—è–µ—Ç –≤—Å–µ —É–∑–ª—ã –∏ –∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏—è
            result = await session.run("MATCH (n) DETACH DELETE n RETURN count(n) as deleted")
            record = await result.single()
            deleted_count = record["deleted"] if record else 0
            
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ —É–∑–ª–æ–≤ –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏–π: {deleted_count}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = await session.run("MATCH (n) RETURN count(n) as node_count")
            record = await result.single()
            remaining_nodes = record["node_count"] if record else 0
            
            result = await session.run("MATCH ()-[r]->() RETURN count(r) as rel_count")
            record = await result.single()
            remaining_rels = record["rel_count"] if record else 0
            
            stats["nodes_after"] = remaining_nodes
            stats["relationships_after"] = remaining_rels
            
            logger.info(
                f"–û—Å—Ç–∞–ª–æ—Å—å —É–∑–ª–æ–≤: {remaining_nodes}, –æ—Ç–Ω–æ—à–µ–Ω–∏–π: {remaining_rels}"
            )
        
        logger.info("Neo4j –æ—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ Neo4j", error=str(e))
        raise
    finally:
        if driver:
            await driver.close()
    
    return stats

# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(
        description="–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞—Å—Ç—Ä—è–≤—à–∏—Ö –æ—á–µ—Ä–µ–¥–µ–π"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="–†–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"
    )
    parser.add_argument(
        "--skip-postgres",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—á–∏—Å—Ç–∫—É PostgreSQL"
    )
    parser.add_argument(
        "--skip-redis",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—á–∏—Å—Ç–∫—É Redis Streams"
    )
    parser.add_argument(
        "--skip-qdrant",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—á–∏—Å—Ç–∫—É Qdrant"
    )
    parser.add_argument(
        "--skip-neo4j",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—á–∏—Å—Ç–∫—É Neo4j"
    )
    parser.add_argument(
        "--skip-prometheus",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ—á–∏—Å—Ç–∫—É Prometheus –º–µ—Ç—Ä–∏–∫"
    )
    parser.add_argument(
        "--yes",
        "-y",
        action="store_true",
        help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ (–±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è)"
    )
    
    args = parser.parse_args()
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π URL –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    db_url_env = os.getenv(
        "DATABASE_URL",
        "postgresql+asyncpg://postgres:postgres@localhost:5432/postgres"
    )
    # –ï—Å–ª–∏ URL —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π (postgresql://), –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ asyncpg
    if db_url_env.startswith("postgresql://") and "+asyncpg" not in db_url_env:
        db_url = db_url_env.replace("postgresql://", "postgresql+asyncpg://", 1)
    else:
        db_url = db_url_env
    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")
    qdrant_url = os.getenv("QDRANT_URL", "http://qdrant:6333")
    neo4j_uri = os.getenv("NEO4J_URI") or os.getenv("NEO4J_URL", "neo4j://neo4j:7687")
    neo4j_user = os.getenv("NEO4J_USER", "neo4j")
    neo4j_password = os.getenv("NEO4J_PASSWORD", "neo4j123")
    prometheus_url = os.getenv("PROMETHEUS_URL", "http://prometheus:9090")
    
    print("=" * 80)
    print("–û–ß–ò–°–¢–ö–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–• –ò –ó–ê–°–¢–†–Ø–í–®–ò–• –û–ß–ï–†–ï–î–ï–ô")
    print("=" * 80)
    print(f"–†–µ–∂–∏–º: {'DRY-RUN (–ø—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è)' if args.dry_run else '–†–ï–ê–õ–¨–ù–û–ï –£–î–ê–õ–ï–ù–ò–ï'}")
    print(f"PostgreSQL: {'–ü—Ä–æ–ø—É—â–µ–Ω–æ' if args.skip_postgres else '–í–∫–ª—é—á–µ–Ω–æ'}")
    print(f"Redis: {'–ü—Ä–æ–ø—É—â–µ–Ω–æ' if args.skip_redis else '–í–∫–ª—é—á–µ–Ω–æ'}")
    print(f"Qdrant: {'–ü—Ä–æ–ø—É—â–µ–Ω–æ' if args.skip_qdrant else '–í–∫–ª—é—á–µ–Ω–æ'}")
    print(f"Neo4j: {'–ü—Ä–æ–ø—É—â–µ–Ω–æ' if args.skip_neo4j else '–í–∫–ª—é—á–µ–Ω–æ'}")
    print(f"Prometheus: {'–ü—Ä–æ–ø—É—â–µ–Ω–æ' if args.skip_prometheus else '–í–∫–ª—é—á–µ–Ω–æ'}")
    print(f"\n‚ö†Ô∏è  –í–ê–ñ–ù–û: Grafana –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Prometheus –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö.")
    print(f"    –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ Prometheus, –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ Grafana –∏—Å—á–µ–∑–Ω—É—Ç,")
    print(f"    –Ω–æ –¥–∞—à–±–æ—Ä–¥—ã –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–Ω—É—Ç—Å—è.")
    print("=" * 80)
    
    if not args.dry_run and not args.yes:
        try:
            response = input("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ë—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —Ä–µ–∞–ª—å–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö! –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (yes/no): ")
            if response.lower() != "yes":
                print("–û—Ç–º–µ–Ω–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                sys.exit(0)
        except EOFError:
            # –ù–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–≤–æ–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ docker exec -T)
            print("\n‚ö†Ô∏è  –ù–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–≤–æ–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --yes –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è.")
            sys.exit(1)
    
    all_stats = {}
    
    try:
        # –û—á–∏—Å—Ç–∫–∞ PostgreSQL
        if not args.skip_postgres:
            print("\nüìä –û—á–∏—Å—Ç–∫–∞ PostgreSQL...")
            all_stats["postgresql"] = await cleanup_postgres(db_url, args.dry_run)
        else:
            print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ PostgreSQL")
        
        # –û—á–∏—Å—Ç–∫–∞ Redis Streams
        if not args.skip_redis:
            print("\nüìä –û—á–∏—Å—Ç–∫–∞ Redis Streams...")
            all_stats["redis"] = await cleanup_redis_streams(redis_url, args.dry_run)
        else:
            print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ Redis Streams")
        
        # –û—á–∏—Å—Ç–∫–∞ Qdrant
        if not args.skip_qdrant:
            print("\nüìä –û—á–∏—Å—Ç–∫–∞ Qdrant...")
            all_stats["qdrant"] = await cleanup_qdrant(qdrant_url, args.dry_run)
        else:
            print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ Qdrant")
        
        # –û—á–∏—Å—Ç–∫–∞ Neo4j
        if not args.skip_neo4j:
            print("\nüìä –û—á–∏—Å—Ç–∫–∞ Neo4j...")
            all_stats["neo4j"] = await cleanup_neo4j(
                neo4j_uri, neo4j_user, neo4j_password, args.dry_run
            )
        else:
            print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ Neo4j")
        
        # –û—á–∏—Å—Ç–∫–∞ Prometheus
        if not args.skip_prometheus:
            print("\nüìä –û—á–∏—Å—Ç–∫–∞ Prometheus –º–µ—Ç—Ä–∏–∫...")
            all_stats["prometheus"] = await cleanup_prometheus(
                prometheus_url, args.dry_run
            )
        else:
            print("\n‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ –æ—á–∏—Å—Ç–∫–∏ Prometheus")
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "=" * 80)
        print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("=" * 80)
        
        if "postgresql" in all_stats:
            print("\nPostgreSQL:")
            for table, before_count in all_stats["postgresql"]["before"].items():
                after_count = all_stats["postgresql"]["after"].get(table, 0)
                deleted = before_count - after_count
                print(f"  {table}: {before_count} ‚Üí {after_count} (—É–¥–∞–ª–µ–Ω–æ: {deleted})")
        
        if "redis" in all_stats:
            print("\nRedis Streams:")
            for stream, stream_stats in all_stats["redis"].items():
                before = stream_stats.get("before", 0)
                after = stream_stats.get("after", 0)
                deleted = before - after
                if before > 0 or deleted > 0:
                    print(f"  {stream}: {before} ‚Üí {after} (—É–¥–∞–ª–µ–Ω–æ: {deleted})")
        
        if "qdrant" in all_stats:
            print("\nQdrant:")
            total_points = sum(all_stats["qdrant"].values())
            print(f"  –í—Å–µ–≥–æ —Ç–æ—á–µ–∫ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—è—Ö: {total_points}")
            print(f"  –ö–æ–ª–ª–µ–∫—Ü–∏–π: {len(all_stats['qdrant'])}")
        
        if "neo4j" in all_stats:
            print("\nNeo4j:")
            nodes = all_stats["neo4j"].get("nodes", 0)
            rels = all_stats["neo4j"].get("relationships", 0)
            nodes_after = all_stats["neo4j"].get("nodes_after", 0)
            rels_after = all_stats["neo4j"].get("relationships_after", 0)
            print(f"  –£–∑–ª—ã: {nodes} ‚Üí {nodes_after} (—É–¥–∞–ª–µ–Ω–æ: {nodes - nodes_after})")
            print(f"  –û—Ç–Ω–æ—à–µ–Ω–∏—è: {rels} ‚Üí {rels_after} (—É–¥–∞–ª–µ–Ω–æ: {rels - rels_after})")
        
        if "prometheus" in all_stats:
            print("\nPrometheus:")
            status = all_stats["prometheus"].get("status", "unknown")
            if status == "completed":
                print("  ‚úÖ –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ —É–¥–∞–ª–µ–Ω—ã –∏–∑ TSDB")
                print("  ‚ö†Ô∏è  Grafana –±–æ–ª—å—à–µ –Ω–µ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏")
            elif status == "dry_run":
                print("  üîç DRY-RUN: –ü—Ä–æ–ø—É—â–µ–Ω–æ")
            else:
                print(f"  ‚ö†Ô∏è  –°—Ç–∞—Ç—É—Å: {status}")
                if "error" in all_stats["prometheus"]:
                    print(f"  –û—à–∏–±–∫–∞: {all_stats['prometheus']['error']}")
        
        print("\n" + "=" * 80)
        
        if args.dry_run:
            print("‚úÖ DRY-RUN –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ. –î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–∑ --dry-run")
        else:
            print("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        logger.error("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞", error=str(e))
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())

