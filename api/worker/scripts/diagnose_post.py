#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ—Å—Ç–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏.

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –ù–∞–ª–∏—á–∏–µ –ø–æ—Å—Ç–∞ –≤ –ë–î
- –ù–∞–ª–∏—á–∏–µ —Ç–µ–≥–æ–≤ –≤ post_enrichment
- –ù–∞–ª–∏—á–∏–µ enrichment –¥–∞–Ω–Ω—ã—Ö (vision, crawl)
- –ù–∞–ª–∏—á–∏–µ –∑–∞–ø–∏—Å–∏ –≤ Qdrant
- –ù–∞–ª–∏—á–∏–µ –∑–∞–ø–∏—Å–∏ –≤ Neo4j
- –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (indexing_status)
- –ù–∞–ª–∏—á–∏–µ —Å–æ–±—ã—Ç–∏–π –≤ Redis streams
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç–º–±—ç–¥–∏–Ω–≥–æ–≤

Context7 best practices:
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ scroll –≤ Qdrant –ø–æ post_id (payload filter)
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ MATCH –≤ Neo4j –ø–æ post_id property
- –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
"""

import asyncio
import os
import sys
import json
import argparse
from datetime import datetime, timezone
from typing import Dict, Any, Optional, List
import structlog
import psycopg2
from psycopg2.extras import RealDictCursor
import redis.asyncio as redis_async
from redis.asyncio import Redis

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from integrations.qdrant_client import QdrantClient
from integrations.neo4j_client import Neo4jClient

logger = structlog.get_logger()

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

def get_env_config():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è."""
    return {
        'database_url': os.getenv("DATABASE_URL", "postgresql://postgres:postgres@supabase-db:5432/postgres"),
        'redis_url': os.getenv("REDIS_URL", "redis://redis:6379"),
        'qdrant_url': os.getenv("QDRANT_URL", "http://qdrant:6333"),
        'neo4j_uri': os.getenv("NEO4J_URI", "neo4j://neo4j:7687"),
        'neo4j_user': os.getenv("NEO4J_USER", "neo4j"),
        'neo4j_password': os.getenv("NEO4J_PASSWORD", "changeme"),
    }

# ============================================================================
# –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê
# ============================================================================

class PostDiagnostic:
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Å—Ç–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ."""
    
    def __init__(self, config: Dict[str, str]):
        self.config = config
        self.qdrant_client: Optional[QdrantClient] = None
        self.neo4j_client: Optional[Neo4jClient] = None
        self.redis_client: Optional[Redis] = None
        self.results: Dict[str, Any] = {}
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤."""
        try:
            # Qdrant
            self.qdrant_client = QdrantClient(self.config['qdrant_url'])
            await self.qdrant_client.connect()
            
            # Neo4j
            self.neo4j_client = Neo4jClient(
                uri=self.config['neo4j_uri'],
                username=self.config['neo4j_user'],
                password=self.config['neo4j_password']
            )
            await self.neo4j_client.connect()
            
            # Redis
            self.redis_client = Redis.from_url(
                self.config['redis_url'],
                decode_responses=True
            )
            
            logger.info("Diagnostic clients initialized")
            
        except Exception as e:
            logger.error("Failed to initialize clients", error=str(e))
            raise
    
    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤."""
        if self.neo4j_client:
            await self.neo4j_client.close()
        if self.redis_client:
            await self.redis_client.close()
    
    async def diagnose(self, post_id: str) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Å—Ç–∞.
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞
        """
        self.results = {
            'post_id': post_id,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'checks': {}
        }
        
        try:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –ë–î
            await self._check_post_in_db(post_id)
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–≥–æ–≤
            await self._check_tags(post_id)
            
            # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ enrichment –¥–∞–Ω–Ω—ã—Ö
            await self._check_enrichment(post_id)
            
            # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            await self._check_indexing_status(post_id)
            
            # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ Qdrant
            await self._check_qdrant(post_id)
            
            # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ Neo4j
            await self._check_neo4j(post_id)
            
            # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–±—ã—Ç–∏–π –≤ Redis streams
            await self._check_redis_streams(post_id)
            
            # 8. –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
            self.results['summary'] = self._generate_summary()
            
        except Exception as e:
            logger.error("Diagnostic failed", post_id=post_id, error=str(e))
            self.results['error'] = str(e)
        
        return self.results
    
    async def _check_post_in_db(self, post_id: str):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å—Ç–∞ –≤ –ë–î."""
        try:
            conn = psycopg2.connect(self.config['database_url'])
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            cursor.execute("""
                SELECT 
                    p.id,
                    p.channel_id,
                    p.content,
                    p.telegram_message_id,
                    p.created_at,
                    p.is_processed,
                    c.title as channel_title,
                    c.settings->>'tenant_id' as tenant_id
                FROM posts p
                JOIN channels c ON p.channel_id = c.id
                WHERE p.id = %s
            """, (post_id,))
            
            row = cursor.fetchone()
            cursor.close()
            conn.close()
            
            if row:
                self.results['checks']['post_in_db'] = {
                    'found': True,
                    'data': dict(row),
                    'tenant_id': str(row['tenant_id']),
                    'channel_id': str(row['channel_id']),
                    'is_processed': row['is_processed']
                }
            else:
                self.results['checks']['post_in_db'] = {
                    'found': False,
                    'error': 'Post not found in database'
                }
                
        except Exception as e:
            self.results['checks']['post_in_db'] = {
                'found': False,
                'error': str(e)
            }
    
    async def _check_tags(self, post_id: str):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–≥–æ–≤ –≤ post_enrichment."""
        try:
            conn = psycopg2.connect(self.config['database_url'])
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            cursor.execute("""
                SELECT 
                    data,
                    tags,
                    status,
                    provider,
                    updated_at
                FROM post_enrichment
                WHERE post_id = %s AND kind = 'tags'
                ORDER BY updated_at DESC
                LIMIT 1
            """, (post_id,))
            
            row = cursor.fetchone()
            cursor.close()
            conn.close()
            
            if row:
                tags_data = row['data']
                if isinstance(tags_data, str):
                    tags_data = json.loads(tags_data)
                
                tags_list = tags_data.get('tags', []) if tags_data else (row['tags'] or [])
                
                self.results['checks']['tags'] = {
                    'found': True,
                    'tags': tags_list if isinstance(tags_list, list) else [],
                    'tags_count': len(tags_list) if isinstance(tags_list, list) else 0,
                    'status': row['status'],
                    'provider': row['provider'],
                    'updated_at': row['updated_at'].isoformat() if row['updated_at'] else None,
                    'has_data': bool(tags_data)
                }
            else:
                self.results['checks']['tags'] = {
                    'found': False,
                    'error': 'Tags not found in post_enrichment'
                }
                
        except Exception as e:
            self.results['checks']['tags'] = {
                'found': False,
                'error': str(e)
            }
    
    async def _check_enrichment(self, post_id: str):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ enrichment –¥–∞–Ω–Ω—ã—Ö (vision, crawl)."""
        try:
            conn = psycopg2.connect(self.config['database_url'])
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            cursor.execute("""
                SELECT 
                    kind,
                    data,
                    status,
                    provider,
                    updated_at
                FROM post_enrichment
                WHERE post_id = %s AND kind IN ('vision', 'crawl')
                ORDER BY kind, updated_at DESC
            """, (post_id,))
            
            rows = cursor.fetchall()
            cursor.close()
            conn.close()
            
            enrichment = {
                'vision': None,
                'crawl': None
            }
            
            for row in rows:
                if not row:
                    continue
                kind = row.get('kind')
                if not kind:
                    continue
                data = row.get('data')
                if isinstance(data, str):
                    try:
                        data = json.loads(data)
                    except:
                        data = None
                
                enrichment[kind] = {
                    'found': True,
                    'status': row.get('status'),
                    'provider': row.get('provider'),
                    'updated_at': row.get('updated_at').isoformat() if row.get('updated_at') else None,
                    'has_data': bool(data),
                    'data_keys': list(data.keys()) if data and isinstance(data, dict) else []
                }
            
            self.results['checks']['enrichment'] = enrichment
            
        except Exception as e:
            self.results['checks']['enrichment'] = {
                'error': str(e)
            }
    
    async def _check_indexing_status(self, post_id: str):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."""
        try:
            conn = psycopg2.connect(self.config['database_url'])
            cursor = conn.cursor(cursor_factory=RealDictCursor)
            
            cursor.execute("""
                SELECT 
                    embedding_status,
                    graph_status,
                    vector_id,
                    error_message,
                    processing_started_at,
                    processing_completed_at
                FROM indexing_status
                WHERE post_id = %s
            """, (post_id,))
            
            row = cursor.fetchone()
            cursor.close()
            conn.close()
            
            if row:
                self.results['checks']['indexing_status'] = {
                    'found': True,
                    'embedding_status': row['embedding_status'],
                    'graph_status': row['graph_status'],
                    'vector_id': row['vector_id'],
                    'error_message': row['error_message'],
                    'processing_started_at': row['processing_started_at'].isoformat() if row['processing_started_at'] else None,
                    'processing_completed_at': row['processing_completed_at'].isoformat() if row['processing_completed_at'] else None,
                    'is_completed': (row['embedding_status'] == 'completed' and row['graph_status'] == 'completed')
                }
            else:
                self.results['checks']['indexing_status'] = {
                    'found': False,
                    'error': 'Indexing status not found'
                }
                
        except Exception as e:
            self.results['checks']['indexing_status'] = {
                'found': False,
                'error': str(e)
            }
    
    async def _check_qdrant(self, post_id: str):
        """
        Context7 best practice: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤ Qdrant —á–µ—Ä–µ–∑ scroll —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ post_id.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ–º scroll –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ—á–∫–∏ –ø–æ payload.post_id, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –Ω–∞–¥—ë–∂–Ω–µ–µ,
        —á–µ–º –ø—Ä—è–º–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ ID (ID –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ).
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º tenant_id –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ë–î
            tenant_id = None
            if 'post_in_db' in self.results['checks']:
                post_check = self.results['checks']['post_in_db']
                if post_check.get('found'):
                    tenant_id = post_check.get('tenant_id') or post_check.get('data', {}).get('tenant_id')
            
            # –ï—Å–ª–∏ tenant_id –∏–∑–≤–µ—Å—Ç–µ–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é
            collections_to_check = []
            if tenant_id:
                collections_to_check.append(f"t{tenant_id}_posts")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –ø–æ—Å—Ç–æ–≤
                collections = self.qdrant_client.client.get_collections()
                collections_to_check = [
                    col.name for col in collections.collections
                    if (col.name.startswith('t') and col.name.endswith('_posts')) or
                       (col.name.startswith('user_') and col.name.endswith('_posts'))
                ]
            
            qdrant_found = False
            qdrant_data = None
            collection_name = None
            
            for coll_name in collections_to_check:
                try:
                    # Context7: –ò—Å–ø–æ–ª—å–∑—É–µ–º scroll —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ post_id –≤ payload
                    from qdrant_client.http import models
                    
                    scroll_filter = models.Filter(
                        must=[
                            models.FieldCondition(
                                key="post_id",
                                match=models.MatchValue(value=post_id)
                            )
                        ]
                    )
                    
                    scroll_result = self.qdrant_client.client.scroll(
                        collection_name=coll_name,
                        scroll_filter=scroll_filter,
                        limit=1
                    )
                    
                    points, _ = scroll_result
                    
                    if points:
                        point = points[0]
                        qdrant_found = True
                        collection_name = coll_name
                        qdrant_data = {
                            'vector_id': str(point.id),
                            'payload': point.payload,
                            'has_vector': point.vector is not None,
                            'vector_dim': len(point.vector) if point.vector else 0,
                            'payload_keys': list(point.payload.keys()) if point.payload else [],
                            'collection': coll_name
                        }
                        break
                        
                except Exception as e:
                    logger.debug("Qdrant check failed for collection",
                               collection=coll_name,
                               post_id=post_id,
                               error=str(e))
                    continue
            
            self.results['checks']['qdrant'] = {
                'found': qdrant_found,
                'data': qdrant_data,
                'collections_checked': len(collections_to_check)
            }
            
            if not qdrant_found:
                self.results['checks']['qdrant']['error'] = 'Post not found in Qdrant'
                
        except Exception as e:
            self.results['checks']['qdrant'] = {
                'found': False,
                'error': str(e)
            }
    
    async def _check_neo4j(self, post_id: str):
        """
        Context7 best practice: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤ Neo4j —á–µ—Ä–µ–∑ MATCH –ø–æ post_id property.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.
        """
        try:
            if not self.neo4j_client or not self.neo4j_client._driver:
                self.results['checks']['neo4j'] = {
                    'found': False,
                    'error': 'Neo4j client not initialized'
                }
                return
            
            async with self.neo4j_client._driver.session() as session:
                # Context7: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                result = await session.run(
                    "MATCH (p:Post {post_id: $post_id}) RETURN p, p.post_id as post_id, p.tenant_id as tenant_id, p.channel_id as channel_id, p.indexed_at as indexed_at",
                    post_id=post_id
                )
                
                record = await result.single()
                
                if record:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑–∏ —Å —Ç–µ–≥–∞–º–∏
                    tags_result = await session.run(
                        "MATCH (p:Post {post_id: $post_id})-[:TAGGED_AS]->(t:Tag) RETURN t.name as tag_name ORDER BY tag_name",
                        post_id=post_id
                    )
                    tags = [r['tag_name'] for r in await tags_result.data()]
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
                    images_result = await session.run(
                        "MATCH (p:Post {post_id: $post_id})-[:HAS_IMAGE]->(img:Image) RETURN img.sha256 as sha256, img.s3_key as s3_key LIMIT 5",
                        post_id=post_id
                    )
                    images = await images_result.data()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–≤—è–∑–∏ —Å –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                    webpages_result = await session.run(
                        "MATCH (p:Post {post_id: $post_id})-[:REFERS_TO]->(wp:WebPage) RETURN wp.url as url LIMIT 5",
                        post_id=post_id
                    )
                    webpages = await webpages_result.data()
                    
                    self.results['checks']['neo4j'] = {
                        'found': True,
                        'data': {
                            'post_id': record.get('post_id'),
                            'tenant_id': record.get('tenant_id'),
                            'channel_id': record.get('channel_id'),
                            'indexed_at': record.get('indexed_at'),
                            'tags_count': len(tags),
                            'tags': tags[:10],  # –ü–µ—Ä–≤—ã–µ 10 —Ç–µ–≥–æ–≤
                            'images_count': len(images),
                            'images': images,
                            'webpages_count': len(webpages),
                            'webpages': [w['url'] for w in webpages[:5]]
                        }
                    }
                else:
                    self.results['checks']['neo4j'] = {
                        'found': False,
                        'error': 'Post not found in Neo4j'
                    }
                    
        except Exception as e:
            self.results['checks']['neo4j'] = {
                'found': False,
                'error': str(e)
            }
    
    async def _check_redis_streams(self, post_id: str):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–±—ã—Ç–∏–π –≤ Redis streams."""
        try:
            from event_bus import STREAMS
            
            streams_to_check = {
                'posts.tagged': STREAMS.get('posts.tagged', 'stream:posts:tagged'),
                'posts.enriched': STREAMS.get('posts.enriched', 'stream:posts:enriched'),
                'posts.indexed': STREAMS.get('posts.indexed', 'stream:posts:indexed')
            }
            
            stream_results = {}
            
            for stream_name, stream_key in streams_to_check.items():
                try:
                    # –ò—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Å post_id –≤ –¥–∞–Ω–Ω—ã—Ö
                    # –ß–∏—Ç–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —Å–æ–æ–±—â–µ–Ω–∏–π
                    messages = await self.redis_client.xrevrange(
                        stream_key,
                        count=1000,
                        max='+',
                        min='-'
                    )
                    
                    found_messages = []
                    for msg_id, fields in messages:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ post_id –≤ –ø–æ–ª—è—Ö
                        if 'post_id' in fields and fields['post_id'] == post_id:
                            # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —ç—Ç–æ JSON
                            data = {}
                            if 'data' in fields:
                                try:
                                    data = json.loads(fields['data'])
                                except:
                                    data = {'raw': fields['data']}
                            elif 'payload' in fields:
                                try:
                                    data = json.loads(fields['payload'])
                                except:
                                    data = {'raw': fields['payload']}
                            else:
                                data = fields
                            
                            found_messages.append({
                                'message_id': msg_id,
                                'timestamp': msg_id.split('-')[0] if '-' in msg_id else None,
                                'data': data
                            })
                    
                    stream_results[stream_name] = {
                        'found': len(found_messages) > 0,
                        'messages_count': len(found_messages),
                        'messages': found_messages[:5]  # –ü–µ—Ä–≤—ã–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
                    }
                    
                except Exception as e:
                    stream_results[stream_name] = {
                        'found': False,
                        'error': str(e)
                    }
            
            self.results['checks']['redis_streams'] = stream_results
            
        except Exception as e:
            self.results['checks']['redis_streams'] = {
                'error': str(e)
            }
    
    def _generate_summary(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏."""
        checks = self.results['checks']
        
        summary = {
            'post_exists': checks.get('post_in_db', {}).get('found', False),
            'has_tags': checks.get('tags', {}).get('found', False) and checks.get('tags', {}).get('tags_count', 0) > 0,
            'has_enrichment': (
                checks.get('enrichment', {}).get('vision', {}).get('found', False) or
                checks.get('enrichment', {}).get('crawl', {}).get('found', False)
            ),
            'is_indexed_qdrant': checks.get('qdrant', {}).get('found', False),
            'is_indexed_neo4j': checks.get('neo4j', {}).get('found', False),
            'indexing_completed': checks.get('indexing_status', {}).get('is_completed', False),
            'has_events': any(
                s.get('found', False) 
                for s in checks.get('redis_streams', {}).values() 
                if isinstance(s, dict)
            )
        }
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
        issues = []
        if not summary['post_exists']:
            issues.append('Post not found in database')
        if not summary['has_tags']:
            issues.append('No tags found in post_enrichment')
        if not summary['is_indexed_qdrant']:
            issues.append('Post not indexed in Qdrant')
        if not summary['is_indexed_neo4j']:
            issues.append('Post not indexed in Neo4j')
        if not summary['indexing_completed']:
            indexing_status = checks.get('indexing_status', {})
            if indexing_status.get('found'):
                issues.append(f"Indexing incomplete: embedding={indexing_status.get('embedding_status')}, graph={indexing_status.get('graph_status')}")
            else:
                issues.append('Indexing status not found')
        
        summary['issues'] = issues
        summary['pipeline_status'] = 'complete' if not issues else 'stuck'
        summary['pipeline_stage'] = self._determine_stage()
        
        return summary
    
    def _determine_stage(self) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç—Ç–∞–ø–∞, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –∑–∞—Å—Ç—Ä—è–ª –ø–∞–π–ø–ª–∞–π–Ω."""
        checks = self.results['checks']
        
        if not checks.get('post_in_db', {}).get('found'):
            return 'not_started'
        
        if not checks.get('tags', {}).get('found'):
            return 'tagging'
        
        if not checks.get('enrichment', {}).get('crawl', {}).get('found'):
            return 'enrichment'
        
        if not checks.get('indexing_status', {}).get('found'):
            return 'indexing_pending'
        
        indexing_status = checks.get('indexing_status', {})
        if indexing_status.get('embedding_status') != 'completed':
            return 'indexing_embeddings'
        
        if indexing_status.get('graph_status') != 'completed':
            return 'indexing_graph'
        
        if not checks.get('qdrant', {}).get('found'):
            return 'qdrant_indexing'
        
        if not checks.get('neo4j', {}).get('found'):
            return 'neo4j_indexing'
        
        return 'complete'


# ============================================================================
# MAIN
# ============================================================================

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(description='–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Å—Ç–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ')
    parser.add_argument('post_id', help='ID –ø–æ—Å—Ç–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏')
    parser.add_argument('--json', action='store_true', help='–í—ã–≤–æ–¥ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ')
    parser.add_argument('--compact', action='store_true', help='–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –≤—ã–≤–æ–¥ (—Ç–æ–ª—å–∫–æ summary)')
    
    args = parser.parse_args()
    
    config = get_env_config()
    diagnostic = PostDiagnostic(config)
    
    try:
        await diagnostic.initialize()
        results = await diagnostic.diagnose(args.post_id)
        
        if args.compact:
            # –¢–æ–ª—å–∫–æ summary
            print(json.dumps(results.get('summary', {}), indent=2, ensure_ascii=False))
        elif args.json:
            # –ü–æ–ª–Ω—ã–π JSON
            print(json.dumps(results, indent=2, ensure_ascii=False, default=str))
        else:
            # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –≤—ã–≤–æ–¥
            _print_human_readable(results)
            
    except Exception as e:
        logger.error("Diagnostic failed", error=str(e))
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}", file=sys.stderr)
        sys.exit(1)
    finally:
        await diagnostic.close()


def _print_human_readable(results: Dict[str, Any]):
    """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
    post_id = results.get('post_id', 'unknown')
    checks = results.get('checks', {})
    summary = results.get('summary', {})
    
    if not summary:
        summary = {}
    
    print(f"\n{'='*60}")
    print(f"–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ—Å—Ç–∞: {post_id}")
    print(f"{'='*60}\n")
    
    # Post in DB
    post_check = checks.get('post_in_db', {})
    status = "‚úÖ" if post_check.get('found') else "‚ùå"
    print(f"{status} –ë–î: {'–ù–∞–π–¥–µ–Ω' if post_check.get('found') else '–ù–µ –Ω–∞–π–¥–µ–Ω'}")
    if post_check.get('found'):
        data = post_check.get('data', {})
        print(f"   - Tenant ID: {data.get('tenant_id', 'N/A')}")
        print(f"   - Channel ID: {data.get('channel_id', 'N/A')}")
        print(f"   - Is Processed: {data.get('is_processed', False)}")
        print(f"   - Created: {data.get('created_at', 'N/A')}")
    
    # Tags
    tags_check = checks.get('tags', {})
    status = "‚úÖ" if tags_check.get('found') and tags_check.get('tags_count', 0) > 0 else "‚ùå"
    print(f"\n{status} –¢–µ–≥–∏: {'–ù–∞–π–¥–µ–Ω—ã' if tags_check.get('found') else '–ù–µ –Ω–∞–π–¥–µ–Ω—ã'}")
    if tags_check.get('found'):
        print(f"   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {tags_check.get('tags_count', 0)}")
        tags = tags_check.get('tags', [])
        if tags:
            print(f"   - –ü—Ä–∏–º–µ—Ä—ã: {', '.join(tags[:5])}")
        print(f"   - –°—Ç–∞—Ç—É—Å: {tags_check.get('status', 'N/A')}")
        print(f"   - Provider: {tags_check.get('provider', 'N/A')}")
    
    # Enrichment
    enrichment = checks.get('enrichment', {})
    print(f"\nüìä Enrichment –¥–∞–Ω–Ω—ã–µ:")
    for kind in ['vision', 'crawl']:
        kind_data = enrichment.get(kind) or {}
        if isinstance(kind_data, dict):
            status = "‚úÖ" if kind_data.get('found') else "‚ö™"
            print(f"   {status} {kind.upper()}: {'–ù–∞–π–¥–µ–Ω–æ' if kind_data.get('found') else '–ù–µ –Ω–∞–π–¥–µ–Ω–æ'}")
            if kind_data.get('found'):
                print(f"      - –°—Ç–∞—Ç—É—Å: {kind_data.get('status', 'N/A')}")
                print(f"      - Provider: {kind_data.get('provider', 'N/A')}")
                print(f"      - –ö–ª—é—á–∏ –¥–∞–Ω–Ω—ã—Ö: {', '.join(kind_data.get('data_keys', [])[:5])}")
        else:
            print(f"   ‚ö™ {kind.upper()}: –ù–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # Indexing Status
    indexing = checks.get('indexing_status', {})
    status = "‚úÖ" if indexing.get('is_completed') else "‚ùå"
    print(f"\n{status} –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {'–ó–∞–≤–µ—Ä—à–µ–Ω–∞' if indexing.get('is_completed') else '–ù–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞'}")
    if indexing.get('found'):
        print(f"   - Embedding: {indexing.get('embedding_status', 'N/A')}")
        print(f"   - Graph: {indexing.get('graph_status', 'N/A')}")
        if indexing.get('vector_id'):
            print(f"   - Vector ID: {indexing.get('vector_id')}")
        if indexing.get('error_message'):
            print(f"   - –û—à–∏–±–∫–∞: {indexing.get('error_message')}")
    
    # Qdrant
    qdrant = checks.get('qdrant', {})
    status = "‚úÖ" if qdrant.get('found') else "‚ùå"
    print(f"\n{status} Qdrant: {'–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω' if qdrant.get('found') else '–ù–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω'}")
    if qdrant.get('found'):
        data = qdrant.get('data', {})
        print(f"   - Collection: {data.get('collection', 'N/A')}")
        print(f"   - Vector ID: {data.get('vector_id', 'N/A')}")
        print(f"   - Vector dimension: {data.get('vector_dim', 0)}")
        print(f"   - Payload keys: {', '.join(data.get('payload_keys', [])[:10])}")
    
    # Neo4j
    neo4j = checks.get('neo4j', {})
    status = "‚úÖ" if neo4j.get('found') else "‚ùå"
    print(f"\n{status} Neo4j: {'–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω' if neo4j.get('found') else '–ù–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω'}")
    if neo4j.get('found'):
        data = neo4j.get('data', {})
        print(f"   - Tags –≤ –≥—Ä–∞—Ñ–µ: {data.get('tags_count', 0)}")
        print(f"   - Images: {data.get('images_count', 0)}")
        print(f"   - WebPages: {data.get('webpages_count', 0)}")
        if data.get('tags'):
            print(f"   - –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–≥–æ–≤: {', '.join(data.get('tags', [])[:5])}")
    
    # Redis Streams
    streams = checks.get('redis_streams', {})
    print(f"\nüì® –°–æ–±—ã—Ç–∏—è –≤ Redis streams:")
    for stream_name, stream_data in streams.items():
        if isinstance(stream_data, dict):
            status = "‚úÖ" if stream_data.get('found') else "‚ö™"
            count = stream_data.get('messages_count', 0)
            print(f"   {status} {stream_name}: {count} —Å–æ–æ–±—â–µ–Ω–∏–π")
    
            # Summary
    print(f"\n{'='*60}")
    print("–°–≤–æ–¥–∫–∞:")
    print(f"{'='*60}")
    if summary:
        print(f"–°—Ç–∞—Ç—É—Å –ø–∞–π–ø–ª–∞–π–Ω–∞: {summary.get('pipeline_status', 'unknown')}")
        print(f"–≠—Ç–∞–ø: {summary.get('pipeline_stage', 'unknown')}")
        
        if summary.get('issues'):
            print(f"\n‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:")
            for issue in summary['issues']:
                print(f"   - {issue}")
        else:
            print(f"\n‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    else:
        print("‚ö†Ô∏è Summary –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫")
    
    print()


if __name__ == "__main__":
    asyncio.run(main())

