"""
Digest Service –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π
Context7: —Å–±–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¢–û–õ–¨–ö–û –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Ç–µ–º–∞—Ç–∏–∫–∞–º –∏–∑ digest_settings.topics
"""

import time
from typing import List, Dict, Any, Optional
from uuid import UUID
from datetime import datetime, date, timezone

import structlog
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, func
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, MatchAny
from langchain_gigachat import GigaChat
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel
from langchain_core.output_parsers import StrOutputParser
from pydantic import BaseModel

from models.database import Post, PostEnrichment, Channel, User, DigestSettings, DigestHistory, UserChannel
from services.rag_service import RAGService  # –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ embedding
from services.graph_service import get_graph_service
from config import settings

logger = structlog.get_logger()

# ============================================================================
# PYDANTIC MODELS
# ============================================================================

class DigestContent(BaseModel):
    """–ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞."""
    content: str
    posts_count: int
    topics: List[str]
    sections: List[Dict[str, Any]]  # –°–µ–∫—Ü–∏–∏ –ø–æ —Ç–µ–º–∞–º


# ============================================================================
# DIGEST SERVICE
# ============================================================================

class DigestService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤."""
    
    def __init__(
        self,
        qdrant_url: str,
        qdrant_client: Optional[QdrantClient] = None,
        openai_api_base: Optional[str] = None,
        graph_service: Optional[Any] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Digest Service.
        
        Args:
            qdrant_url: URL Qdrant —Å–µ—Ä–≤–∏—Å–∞
            qdrant_client: Qdrant –∫–ª–∏–µ–Ω—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            openai_api_base: URL gpt2giga-proxy
            graph_service: GraphService –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Neo4j (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.qdrant_url = qdrant_url
        self.qdrant_client = qdrant_client or QdrantClient(url=qdrant_url)
        
        # Context7: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GraphService –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ–º
        self.graph_service = graph_service or get_graph_service()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GigaChat LLM —á–µ—Ä–µ–∑ langchain-gigachat
        # Context7: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω URL (–±–µ–∑ /v1) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤ –ø—Ä–æ–∫—Å–∏
        api_base = openai_api_base or settings.openai_api_base or "http://gpt2giga-proxy:8090"
        
        import os
        os.environ.setdefault("OPENAI_API_BASE", api_base)
        
        self.llm = GigaChat(
            credentials=getattr(settings, 'gigachat_credentials', '') or os.getenv('GIGACHAT_CREDENTIALS', ''),
            scope=getattr(settings, 'gigachat_scope', None) or os.getenv('GIGACHAT_SCOPE', 'GIGACHAT_API_PERS'),
            model="GigaChat",
            base_url=api_base,
            temperature=0.7,
        )
        
        # Context7: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å executive summary –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–µ—Ä—Å—Ç–∫–æ–π
        self.digest_prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤.

–°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤, —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —Ç–µ–º–∞–º.

–°–¢–†–£–ö–¢–£–†–ê –î–ê–ô–î–ñ–ï–°–¢–ê:

1. **EXECUTIVE SUMMARY** (–≤ –Ω–∞—á–∞–ª–µ):
   - –ö—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏ –Ω–∞ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –Ω–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ, –≥–ª–∞–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã, –∫–ª—é—á–µ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è
   - –í—ã–¥–µ–ª–∏ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏

2. **–¢–ï–ú–ê–¢–ò–ß–ï–°–ö–ò–ï –ë–õ–û–ö–ò**:
   - –ö–∞–∂–¥–∞—è —Ç–µ–º–∞ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º ## –¢–µ–º–∞: [–ù–∞–∑–≤–∞–Ω–∏–µ]
   - –ú–µ–∂–¥—É –±–ª–æ–∫–∞–º–∏ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
   - –í –∫–∞–∂–¥–æ–º –±–ª–æ–∫–µ 3-5 –∫–ª—é—á–µ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π

3. **–§–û–†–ú–ê–¢ –ù–û–í–û–°–¢–ò**:
   - **–ó–∞–≥–æ–ª–æ–≤–æ–∫**: –∫—Ä–∞—Ç–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ (1 —Å—Ç—Ä–æ–∫–∞)
   - **–°—É—Ç—å**: 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π (—á—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ, –ø–æ—á–µ–º—É –≤–∞–∂–Ω–æ)
   - **–ú–µ—Ç—Ä–∏–∫–∏**: [–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: X%] –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö
   - **–°—Å—ã–ª–∫–∞**: [–ö–∞–Ω–∞–ª](—Å—Å—ã–ª–∫–∞) –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç

–í–ê–ñ–ù–û:
- –í–°–ï–ì–î–ê –Ω–∞—á–∏–Ω–∞–π —Å Executive Summary
- –í–°–ï–ì–î–ê –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –º–µ–∂–¥—É —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –±–ª–æ–∫–∞–º–∏
- –î–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ—Å—Ç–∏ –¥–∞–≤–∞–π –Ω–µ —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫, –Ω–æ –∏ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å—É—Ç–∏
- –ò—Å–ø–æ–ª—å–∑—É–π –º–µ—Ç—Ä–∏–∫–∏ (üëÅÔ∏è –ø—Ä–æ—Å–º–æ—Ç—Ä—ã, ‚ù§Ô∏è —Ä–µ–∞–∫—Ü–∏–∏, ‚Ü™Ô∏è —Ä–µ–ø–æ—Å—Ç—ã, üí¨ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏
- –í–°–ï–ì–î–ê –≤–∫–ª—é—á–∞–π —Å—Å—ã–ª–∫—É –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ—Å—Ç–∏

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:

## üìä Executive Summary

[2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –≥–ª–∞–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã, –Ω–∞ —á—Ç–æ –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ, –∫–ª—é—á–µ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è]

## –¢–µ–º–∞ 1: [–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã]

**–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ 1**
–°—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏: [1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π] [–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: X%] [–ö–∞–Ω–∞–ª](—Å—Å—ã–ª–∫–∞)

**–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ 2**
–°—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏: [1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π] [–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: X%] [–ö–∞–Ω–∞–ª](—Å—Å—ã–ª–∫–∞)

**–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ 3**
–°—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏: [1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π] [–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: X%] [–ö–∞–Ω–∞–ª](—Å—Å—ã–ª–∫–∞)


## –¢–µ–º–∞ 2: [–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã]

**–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ 1**
–°—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏: [1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π] [–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: X%] [–ö–∞–Ω–∞–ª](—Å—Å—ã–ª–∫–∞)

**–ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏ 2**
–°—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏: [1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π] [–ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: X%] [–ö–∞–Ω–∞–ª](—Å—Å—ã–ª–∫–∞)

...

–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤. –°—Å—ã–ª–∫–∏ –Ω–∞ –ø–æ—Å—Ç—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–π –Ω–æ–≤–æ—Å—Ç–∏."""),
            ("human", "–ü–æ—Å—Ç—ã –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞:\n{context}\n\n–¢–µ–º—ã: {topics}\n\n–°–æ–∑–¥–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç —Å Executive Summary, –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –∏ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:")
        ])
        
        logger.info("Digest Service initialized", qdrant_url=qdrant_url)
    
    async def _generate_embedding(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ GigaChat."""
        try:
            import requests
            import os
            
            proxy_url = getattr(settings, 'gigachat_proxy_url', None) or os.getenv("GIGACHAT_PROXY_URL", "http://gpt2giga-proxy:8090")
            url = f"{proxy_url}/v1/embeddings"
            
            credentials = os.getenv("GIGACHAT_CREDENTIALS")
            scope = os.getenv("GIGACHAT_SCOPE", "GIGACHAT_API_PERS")
            auth_header = f"giga-cred-{credentials}:{scope}"
            
            response = requests.post(
                url,
                json={
                    "input": text,
                    "model": "any"  # gpt2giga —Å–∞–º –æ—Ç–ø—Ä–∞–≤–∏—Ç –Ω–∞ EmbeddingsGigaR
                },
                headers={
                    "Authorization": f"Bearer {auth_header}",
                    "Content-Type": "application/json"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'data' in data and len(data['data']) > 0:
                    embedding = data['data'][0].get('embedding', [])
                    return embedding
            
            logger.warning("Failed to generate embedding", status_code=response.status_code)
            return []
        
        except Exception as e:
            logger.error("Error generating embedding", error=str(e))
            return []
    
    async def _collect_posts_by_topics(
        self,
        topics: List[str],
        tenant_id: str,
        user_id: UUID,
        channel_ids: Optional[List[str]] = None,
        limit_per_topic: int = 10,
        db: Optional[Session] = None
    ) -> List[Dict[str, Any]]:
        """
        –°–±–æ—Ä –ø–æ—Å—Ç–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Ç–µ–º–∞—Ç–∏–∫–∞–º.
        
        Context7: –¢–û–õ–¨–ö–û –ø–æ —Ç–µ–º–∞–º –∏–∑ digest_settings.topics, –Ω–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑.
        """
        if not db:
            return []
        
        all_posts = []
        
        # –î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —Å–æ–±–∏—Ä–∞–µ–º –ø–æ—Å—Ç—ã
        for topic in topics:
            try:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embedding –¥–ª—è —Ç–µ–º—ã
                topic_embedding = await self._generate_embedding(topic)
                
                if topic_embedding:
                    # –ü–æ–∏—Å–∫ –≤ Qdrant –ø–æ —Ç–µ–º–µ
                    collection_name = f"t{tenant_id}_posts"
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                    collections = self.qdrant_client.get_collections()
                    if collection_name not in [c.name for c in collections.collections]:
                        logger.warning("Qdrant collection not found", collection=collection_name)
                        continue
                    
                    # –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞–Ω–∞–ª–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
                    filter_conditions = []
                    filter_conditions.append(
                        FieldCondition(
                            key="tenant_id",
                            match=MatchValue(value=str(tenant_id))
                        )
                    )
                    
                    if channel_ids:
                        filter_conditions.append(
                            FieldCondition(
                                key="channel_id",
                                match=MatchAny(any=[str(cid) for cid in channel_ids])
                            )
                        )
                    
                    search_filter = Filter(must=filter_conditions) if filter_conditions else None
                    
                    # –ü–æ–∏—Å–∫ –≤ Qdrant
                    search_results = self.qdrant_client.search(
                        collection_name=collection_name,
                        query_vector=topic_embedding,
                        query_filter=search_filter,
                        limit=limit_per_topic
                    )
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç–æ–≤ –∏–∑ –ë–î
                    for result in search_results:
                        post_id = result.payload.get('post_id')
                        if post_id:
                            post = db.query(Post).filter(Post.id == post_id).first()
                            if post:
                                channel = db.query(Channel).filter(Channel.id == post.channel_id).first()
                                
                                all_posts.append({
                                    'post_id': str(post_id),
                                    'content': post.content or "",
                                    'channel_title': channel.title if channel else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–Ω–∞–ª",
                                    'channel_username': channel.username if channel else None,
                                    'permalink': post.telegram_post_url,
                                    'posted_at': post.posted_at,
                                    'topic': topic,
                                    'score': result.score,
                                    # Context7: –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ
                                    'engagement_score': float(post.engagement_score) if post.engagement_score else 0.0,
                                    'views_count': post.views_count or 0,
                                    'reactions_count': post.reactions_count or 0,
                                    'forwards_count': post.forwards_count or 0,
                                    'replies_count': post.replies_count or 0
                                })
                
                # Context7: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Neo4j –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ–º —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
                try:
                    if await self.graph_service.health_check():
                        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–º—ã —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
                        similar_topics = await self.graph_service.find_similar_topics(topic, limit=3)
                        
                        # –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–∏—Å–∫ –ø–æ —Å–≤—è–∑–∞–Ω–Ω—ã–º —Ç–µ–º–∞–º
                        related_topics = [topic] + [st['topic'] for st in similar_topics if st.get('similarity', 0) > 0.6]
                        
                        # –ü–æ–∏—Å–∫ –ø–æ—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ –¥–ª—è –∫–∞–∂–¥–æ–π —Å–≤—è–∑–∞–Ω–Ω–æ–π —Ç–µ–º—ã
                        for related_topic in related_topics:
                            graph_posts = await self.graph_service.search_related_posts(
                                query=related_topic,
                                topic=related_topic,
                                limit=limit_per_topic // len(related_topics),
                                max_depth=getattr(settings, 'neo4j_max_graph_depth', 2)
                            )
                            
                            for graph_post in graph_posts:
                                post_id = graph_post.get('post_id')
                                if post_id:
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –ª–∏ —É–∂–µ
                                    if not any(p['post_id'] == str(post_id) for p in all_posts):
                                        post = db.query(Post).filter(Post.id == UUID(post_id)).first()
                                        if post:
                                            # –§–∏–ª—å—Ç—Ä –ø–æ –∫–∞–Ω–∞–ª–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã)
                                            if channel_ids and str(post.channel_id) not in channel_ids:
                                                continue
                                            
                                            channel = db.query(Channel).filter(Channel.id == post.channel_id).first()
                                            
                                            all_posts.append({
                                                'post_id': str(post_id),
                                                'content': graph_post.get('content', post.content or ""),
                                                'channel_title': channel.title if channel else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–Ω–∞–ª",
                                                'channel_username': channel.username if channel else None,
                                                'permalink': post.telegram_post_url,
                                                'posted_at': post.posted_at,
                                                'topic': related_topic,
                                                'score': graph_post.get('score', 0.7),
                                                'related_topic': related_topic != topic,  # –§–ª–∞–≥ —Å–≤—è–∑–∞–Ω–Ω–æ–π —Ç–µ–º—ã
                                                # Context7: –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
                                                'engagement_score': float(post.engagement_score) if post.engagement_score else 0.0,
                                                'views_count': post.views_count or 0,
                                                'reactions_count': post.reactions_count or 0,
                                                'forwards_count': post.forwards_count or 0,
                                                'replies_count': post.replies_count or 0
                                            })
                except Exception as e:
                    logger.warning("GraphRAG search failed in digest, continuing without graph", error=str(e))
                
                # –¢–∞–∫–∂–µ –∏—â–µ–º —á–µ—Ä–µ–∑ PostgreSQL FTS –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ —Å–ª–æ–≤–∞–º —Ç–µ–º—ã
                topic_words = topic.split()
                fts_query = db.query(Post).join(Channel).filter(
                    and_(
                        Post.content.isnot(None),
                        or_(*[Post.content.ilike(f"%{word}%") for word in topic_words])
                    )
                )
                
                if channel_ids:
                    fts_query = fts_query.filter(Post.channel_id.in_([UUID(cid) for cid in channel_ids]))
                
                fts_posts = fts_query.order_by(Post.posted_at.desc()).limit(limit_per_topic).all()
                
                for post in fts_posts:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω –ª–∏ —É–∂–µ
                    if not any(p['post_id'] == str(post.id) for p in all_posts):
                        channel = db.query(Channel).filter(Channel.id == post.channel_id).first()
                        
                        all_posts.append({
                            'post_id': str(post.id),
                            'content': post.content or "",
                            'channel_title': channel.title if channel else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–Ω–∞–ª",
                            'channel_username': channel.username if channel else None,
                            'permalink': post.telegram_post_url,
                            'posted_at': post.posted_at,
                            'topic': topic,
                            'score': 0.5,  # –°—Ä–µ–¥–Ω–∏–π score –¥–ª—è FTS —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                            # Context7: –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
                            'engagement_score': float(post.engagement_score) if post.engagement_score else 0.0,
                            'views_count': post.views_count or 0,
                            'reactions_count': post.reactions_count or 0,
                            'forwards_count': post.forwards_count or 0,
                            'replies_count': post.replies_count or 0
                        })
            
            except Exception as e:
                logger.error("Error collecting posts for topic", topic=topic, error=str(e))
                continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        all_posts.sort(key=lambda x: (x['posted_at'] or datetime.min, x['score']), reverse=True)
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ post_id
        seen = set()
        unique_posts = []
        for post in all_posts:
            if post['post_id'] not in seen:
                seen.add(post['post_id'])
                unique_posts.append(post)
        
        # Context7: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∞–ª—å–±–æ–º–æ–≤ - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –ø–æ—Å—Ç –∏–∑ –∞–ª—å–±–æ–º–∞ —Å –Ω–∞–∏–≤—ã—Å—à–∏–º score
        try:
            # –ü–æ–ª—É—á–∞–µ–º grouped_id –¥–ª—è –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ –ë–î
            post_ids = [UUID(p['post_id']) for p in unique_posts]
            if post_ids:
                posts_with_grouped = db.query(
                    Post.id,
                    Post.grouped_id
                ).filter(Post.id.in_(post_ids)).all()
                
                # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å post_id -> grouped_id
                post_grouped_map = {str(post.id): post.grouped_id for post in posts_with_grouped if post.grouped_id}
                
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã –ø–æ –∞–ª—å–±–æ–º–∞–º
                album_posts = {}  # grouped_id -> —Å–ø–∏—Å–æ–∫ (post_index, score)
                for idx, post_data in enumerate(unique_posts):
                    grouped_id = post_grouped_map.get(post_data['post_id'])
                    if grouped_id:
                        if grouped_id not in album_posts:
                            album_posts[grouped_id] = []
                        album_posts[grouped_id].append((idx, post_data['score']))
                
                # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–ª—å–±–æ–º–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å—Ç —Å –Ω–∞–∏–≤—ã—Å—à–∏–º score
                indices_to_remove = set()
                for grouped_id, posts_list in album_posts.items():
                    if len(posts_list) > 1:
                        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π
                        posts_list.sort(key=lambda x: x[1], reverse=True)
                        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
                        for idx, _ in posts_list[1:]:
                            indices_to_remove.add(idx)
                
                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∞–ª—å–±–æ–º–æ–≤ (–≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ–±—ã –Ω–µ —Å–±–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã)
                for idx in sorted(indices_to_remove, reverse=True):
                    unique_posts.pop(idx)
                
                logger.debug(
                    "Album deduplication applied in digest",
                    albums_count=len(album_posts),
                    removed_duplicates=len(indices_to_remove)
                )
        except Exception as e:
            logger.warning("Error during album deduplication in digest", error=str(e))
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
        return unique_posts
    
    async def _assemble_context(self, posts: List[Dict[str, Any]], max_posts: int = 20) -> str:
        """
        –°–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –ø–æ—Å—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞.
        
        Context7: –í–∫–ª—é—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø–æ—Å—Ç—ã.
        """
        if not posts:
            return ""
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π engagement_score –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        max_engagement = max((p.get('engagement_score', 0.0) for p in posts), default=1.0)
        if max_engagement == 0:
            max_engagement = 1.0  # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        
        context_parts = []
        
        for idx, post in enumerate(posts[:max_posts], 1):
            content = post.get('content', '')
            # Context7: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—É—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏ (–¥–æ 500 —Å–∏–º–≤–æ–ª–æ–≤)
            if len(content) > 500:
                content = content[:500] + "..."
            
            channel_title = post.get('channel_title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–Ω–∞–ª')
            permalink = post.get('permalink', '')
            
            # Context7: –í—ã—á–∏—Å–ª—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å (%)
            engagement_score = post.get('engagement_score', 0.0)
            popularity_percent = int((engagement_score / max_engagement) * 100) if max_engagement > 0 else 0
            
            # Context7: –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
            views = post.get('views_count', 0)
            reactions = post.get('reactions_count', 0)
            forwards = post.get('forwards_count', 0)
            replies = post.get('replies_count', 0)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –º–µ—Ç—Ä–∏–∫
            metrics_parts = []
            if views > 0:
                metrics_parts.append(f"üëÅÔ∏è {views}")
            if reactions > 0:
                metrics_parts.append(f"‚ù§Ô∏è {reactions}")
            if forwards > 0:
                metrics_parts.append(f"‚Ü™Ô∏è {forwards}")
            if replies > 0:
                metrics_parts.append(f"üí¨ {replies}")
            
            metrics_str = " | ".join(metrics_parts) if metrics_parts else "‚Äî"
            
            # Context7: –£–ª—É—á—à–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ —Å—É—Ç–∏
            # –§–æ—Ä–º–∞—Ç: [N] –ö–∞–Ω–∞–ª | –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: X% | –ú–µ—Ç—Ä–∏–∫–∏ | –°—Å—ã–ª–∫–∞
            # –ó–∞—Ç–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—Ç–∏
            post_header = f"[{idx}] **{channel_title}**"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
            if popularity_percent > 0:
                post_header += f" | –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: {popularity_percent}%"
            
            if metrics_str != "‚Äî":
                post_header += f" | {metrics_str}"
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ markdown –¥–ª—è –ª—É—á—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ LLM
            if permalink:
                post_header += f" | [–°—Å—ã–ª–∫–∞]({permalink})"
            
            # Context7: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏, –∑–∞—Ç–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—Ç–∏
            post_line = f"{post_header}\n\n**–¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞:**\n{content}"
            
            context_parts.append(post_line)
        
        return "\n\n".join(context_parts)
    
    async def generate(
        self,
        user_id: UUID,
        tenant_id: str,
        db: Session,
        digest_date: Optional[date] = None
    ) -> DigestContent:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Context7: –°–±–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¢–û–õ–¨–ö–û –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Ç–µ–º–∞—Ç–∏–∫–∞–º –∏–∑ digest_settings.topics.
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            tenant_id: ID –∞—Ä–µ–Ω–¥–∞—Ç–æ—Ä–∞
            db: SQLAlchemy —Å–µ—Å—Å–∏—è
            digest_date: –î–∞—Ç–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–µ–≥–æ–¥–Ω—è)
        
        Returns:
            DigestContent —Å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∞–π–¥–∂–µ—Å—Ç–æ–º
        """
        start_time = time.time()
        
        if digest_date is None:
            digest_date = date.today()
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞
        digest_settings = db.query(DigestSettings).filter(DigestSettings.user_id == user_id).first()
        
        if not digest_settings:
            raise ValueError("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        if not digest_settings.enabled:
            raise ValueError("–î–∞–π–¥–∂–µ—Å—Ç –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
        
        # Context7: –ï—Å–ª–∏ —Ç–µ–º—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω—Ç–µ—Ä–µ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∫–∞–∫ fallback
        topics = digest_settings.topics if digest_settings.topics and len(digest_settings.topics) > 0 else []
        
        if not topics:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ user_interests
            try:
                from services.user_interest_service import get_user_interest_service
                interest_service = get_user_interest_service()
                user_interests = await interest_service.get_user_interests(user_id, limit=5, db=db)
                
                if user_interests:
                    # –ë–µ—Ä–µ–º —Ç–æ–ø-5 —Ç–µ–º –ø–æ –≤–µ—Å—É
                    topics = [interest.get('topic', '') for interest in user_interests[:5] if interest.get('topic')]
                    logger.info(
                        "Using user interests as topics fallback",
                        user_id=str(user_id),
                        topics_count=len(topics)
                    )
            except Exception as e:
                logger.warning("Failed to get user interests as fallback", error=str(e))
        
        if not topics or len(topics) == 0:
            raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω—ã —Ç–µ–º—ã –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞. –£–∫–∞–∂–∏—Ç–µ —Ç–µ–º—ã –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–∏—Å–∫ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤.")
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–∞–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–µ—Å–ª–∏ channels_filter –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ)
        user_channels = db.query(UserChannel).filter(UserChannel.user_id == user_id).all()
        channel_ids = None
        
        if digest_settings.channels_filter:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
            channel_ids = digest_settings.channels_filter
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –∫–∞–Ω–∞–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            channel_ids = [str(uc.channel_id) for uc in user_channels]
        
        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ—Å—Ç—ã –ø–æ —Ç–µ–º–∞–º
        logger.info(
            "Collecting posts for digest",
            user_id=str(user_id),
            topics=topics,
            channels_count=len(channel_ids) if channel_ids else 0
        )
        
        posts = await self._collect_posts_by_topics(
            topics=topics,
            tenant_id=tenant_id,
            user_id=user_id,
            channel_ids=channel_ids,
            limit_per_topic=digest_settings.max_items_per_digest,
            db=db
        )
        
        if not posts:
            logger.warning("No posts found for digest", user_id=str(user_id), topics=topics)
            return DigestContent(
                content="–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º —Ç–µ–º–∞–º –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.",
                posts_count=0,
                topics=topics,
                sections=[]
            )
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = await self._assemble_context(posts, max_posts=digest_settings.max_items_per_digest * 2)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —á–µ—Ä–µ–∑ GigaChat
        try:
            # Context7: –ò—Å–ø–æ–ª—å–∑—É–µ–º format_messages() –Ω–∞–ø—Ä—è–º—É—é, –∞ –Ω–µ format()
            # ChatPromptTemplate.format_messages() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ messages
            messages = self.digest_prompt.format_messages(
                context=context,
                topics=", ".join(topics)
            )
            
            if not messages:
                logger.error("Empty messages after formatting")
                return DigestContent(
                    content="–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç: –ø—É—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç.",
                    posts_count=len(posts),
                    topics=topics,
                    sections=[]
                )
            
            response = await self.llm.ainvoke(messages)
            content = response.content if hasattr(response, 'content') else str(response)
            
            # –ü–∞—Ä—Å–∏–º —Å–µ–∫—Ü–∏–∏ –∏–∑ markdown (–ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥)
            sections = self._parse_sections(content, topics)
            
            logger.info(
                "Digest generated",
                user_id=str(user_id),
                posts_count=len(posts),
                topics=topics,
                processing_time_ms=int((time.time() - start_time) * 1000)
            )
            
            return DigestContent(
                content=content,
                posts_count=len(posts),
                topics=topics,
                sections=sections
            )
        
        except Exception as e:
            logger.error("Error generating digest", error=str(e), user_id=str(user_id))
            raise
    
    def _parse_sections(self, content: str, topics: List[str]) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å–µ–∫—Ü–∏–π –∏–∑ markdown –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
        sections = []
        lines = content.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('##'):
                # –ù–æ–≤–∞—è —Å–µ–∫—Ü–∏—è
                if current_section:
                    sections.append(current_section)
                current_section = {
                    'title': line.replace('##', '').strip(),
                    'items': []
                }
            elif line.startswith('-') and current_section:
                # –ü—É–Ω–∫—Ç —Å–µ–∫—Ü–∏–∏
                item = line.replace('-', '').strip()
                current_section['items'].append(item)
        
        if current_section:
            sections.append(current_section)
        
        return sections


# ============================================================================
# SINGLETON INSTANCE
# ============================================================================

_digest_service: Optional[DigestService] = None


def get_digest_service(
    qdrant_url: Optional[str] = None
) -> DigestService:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ singleton —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ DigestService."""
    global _digest_service
    if _digest_service is None:
        qdrant_url = qdrant_url or getattr(settings, 'qdrant_url', 'http://qdrant:6333')
        _digest_service = DigestService(qdrant_url=qdrant_url)
    return _digest_service

