"""
RAG Service –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
Context7 best practice: intent-based routing, hybrid search, context assembly, response generation
"""

import asyncio
import time
import json
import hashlib
from collections import defaultdict
from typing import List, Dict, Any, Optional
from uuid import UUID
from datetime import datetime, timezone

import structlog
from sqlalchemy.orm import Session, selectinload
from sqlalchemy import text
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from langchain_gigachat import GigaChat
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableBranch, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage
from pydantic import BaseModel

from models.database import Post, PostEnrichment, User
from services.intent_classifier import get_intent_classifier, IntentResponse
from services.searxng_service import get_searxng_service
from services.graph_service import get_graph_service
from config import settings

logger = structlog.get_logger()

# ============================================================================
# PYDANTIC MODELS
# ============================================================================

class RAGSource(BaseModel):
    """–ò—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è RAG –æ—Ç–≤–µ—Ç–∞."""
    post_id: str
    channel_id: str
    channel_title: str
    channel_username: Optional[str]
    content: str
    score: float
    permalink: Optional[str] = None


class RAGResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç RAG –ø–æ–∏—Å–∫–∞."""
    answer: str
    sources: List[RAGSource]
    confidence: float
    intent: str
    processing_time_ms: int


# ============================================================================
# RAG SERVICE
# ============================================================================

class RAGService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è RAG –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤."""
    
    def __init__(
        self,
        qdrant_url: str,
        qdrant_client: Optional[QdrantClient] = None,
        redis_client: Optional[Any] = None,
        openai_api_base: Optional[str] = None,
        openai_api_key: Optional[str] = None,
        graph_service: Optional[Any] = None
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG Service.
        
        Args:
            qdrant_url: URL Qdrant —Å–µ—Ä–≤–∏—Å–∞
            qdrant_client: Qdrant –∫–ª–∏–µ–Ω—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Å–æ–∑–¥–∞—Å—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            redis_client: Redis –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            openai_api_base: URL gpt2giga-proxy
            openai_api_key: API –∫–ª—é—á
            graph_service: GraphService –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Neo4j (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        self.qdrant_url = qdrant_url
        self.qdrant_client = qdrant_client or QdrantClient(url=qdrant_url)
        self.redis_client = redis_client
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è IntentClassifier
        self.intent_classifier = get_intent_classifier(redis_client=redis_client)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SearXNG
        self.searxng_service = get_searxng_service(redis_client=redis_client)
        
        # Context7: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GraphService –¥–ª—è GraphRAG
        self.graph_service = graph_service or get_graph_service()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GigaChat LLM —á–µ—Ä–µ–∑ langchain-gigachat
        # Context7: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω URL (–±–µ–∑ /v1) –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–≤ –ø—Ä–æ–∫—Å–∏
        api_base = openai_api_base or settings.openai_api_base or "http://gpt2giga-proxy:8090"
        api_key = openai_api_key or settings.openai_api_key or "dummy"
        
        import os
        os.environ.setdefault("OPENAI_API_BASE", api_base)
        os.environ.setdefault("OPENAI_API_KEY", api_key)
        
        self.llm = GigaChat(
            credentials=getattr(settings, 'gigachat_credentials', '') or os.getenv('GIGACHAT_CREDENTIALS', ''),
            scope=getattr(settings, 'gigachat_scope', None) or os.getenv('GIGACHAT_SCOPE', 'GIGACHAT_API_PERS'),
            model="GigaChat",
            base_url=api_base,
            temperature=0.7,
        )
        
        # Context7: Intent-based routing —á–µ—Ä–µ–∑ LangChain RunnableBranch
        self.intent_router = self._create_intent_router()
        
        logger.info(
            "RAG Service initialized",
            qdrant_url=qdrant_url,
            api_base=api_base
        )
    
    def _create_intent_router(self) -> RunnableBranch:
        """–°–æ–∑–¥–∞–Ω–∏–µ intent-based router —á–µ—Ä–µ–∑ LangChain RunnableBranch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π conversation history."""
        
        # Context7: –ü—Ä–æ–º–ø—Ç—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π conversation history
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º MessagesPlaceholder –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏
        ask_prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ Telegram –∫–∞–Ω–∞–ª–æ–≤.
–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç/–∏—Å—Ç–æ—Ä–∏—é.
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á–µ—Å—Ç–Ω–æ —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (Markdown, —Å—Ç—Ä–æ–≥–æ —Å–æ–±–ª—é–¥–∞–π):
1. **–ó–∞–≥–æ–ª–æ–≤–æ–∫** –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π.
2. **–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã** ‚Äî –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–æ 4 –ø—É–Ω–∫—Ç–æ–≤, –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç –∑–∞–≤–µ—Ä—à–∏ —Å—Å—ã–ª–∫–æ–π –≤–∏–¥–∞ [–∫–∞–Ω–∞–ª](URL).
3. **–ß—Ç–æ –¥–∞–ª—å—à–µ** ‚Äî (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π.
4. **–ò—Å—Ç–æ—á–Ω–∏–∫–∏** ‚Äî –ø–æ–≤—Ç–æ—Ä–∏ —Å—Å—ã–ª–∫–∏ —Å–ø–∏—Å–∫–æ–º `‚Ä¢ [–∫–∞–Ω–∞–ª](URL) ‚Äî –∫—Ä–∞—Ç–∫–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ`.
   –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –ø–æ–º–µ—Ç–∫–∏ `üñº` (vision) –∏–ª–∏ `üï∏` (Crawl4AI), —è–≤–Ω–æ —É–∫–∞–∂–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –∏ –≤–µ–±-–Ω–∞—Ö–æ–¥–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π.
   –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Å—Ç—Ä–æ–∫–∏ `[–í–Ω–µ—à–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ ...]`, –≤—ã–Ω–µ—Å–∏ –∏—Ö –≤ –ø–æ–¥–ø—É–Ω–∫—Ç ¬´–í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏¬ª.

–°—Å—ã–ª–∫–∏ –≤—Å–µ–≥–¥–∞ —Ä–∞–∑–º–µ—â–∞–π —Ä—è–¥–æ–º —Å —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã.
–ò—Å–ø–æ–ª—å–∑—É–π –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ (conversation_history), –µ—Å–ª–∏ –æ–Ω–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞."""),
            # Context7: –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
            MessagesPlaceholder(variable_name="conversation_history", optional=True),
            ("human", "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}\n\n–í–æ–ø—Ä–æ—Å: {query}\n\n–û—Ç–≤–µ—Ç:")
        ])
        
        search_prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –ø–æ–∏—Å–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ Telegram –∫–∞–Ω–∞–ª–∞—Ö.
–°—Ñ–æ—Ä–º–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±–∑–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

–§–æ—Ä–º–∞—Ç (Markdown):
1. **–ó–∞–ø—Ä–æ—Å** ‚Äî –∫–æ—Ä–æ—Ç–∫–æ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å.
2. **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã** ‚Äî –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫: `[–∫–∞–Ω–∞–ª](URL): —Ç–µ–∑–∏—Å`. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —É —ç—Ç–æ–≥–æ –ø—É–Ω–∫—Ç–∞ –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å `üñº`, `üì∑` –∏–ª–∏ `üï∏`, –¥–æ–±–∞–≤—å –ø–æ—Å–ª–µ —Ç–µ–∑–∏—Å–∞ –ø–æ–¥–ø—É–Ω–∫—Ç ¬´–ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤¬ª –∏ –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏. –ï—Å–ª–∏ —Ç–∞–∫–∏—Ö —Å—Ç—Ä–æ–∫ –Ω–µ—Ç ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–ø—É—Å—Ç–∏ –ø–æ–¥–ø—É–Ω–∫—Ç (–Ω–µ –ø–∏—à–∏ ¬´–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö¬ª).
3. **–í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏** ‚Äî –¥–æ–±–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏ `[–í–Ω–µ—à–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ ‚Ä¶]`.
4. **–ò—Å—Ç–æ—á–Ω–∏–∫–∏** ‚Äî –≤—ã–≤–µ–¥–∏ –æ–¥–∏–Ω —Ä–∞–∑ –≤ –∫–æ–Ω—Ü–µ, –ø–µ—Ä–µ—á–∏—Å–ª–∏–≤ —Ç–æ–ª—å–∫–æ —Å—Å—ã–ª–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ —É–ø–æ–º—è–Ω—É—Ç—ã –≤—ã—à–µ (Context7: –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º).

–ù–µ –¥–æ–±–∞–≤–ª—è–π —á—É–∂–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞."""),
            MessagesPlaceholder(variable_name="conversation_history", optional=True),
            ("human", "–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã:\n{context}\n\n–ó–∞–ø—Ä–æ—Å: {query}\n\n–†–µ–∑—é–º–µ:")
        ])
        
        recommend_prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
–ù–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –æ–±—ä—è—Å–Ω–∏ —Ü–µ–Ω–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ.

–§–æ—Ä–º–∞—Ç:
1. **–ó–∞–≥–æ–ª–æ–≤–æ–∫**.
2. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏** ‚Äî –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫: `[–∫–∞–Ω–∞–ª](URL) ‚Äî –ø—Ä–∏—á–∏–Ω–∞ + —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ vision/crawl, –µ—Å–ª–∏ –µ—Å—Ç—å`.
3. **–ß—Ç–æ –ø–æ—á–∏—Ç–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ** ‚Äî (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Å–ø–∏—Å–æ–∫ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
4. **–ò—Å—Ç–æ—á–Ω–∏–∫–∏** ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫.

–£—á–∏—Ç—ã–≤–∞–π –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (conversation_history), –Ω–µ –¥—É–±–ª–∏—Ä—É–π —Ñ–∞–∫—Ç—ã."""),
            MessagesPlaceholder(variable_name="conversation_history", optional=True),
            ("human", "–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã:\n{context}\n\n–ó–∞–ø—Ä–æ—Å: {query}\n\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        ])
        
        trend_prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ —Ç—Ä–µ–Ω–¥–æ–≤.
–í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã, –º–µ—Ç—Ä–∏–∫–∏ –∏ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–§–æ—Ä–º–∞—Ç:
1. **–ó–∞–≥–æ–ª–æ–≤–æ–∫**.
2. **–¢—Ä–µ–Ω–¥—ã** ‚Äî –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞ —É–∫–∞–∂–∏:
   - –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ —Å—Å—ã–ª–∫—É `[–∫–∞–Ω–∞–ª](URL)`.
   - –ï—Å–ª–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º –±–ª–æ–∫–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∏ `üñº`, `üì∑` –∏–ª–∏ `üï∏`, –¥–æ–±–∞–≤—å –ø–æ–¥–ø—É–Ω–∫—Ç ¬´–ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤¬ª –∏ –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π –∏—Ö; –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫ –Ω–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏ –ø–æ–¥–ø—É–Ω–∫—Ç.
3. **–ß—Ç–æ –Ω–∞–±–ª—é–¥–∞—Ç—å** ‚Äî —Å–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π/–º–µ—Ç—Ä–∏–∫.
4. **–ò—Å—Ç–æ—á–Ω–∏–∫–∏** ‚Äî –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ (—Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –≤ –æ—Ç–≤–µ—Ç–µ). –û—Ç–¥–µ–ª—å–Ω—ã–π –±–ª–æ–∫ ¬´–í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏¬ª –≤—ã–≤–æ–¥–∏ –ª–∏—à—å –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ `[–í–Ω–µ—à–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ ‚Ä¶]` –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.

–í—Å–µ–≥–¥–∞ –æ—Ç–¥–µ–ª—è–π –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –ø–æ–¥–ø—É–Ω–∫—Ç, –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç `[–í–Ω–µ—à–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫]`."""),
            MessagesPlaceholder(variable_name="conversation_history", optional=True),
            ("human", "–ü–æ—Å—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:\n{context}\n\n–ó–∞–ø—Ä–æ—Å: {query}\n\n–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤:")
        ])
        
        digest_prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢—ã ‚Äî —Å–æ—Å—Ç–∞–≤–∏—Ç–µ–ª—å –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π.
–°—Ñ–æ—Ä–º–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤.

–§–æ—Ä–º–∞—Ç:
1. **–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–∞–π–¥–∂–µ—Å—Ç–∞**.
2. –î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã:
   - `### –¢–µ–º–∞` (—Å –∫—Ä–∞—Ç–∫–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ–º).
   - `‚Ä¢ [–∫–∞–Ω–∞–ª](URL): —Ñ–∞–∫—Ç`. –ï—Å–ª–∏ —É —Ç–µ–º—ã –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å—Ç—Ä–æ–∫–∏ `üñº`, `üì∑` –∏–ª–∏ `üï∏`, –¥–æ–±–∞–≤—å –ø–æ–¥—Å–ø–∏—Å–æ–∫ ¬´–ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤¬ª –∏ –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏. –ï—Å–ª–∏ —Ç–∞–∫–∏—Ö —Å—Ç—Ä–æ–∫ –Ω–µ—Ç ‚Äî –Ω–µ –≤—Å—Ç–∞–≤–ª—è–π –ø–æ–¥–ø—É–Ω–∫—Ç.
3. **–í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏** ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è `[–í–Ω–µ—à–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ ‚Ä¶]`.
4. **–ò—Å—Ç–æ—á–Ω–∏–∫–∏** ‚Äî –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ –∏–∑ –æ—Ç–≤–µ—Ç–∞ (Context7: –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å —Ç–æ –∂–µ —Å–∞–º–æ–µ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –±–ª–æ–∫–∞—Ö).

–¢–µ–º—ã –∏ —Ñ–∞–∫—Ç—ã –¥–æ–ª–∂–Ω—ã —Å—Å—ã–ª–∞—Ç—å—Å—è –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ."""),
            MessagesPlaceholder(variable_name="conversation_history", optional=True),
            ("human", "–ü–æ—Å—Ç—ã –¥–ª—è –¥–∞–π–¥–∂–µ—Å—Ç–∞:\n{context}\n\n–ó–∞–ø—Ä–æ—Å: {query}\n\n–î–∞–π–¥–∂–µ—Å—Ç:")
        ])
        
        # Context7: RunnableBranch –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è–º
        return RunnableBranch(
            (lambda x: x["intent"] == "ask", ask_prompt | self.llm | StrOutputParser()),
            (lambda x: x["intent"] == "search", search_prompt | self.llm | StrOutputParser()),
            (lambda x: x["intent"] == "recommend", recommend_prompt | self.llm | StrOutputParser()),
            (lambda x: x["intent"] == "trend", trend_prompt | self.llm | StrOutputParser()),
            (lambda x: x["intent"] == "digest", digest_prompt | self.llm | StrOutputParser()),
            # Fallback –Ω–∞ search
            search_prompt | self.llm | StrOutputParser()
        )
    
    async def _generate_embedding(self, text: str) -> List[float]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ GigaChat."""
        try:
            import requests
            import os
            
            proxy_url = getattr(settings, 'gigachat_proxy_url', None) or os.getenv("GIGACHAT_PROXY_URL", "http://gpt2giga-proxy:8090")
            url = f"{proxy_url}/v1/embeddings"
            
            credentials = os.getenv("GIGACHAT_CREDENTIALS")
            scope = os.getenv("GIGACHAT_SCOPE", "GIGACHAT_API_PERS")
            auth_header = f"giga-cred-{credentials}:{scope}"
            
            response = requests.post(
                url,
                json={
                    "input": text,
                    "model": "any"  # gpt2giga —Å–∞–º –æ—Ç–ø—Ä–∞–≤–∏—Ç –Ω–∞ EmbeddingsGigaR
                },
                headers={
                    "Authorization": f"Bearer {auth_header}",
                    "Content-Type": "application/json"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'data' in data and len(data['data']) > 0:
                    embedding = data['data'][0].get('embedding', [])
                    return embedding
            
            logger.warning("Failed to generate embedding", status_code=response.status_code)
            return []
        
        except Exception as e:
            logger.error("Error generating embedding", error=str(e))
            return []
    
    async def _search_qdrant(
        self,
        query_embedding: List[float],
        tenant_id: str,
        limit: int = 10,
        channel_ids: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –≤ Qdrant –ø–æ –≤–µ–∫—Ç–æ—Ä—É."""
        try:
            collection_name = f"t{tenant_id}_posts"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            collections = self.qdrant_client.get_collections()
            if collection_name not in [c.name for c in collections.collections]:
                logger.warning("Qdrant collection not found", collection=collection_name)
                return []
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞
            filter_conditions = []
            filter_conditions.append(
                FieldCondition(
                    key="tenant_id",
                    match=MatchValue(value=str(tenant_id))
                )
            )
            
            if channel_ids:
                filter_conditions.append(
                    FieldCondition(
                        key="channel_id",
                        match=MatchValue(any=[str(cid) for cid in channel_ids])
                    )
                )
            
            search_filter = Filter(must=filter_conditions) if filter_conditions else None
            
            # –ü–æ–∏—Å–∫
            search_results = self.qdrant_client.search(
                collection_name=collection_name,
                query_vector=query_embedding,
                query_filter=search_filter,
                limit=limit
            )
            
            results = []
            for result in search_results:
                results.append({
                    'post_id': result.payload.get('post_id'),
                    'score': result.score,
                    'payload': result.payload
                })
            
            return results
        
        except Exception as e:
            logger.error("Error searching Qdrant", error=str(e))
            return []
    
    async def _search_postgres_fts(
        self,
        query: str,
        tenant_id: str,
        limit: int = 10,
        channel_ids: Optional[List[str]] = None,
        db: Optional[Session] = None
    ) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ PostgreSQL Full-Text Search."""
        if not db:
            return []
        
        try:
            # Context7: PostgreSQL FTS –¥–ª—è keyword search
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º tsvector –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ content
            # Context7: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ tenant_id —á–µ—Ä–µ–∑ JOIN —Å user_channel –∏ –ø–æ channel_ids
            base_query = """
                SELECT DISTINCT
                    p.id,
                    p.channel_id,
                    p.content,
                    p.telegram_post_url,
                    ts_rank(to_tsvector('russian', COALESCE(p.content, '')), plainto_tsquery('russian', :query)) as rank
                FROM posts p
                JOIN channels c ON p.channel_id = c.id
                JOIN user_channel uc ON uc.channel_id = c.id
                JOIN users u ON u.id = uc.user_id
                WHERE to_tsvector('russian', COALESCE(p.content, '')) @@ plainto_tsquery('russian', :query)
                    AND u.tenant_id = CAST(:tenant_id AS uuid)
            """
            
            params = {"query": query, "tenant_id": tenant_id, "limit": limit}
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ channel_ids –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
            if channel_ids:
                base_query += " AND p.channel_id = ANY(CAST(:channel_ids AS uuid[]))"
                params["channel_ids"] = channel_ids
            
            base_query += " ORDER BY rank DESC LIMIT :limit"
            
            fts_query = text(base_query)
            result = db.execute(fts_query, params)
            rows = result.fetchall()
            
            results = []
            for row in rows:
                results.append({
                    'post_id': str(row.id),
                    'channel_id': str(row.channel_id),
                    'content': row.content,
                    'permalink': row.telegram_post_url,
                    'score': float(row.rank) if row.rank else 0.0
                })
            
            return results
        
        except Exception as e:
            logger.error("Error searching PostgreSQL FTS", error=str(e))
            return []
    
    async def _search_neo4j_graph(
        self,
        query: str,
        user_id: Optional[str] = None,
        tenant_id: Optional[str] = None,
        limit: int = 10,
        max_depth: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        GraphRAG –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Neo4j.
        
        Context7: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≥—Ä–∞—Ñ–æ–≤—ã–µ —Å–≤—è–∑–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –∏–Ω—Ç–µ—Ä–µ—Å–∞–º)
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            max_depth: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –æ–±—Ö–æ–¥–∞ –≥—Ä–∞—Ñ–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ –≥—Ä–∞—Ñ–∞
        """
        try:
            # Context7: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞ Redis
            if self.redis_client:
                cache_key = f"graphrag:query:{hashlib.sha1((query + (user_id or '')).encode()).hexdigest()}"
                cached = self.redis_client.get(cache_key)
                if cached:
                    logger.debug("GraphRAG cache hit", query=query[:50])
                    return json.loads(cached)
            
            # Context7: Health check –ø–µ—Ä–µ–¥ –≥—Ä–∞—Ñ–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
            if not await self.graph_service.health_check():
                logger.warning("Neo4j unavailable, skipping GraphRAG search")
                return []
            
            max_depth = max_depth or getattr(settings, 'neo4j_max_graph_depth', 2)
            
            # –ü–æ–∏—Å–∫ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
            graph_results = await self.graph_service.search_related_posts(
                query=query,
                topic=None,  # –ú–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å —Ç–µ–º—É –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                tenant_id=tenant_id,
                limit=limit * 2,
                max_depth=max_depth
            )
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å hybrid_search
            results = []
            for item in graph_results:
                results.append({
                    'post_id': item.get('post_id'),
                    'content': item.get('content', ''),
                    'topic': item.get('topic'),
                    'topics': item.get('topics', []),
                    'channel_title': item.get('channel_title'),
                    'score': 0.8,  # –ë–∞–∑–æ–≤—ã–π score –¥–ª—è –≥—Ä–∞—Ñ–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    'graph_score': 0.8,
                    'relation_type': item.get('relation_type', 'direct')
                })
            
            # Context7: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (TTL 5 –º–∏–Ω—É—Ç)
            if self.redis_client and results:
                self.redis_client.setex(
                    cache_key,
                    300,  # 5 –º–∏–Ω—É—Ç
                    json.dumps(results)
                )
            
            logger.debug("GraphRAG search completed", query=query[:50], results_count=len(results))
            return results
            
        except Exception as e:
            logger.error("Error in GraphRAG search", error=str(e), query=query[:50])
            # Context7: Graceful degradation - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return []
    
    async def _hybrid_search(
        self,
        query: str,
        query_embedding: List[float],
        tenant_id: str,
        limit: int = 10,
        channel_ids: Optional[List[str]] = None,
        db: Optional[Session] = None,
        user_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Hybrid search: Qdrant ANN + PostgreSQL FTS + Neo4j GraphRAG —Å re-ranking.
        
        Context7: –¢—Ä–æ–π–Ω–æ–π –≥–∏–±—Ä–∏–¥:
        - Qdrant (–≤–µ—Å 0.5) - —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        - PostgreSQL FTS (–≤–µ—Å 0.2) - keyword search
        - Neo4j GraphRAG (–≤–µ—Å 0.3) - –≥—Ä–∞—Ñ–æ–≤—ã–µ —Å–≤—è–∑–∏ –∏ –∏–Ω—Ç–µ—Ä–µ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ Qdrant, PostgreSQL –∏ Neo4j
        qdrant_results = await self._search_qdrant(query_embedding, tenant_id, limit * 2, channel_ids)
        fts_results = await self._search_postgres_fts(query, tenant_id, limit * 2, channel_ids, db)
        
        # Context7: GraphRAG –ø–æ–∏—Å–∫ (—Å fallback –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Neo4j)
        graph_results = []
        try:
            graph_results = await self._search_neo4j_graph(query, user_id, tenant_id=tenant_id, limit=limit * 2)
        except Exception as e:
            logger.warning("GraphRAG search failed, continuing without graph results", error=str(e))
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        post_scores = {}
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ Qdrant (–≤–µ—Å 0.5)
        for result in qdrant_results:
            post_id = result['post_id']
            score = result['score'] * 0.5
            if post_id not in post_scores:
                post_scores[post_id] = {
                    'post_id': post_id,
                    'payload': result.get('payload', {}),
                    'qdrant_score': result['score'],
                    'fts_score': 0.0,
                    'graph_score': 0.0,
                    'hybrid_score': score
                }
            else:
                post_scores[post_id]['hybrid_score'] += score
                post_scores[post_id]['qdrant_score'] = result['score']
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ FTS (–≤–µ—Å 0.2)
        for result in fts_results:
            post_id = result['post_id']
            score = result['score'] * 0.2
            if post_id not in post_scores:
                post_scores[post_id] = {
                    'post_id': post_id,
                    'payload': result,
                    'qdrant_score': 0.0,
                    'fts_score': result['score'],
                    'graph_score': 0.0,
                    'hybrid_score': score
                }
            else:
                post_scores[post_id]['hybrid_score'] += score
                post_scores[post_id]['fts_score'] = result['score']
                if 'content' not in post_scores[post_id]['payload']:
                    post_scores[post_id]['payload'].update(result)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ Neo4j GraphRAG (–≤–µ—Å 0.3)
        for result in graph_results:
            post_id = result.get('post_id')
            if not post_id:
                continue
            
            score = result.get('graph_score', 0.8) * 0.3
            if post_id not in post_scores:
                post_scores[post_id] = {
                    'post_id': post_id,
                    'payload': {
                        'content': result.get('content', ''),
                        'topic': result.get('topic'),
                        'topics': result.get('topics', []),
                        'channel_title': result.get('channel_title')
                    },
                    'qdrant_score': 0.0,
                    'fts_score': 0.0,
                    'graph_score': result.get('graph_score', 0.8),
                    'hybrid_score': score,
                    'relation_type': result.get('relation_type', 'direct')
                }
            else:
                post_scores[post_id]['hybrid_score'] += score
                post_scores[post_id]['graph_score'] = result.get('graph_score', 0.8)
                # –û–±–æ–≥–∞—â–∞–µ–º payload –≥—Ä–∞—Ñ–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                if 'topics' in result:
                    existing_topics = post_scores[post_id]['payload'].get('topics', [])
                    if isinstance(existing_topics, list):
                        post_scores[post_id]['payload']['topics'] = list(set(existing_topics + result.get('topics', [])))
        
        # Context7: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∞–ª—å–±–æ–º–æ–≤ - –ø–æ–ª—É—á–∞–µ–º grouped_id –∏–∑ –ë–î –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –ø–æ—Å—Ç —Å –Ω–∞–∏–≤—ã—Å—à–∏–º score
        if db:
            try:
                # –ü–æ–ª—É—á–∞–µ–º grouped_id –¥–ª—è –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ –ë–î
                post_ids = [UUID(pid) for pid in post_scores.keys() if pid]
                if post_ids:
                    posts_with_grouped = db.query(
                        Post.id,
                        Post.grouped_id
                    ).filter(Post.id.in_(post_ids)).all()
                    
                    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å post_id -> grouped_id
                    post_grouped_map = {str(post.id): post.grouped_id for post in posts_with_grouped if post.grouped_id}
                    
                    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã –ø–æ –∞–ª—å–±–æ–º–∞–º
                    album_posts = {}  # grouped_id -> —Å–ø–∏—Å–æ–∫ (post_id, hybrid_score)
                    for post_id, score_data in post_scores.items():
                        grouped_id = post_grouped_map.get(post_id)
                        if grouped_id:
                            if grouped_id not in album_posts:
                                album_posts[grouped_id] = []
                            album_posts[grouped_id].append((post_id, score_data['hybrid_score']))
                    
                    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–ª—å–±–æ–º–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å—Ç —Å –Ω–∞–∏–≤—ã—Å—à–∏–º score
                    posts_to_remove = set()
                    for grouped_id, posts_list in album_posts.items():
                        if len(posts_list) > 1:
                            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π
                            posts_list.sort(key=lambda x: x[1], reverse=True)
                            # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ
                            for post_id, _ in posts_list[1:]:
                                posts_to_remove.add(post_id)
                    
                    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∞–ª—å–±–æ–º–æ–≤
                    for post_id in posts_to_remove:
                        post_scores.pop(post_id, None)
                    
                    logger.debug(
                        "Album deduplication applied",
                        albums_count=len(album_posts),
                        removed_duplicates=len(posts_to_remove)
                    )
            except Exception as e:
                logger.warning("Error during album deduplication", error=str(e))
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ hybrid_score
        sorted_results = sorted(
            post_scores.values(),
            key=lambda x: x['hybrid_score'],
            reverse=True
        )
        
        return sorted_results[:limit]
    
    async def _assemble_context(
        self,
        results: List[Dict[str, Any]],
        db: Session
    ) -> tuple[str, List[RAGSource]]:
        """–°–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ —Å –æ–±–æ–≥–∞—â–µ–Ω–∏—è–º–∏ Vision/Crawl."""
        max_context_posts = 5
        ordered_results: List[Dict[str, Any]] = []
        post_ids: List[UUID] = []
        post_ids_str: List[str] = []
        
        for result in results[:max_context_posts]:
            post_id_raw = result.get("post_id")
            if not post_id_raw:
                continue
            try:
                post_uuid = UUID(str(post_id_raw))
            except (ValueError, TypeError):
                continue
            ordered_results.append(result)
            post_ids.append(post_uuid)
            post_ids_str.append(str(post_uuid))
        
        if not ordered_results:
            return "", []
        
        posts = (
            db.query(Post)
            .options(selectinload(Post.channel))
            .filter(Post.id.in_(post_ids))
            .all()
        )
        post_map = {str(post.id): post for post in posts}
        
        enrichments = db.query(PostEnrichment).filter(
            PostEnrichment.post_id.in_(post_ids),
            PostEnrichment.kind.in_(("vision", "vision_ocr", "crawl", "general"))
        ).all()
        enrichment_map: defaultdict[str, dict[str, PostEnrichment]] = defaultdict(dict)
        for enrichment in enrichments:
            enrichment_map[str(enrichment.post_id)][enrichment.kind] = enrichment
        
        context_parts: List[str] = []
        sources: List[RAGSource] = []
        
        for idx, result in enumerate(ordered_results):
            post = post_map.get(str(result.get("post_id")))
            if not post:
                continue
            
            channel = post.channel
            channel_title = channel.title if channel else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–∞–Ω–∞–ª"
            channel_username = channel.username if channel else None
            
            content = (post.content or "").strip()
            if len(content) > 500:
                content = content[:500].rstrip() + "‚Ä¶"
            if not content:
                content = "–ë–µ–∑ —Ç–µ–∫—Å—Ç–∞, –¥–æ—Å—Ç—É–ø–Ω–æ —Ç–æ–ª—å–∫–æ –º–µ–¥–∏–∞/–æ–±–æ–≥–∞—â–µ–Ω–∏—è."
            
            enrichment_bundle = enrichment_map.get(str(post.id), {})
            enrichment_snippets = self._render_enrichment_snippets(enrichment_bundle)
            
            if post.grouped_id and not any(snippet.startswith("üì∑") for snippet in enrichment_snippets):
                enrichment_snippets.insert(0, "üì∑ –ê–ª—å–±–æ–º –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ–¥–∏–∞")
            
            enrichment_text = ""
            if enrichment_snippets:
                enrichment_text = "\n" + "\n".join(enrichment_snippets)
            
            permalink = post.telegram_post_url or ""
            if permalink:
                entry = f"[{idx + 1}] [{channel_title}]({permalink}): {content}{enrichment_text}"
            else:
                entry = f"[{idx + 1}] {channel_title}: {content}{enrichment_text}"
            context_parts.append(entry)
            
            source_content = content
            if enrichment_snippets:
                source_content = f"{content}\n" + "\n".join(enrichment_snippets)
            
            sources.append(
                RAGSource(
                    post_id=str(post.id),
                    channel_id=str(post.channel_id),
                    channel_title=channel_title,
                    channel_username=channel_username,
                    content=source_content,
                    score=result.get("hybrid_score", result.get("score", 0.0)),
                    permalink=post.telegram_post_url
                )
            )
        
        context = "\n\n".join(context_parts)
        return context, sources

    def _render_enrichment_snippets(
        self,
        enrichment_bundle: Optional[Dict[str, PostEnrichment]]
    ) -> List[str]:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Vision/Crawl4AI –æ–±–æ–≥–∞—â–µ–Ω–∏–π."""
        snippets: List[str] = []
        if not enrichment_bundle:
            return snippets
        
        def _append_unique(
            prefix: str,
            text_value: Optional[str],
            limit: int = 280,
            skip_values: Optional[List[str]] = None
        ) -> None:
            if not text_value:
                return
            normalized = text_value.strip()
            if not normalized:
                return
            if skip_values and normalized.lower() in skip_values:
                return
            short_text = self._shorten_text(normalized, limit)
            if short_text and not any(snippet.startswith(prefix) for snippet in snippets):
                snippets.append(f"{prefix} {short_text}")
        
        vision = enrichment_bundle.get("vision")
        if vision and isinstance(getattr(vision, "data", None), dict):
            data = vision.data or {}
            caption = data.get("summary") or data.get("description") or data.get("caption")
            _append_unique(
                "üñº",
                caption,
                skip_values=[
                    "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è",
                    "image without description",
                    "no description",
                ]
            )
            labels = data.get("labels")
            if isinstance(labels, list) and labels:
                normalized_labels = ", ".join(str(label) for label in labels[:5] if label)
                _append_unique("üè∑ –¢–µ–≥–∏:", normalized_labels, limit=200)
            ocr_payload = data.get("ocr")
            ocr_text = None
            if isinstance(ocr_payload, dict):
                ocr_text = ocr_payload.get("text")
            elif isinstance(ocr_payload, str):
                ocr_text = ocr_payload
            cleaned_ocr = self._normalize_ocr_text(ocr_text)
            _append_unique("üî§ OCR:", cleaned_ocr, limit=240, skip_values=[""])
        
        vision_ocr = enrichment_bundle.get("vision_ocr")
        if vision_ocr and isinstance(getattr(vision_ocr, "data", None), dict):
            ocr_text = vision_ocr.data.get("text") or vision_ocr.data.get("raw_text")
            cleaned_ocr = self._normalize_ocr_text(ocr_text)
            _append_unique("üî§ OCR:", cleaned_ocr, limit=240, skip_values=[""])
        
        crawl = enrichment_bundle.get("crawl") or enrichment_bundle.get("general")
        if crawl and isinstance(getattr(crawl, "data", None), dict):
            crawl_data = crawl.data or {}
            crawl_excerpt = crawl_data.get("md_excerpt") or crawl_data.get("markdown")
            _append_unique("üï∏ Crawl4AI:", crawl_excerpt, limit=320)
            crawl_summary = crawl_data.get("summary")
            _append_unique("üì∞", crawl_summary, limit=240)
        
        album_size = None
        for enrichment in enrichment_bundle.values():
            size = getattr(enrichment, "album_size", None)
            if size:
                album_size = max(album_size or 0, size)
        if album_size:
            snippets.append(f"üì∑ –ê–ª—å–±–æ–º: {album_size} –º–µ–¥–∏–∞")
        
        return snippets

    @staticmethod
    def _shorten_text(value: Optional[str], limit: int = 280) -> str:
        """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ –∑–∞–¥–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏—è."""
        if not value:
            return ""
        trimmed = value.strip()
        if len(trimmed) <= limit:
            return trimmed
        return trimmed[:limit].rstrip() + "‚Ä¶"
    
    @staticmethod
    def _normalize_ocr_text(value: Optional[str]) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç OCR-—Ç–µ–∫—Å—Ç: —É–±–∏—Ä–∞–µ—Ç –∫–∞–ø—Å–ª–æ–∫ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã."""
        if not value:
            return ""
        normalized = " ".join(value.split())
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ –í–ï–†–•–ù–ï–ú —Ä–µ–≥–∏—Å—Ç—Ä–µ, –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        if normalized.isupper():
            normalized = normalized.capitalize()
        return normalized
    
    async def _should_enrich_with_searxng(
        self,
        search_results: List[Dict[str, Any]],
        confidence: float,
        query: str
    ) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è –æ–±–æ–≥–∞—â–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ SearXNG.
        
        Context7: –û–±–æ–≥–∞—â–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏:
        - –ù–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (confidence < threshold)
        - –ú–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (< minimum_results_threshold)
        - –ù–∏–∑–∫–∏–µ scores —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (—Å—Ä–µ–¥–Ω–∏–π score < score_threshold)
        
        Args:
            search_results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–∑ –∫–∞–Ω–∞–ª–æ–≤
            confidence: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ç–≤–µ—Ç–µ (0.0-1.0)
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            
        Returns:
            True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±–æ–≥–∞—â–∞—Ç—å –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ SearXNG
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω–æ –ª–∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ
        if not settings.searxng_enrichment_enabled or not self.searxng_service.enabled:
            logger.debug(
                "Enrichment disabled",
                searxng_enrichment_enabled=settings.searxng_enrichment_enabled,
                searxng_service_enabled=self.searxng_service.enabled
            )
            return False
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–Ω–µ—à–Ω–µ–µ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ –∫–∞–∫ fallback
        if not search_results:
            logger.debug(
                "Enrichment triggered: no channel results",
                confidence=confidence
            )
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        if confidence < settings.searxng_enrichment_confidence_threshold:
            logger.debug(
                "Enrichment triggered: low confidence",
                confidence=confidence,
                threshold=settings.searxng_enrichment_confidence_threshold
            )
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ú–∞–ª–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if len(search_results) < settings.searxng_enrichment_min_results_threshold:
            logger.debug(
                "Enrichment triggered: few results",
                results_count=len(search_results),
                threshold=settings.searxng_enrichment_min_results_threshold
            )
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –ù–∏–∑–∫–∏–µ scores —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if search_results:
            avg_score = sum(
                r.get('hybrid_score', r.get('score', 0.0)) 
                for r in search_results
            ) / len(search_results)
            
            if avg_score < settings.searxng_enrichment_score_threshold:
                logger.debug(
                    "Enrichment triggered: low average score",
                    avg_score=avg_score,
                    threshold=settings.searxng_enrichment_score_threshold
                )
                return True
        
        return False
    
    async def _enrich_with_searxng(
        self,
        query: str,
        user_id: str,
        existing_sources: List[RAGSource],
        lang: str = "ru"
    ) -> tuple[List[RAGSource], float]:
        """
        –û–±–æ–≥–∞—â–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤–Ω–µ—à–Ω–∏–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ —á–µ—Ä–µ–∑ SearXNG.
        
        Context7: Graceful degradation - –æ—à–∏–±–∫–∏ SearXNG –Ω–µ –¥–æ–ª–∂–Ω—ã –≤–ª–∏—è—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç.
        –û–±–æ–≥–∞—â–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π flow.
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è rate limiting
            existing_sources: –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –∫–∞–Ω–∞–ª–æ–≤
            lang: –Ø–∑—ã–∫ –ø–æ–∏—Å–∫–∞
            
        Returns:
            Tuple (–æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π confidence boost)
        """
        enriched_sources = existing_sources.copy()
        confidence_boost = 0.0
        
        try:
            # Context7: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ SearXNG (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π flow)
            searxng_timeout = getattr(settings, "searxng_timeout_seconds", 8)
            searxng_response = await asyncio.wait_for(
                self.searxng_service.search(
                    query=query,
                    user_id=user_id,
                    lang=lang,
                    score_threshold=0.5  # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                ),
                timeout=searxng_timeout
            )
            
            if searxng_response.results:
                # –î–æ–±–∞–≤–ª—è–µ–º –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å –ø–æ–º–µ—Ç–∫–æ–π "external"
                external_count = min(
                    len(searxng_response.results),
                    settings.searxng_enrichment_max_external_results
                )
                
                for idx, result in enumerate(searxng_response.results[:external_count]):
                    external_source = RAGSource(
                        post_id=f"external_{idx}",
                        channel_id="external",
                        channel_title=result.title,
                        channel_username=None,
                        content=result.snippet,
                        score=0.5,  # –í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–º–µ—é—Ç —Å—Ä–µ–¥–Ω–∏–π score
                        permalink=str(result.url)
                    )
                    enriched_sources.append(external_source)
                
                # Context7: Confidence boost –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                # –ß–µ–º –±–æ–ª—å—à–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Ç–µ–º –≤—ã—à–µ boost
                confidence_boost = min(
                    0.15,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π boost 0.15
                    len(searxng_response.results[:external_count]) * 0.05
                )
                
                logger.info(
                    "Enrichment completed",
                    query=query[:50],
                    external_results=external_count,
                    confidence_boost=confidence_boost
                )
            else:
                logger.debug("Enrichment: no external results found", query=query[:50])
        
        except asyncio.TimeoutError:
            logger.warning(
                "Enrichment failed due to timeout",
                query=query[:50],
                timeout_seconds=getattr(settings, "searxng_timeout_seconds", 8)
            )
        except Exception as e:
            # Context7: Graceful degradation - –æ—à–∏–±–∫–∏ –Ω–µ –≤–ª–∏—è—é—Ç –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç
            logger.warning(
                "Enrichment failed, continuing without external sources",
                error=str(e),
                query=query[:50]
            )
        
        return enriched_sources, confidence_boost
    
    async def _get_conversation_history(
        self,
        user_id: UUID,
        db: Session,
        max_turns: int = 5
    ) -> List[Dict[str, str]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        
        Context7: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ RAGQueryHistory
        –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –≤ multi-turn –¥–∏–∞–ª–æ–≥–∞—Ö.
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            db: SQLAlchemy —Å–µ—Å—Å–∏—è
            max_turns: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]
        """
        try:
            from models.database import RAGQueryHistory
            from sqlalchemy import desc
            from datetime import timedelta
            
            # Context7: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–∫–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 24 —á–∞—Å–∞)
            window_hours = getattr(settings, 'rag_conversation_window_hours', 24)
            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=window_hours)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –æ—Ç–≤–µ—Ç–∞–º–∏ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞
            history_records = db.query(RAGQueryHistory).filter(
                RAGQueryHistory.user_id == user_id,
                RAGQueryHistory.response_text.isnot(None),
                RAGQueryHistory.created_at >= cutoff_time
            ).order_by(
                desc(RAGQueryHistory.created_at)
            ).limit(max_turns).all()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ (–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º)
            conversation = []
            for record in reversed(history_records):
                if record.query_text:
                    conversation.append({
                        "role": "user",
                        "content": record.query_text
                    })
                if record.response_text:
                    conversation.append({
                        "role": "assistant",
                        "content": record.response_text[:1000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
                    })
            
            logger.debug(
                "Conversation history retrieved",
                user_id=str(user_id),
                turns=len(conversation) // 2,
                total_messages=len(conversation)
            )
            
            return conversation
            
        except Exception as e:
            logger.warning(
                "Failed to get conversation history",
                error=str(e),
                user_id=str(user_id)
            )
            return []
    
    async def query(
        self,
        query: str,
        user_id: UUID,
        tenant_id: str,
        db: Session,
        limit: int = 5,
        channel_ids: Optional[List[str]] = None,
        audio_file_id: Optional[str] = None,
        transcription_text: Optional[str] = None,
        include_conversation_history: bool = True,
        max_conversation_turns: int = 5,
        intent_override: Optional[str] = None
    ) -> RAGResult:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ RAG –∑–∞–ø—Ä–æ—Å–∞ —Å intent-based routing –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
        
        Context7: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç multi-turn conversations —á–µ—Ä–µ–∑ conversation history.
        
        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            tenant_id: ID –∞—Ä–µ–Ω–¥–∞—Ç–æ—Ä–∞
            db: SQLAlchemy —Å–µ—Å—Å–∏—è
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            channel_ids: –°–ø–∏—Å–æ–∫ ID –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            audio_file_id: ID –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            transcription_text: –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            include_conversation_history: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
            max_conversation_turns: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Returns:
            RAGResult —Å –æ—Ç–≤–µ—Ç–æ–º –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
        """
        start_time = time.time()
        
        try:
            # Context7: –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ config –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã —è–≤–Ω–æ
            use_history = include_conversation_history if include_conversation_history is not None else getattr(settings, 'rag_conversation_history_enabled', True)
            max_turns = max_conversation_turns if max_conversation_turns is not None else getattr(settings, 'rag_max_conversation_turns', 5)
            
            conversation_history = []
            if use_history:
                conversation_history = await self._get_conversation_history(
                    user_id=user_id,
                    db=db,
                    max_turns=max_turns
                )
            
            # 1. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è
            # Context7: –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω intent_override, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –≤–º–µ—Å—Ç–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if intent_override:
                intent = intent_override
                confidence = 1.0  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
                logger.debug("Using intent override", intent=intent, query=query[:50])
            else:
                intent_result = await self.intent_classifier.classify(query, str(user_id))
                intent = intent_result.intent
                confidence = intent_result.confidence
            
            # Context7: –î–ª—è intent="recommend" –∏—Å–ø–æ–ª—å–∑—É–µ–º RecommendationService
            if intent == "recommend":
                from services.recommendation_service import get_recommendation_service
                recommendation_service = get_recommendation_service()
                
                # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤
                recommendations = await recommendation_service.get_recommendations(
                    user_id=user_id,
                    limit=limit,
                    days=7,
                    db=db
                )
                
                if not recommendations:
                    # Fallback –Ω–∞ collaborative filtering
                    recommendations = await recommendation_service.get_collaborative_recommendations(
                        user_id=user_id,
                        limit=limit,
                        days=7,
                        db=db
                    )
                
                if recommendations:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                    sources = []
                    context_parts = []
                    
                    for rec in recommendations:
                        post_id = rec.get('post_id')
                        if not post_id:
                            continue
                        
                        try:
                            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ post_id –≤ UUID
                            if isinstance(post_id, UUID):
                                post_uuid = post_id
                            elif isinstance(post_id, str):
                                try:
                                    post_uuid = UUID(post_id)
                                except (ValueError, TypeError) as e:
                                    logger.warning(
                                        "Invalid post_id format in recommendation",
                                        post_id=post_id,
                                        error=str(e)
                                    )
                                    continue
                            else:
                                logger.warning(
                                    "Unexpected post_id type in recommendation",
                                    post_id=post_id,
                                    post_id_type=type(post_id).__name__
                                )
                                continue
                            
                            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å—Ç–µ –∏–∑ –ë–î
                            post = db.query(Post).filter(Post.id == post_uuid).first()
                            if not post:
                                logger.debug("Post not found in database", post_id=str(post_uuid))
                                continue
                            
                            channel = db.query(Channel).filter(Channel.id == post.channel_id).first()
                            
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º post_id –∫–∞–∫ —Å—Ç—Ä–æ–∫—É –¥–ª—è RAGSource
                            source = RAGSource(
                                post_id=str(post_uuid),
                                channel_id=str(post.channel_id),
                                channel_title=channel.title if channel else "Unknown",
                                channel_username=channel.username if channel else None,
                                content=rec.get('content', post.content or ''),
                                score=rec.get('recommendation_score', 0.8),
                                permalink=post.telegram_post_url
                            )
                            sources.append(source)
                            
                            context_parts.append(
                                f"–ü–æ—Å—Ç –∏–∑ –∫–∞–Ω–∞–ª–∞ {source.channel_title}:\n{source.content[:200]}"
                            )
                        except Exception as e:
                            logger.warning(
                                "Error processing recommendation",
                                post_id=post_id,
                                error=str(e),
                                exc_info=True
                            )
                            continue
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
                    if not sources:
                        logger.warning("No valid sources found from recommendations", user_id=str(user_id))
                        # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
                        intent = "search"
                    else:
                        context = "\n\n".join(context_parts) if context_parts else ""
                        
                        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM —Å conversation history
                        # Context7: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ LangChain Message –æ–±—ä–µ–∫—Ç—ã
                        history_messages = []
                        if conversation_history:
                            for msg in conversation_history:
                                if msg.get("role") == "user":
                                    history_messages.append(HumanMessage(content=msg.get("content", "")))
                                elif msg.get("role") == "assistant":
                                    history_messages.append(AIMessage(content=msg.get("content", "")))
                        
                        router_input = {
                            "query": query,
                            "context": context,
                            "intent": intent,
                            "conversation_history": history_messages if history_messages else []
                        }
                        
                        answer = await self.intent_router.ainvoke(router_input)
                        
                        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤
                        try:
                            from services.user_interest_service import get_user_interest_service
                            interest_service = get_user_interest_service(redis_client=self.redis_client)
                            
                            # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ç–µ–º–∞–º–∏
                            sources_for_tracking = [
                                {'topics': [rec.get('interest_topic')]}
                                for rec in recommendations
                                if rec.get('interest_topic')
                            ]
                            
                            await interest_service.track_query(
                                user_id=user_id,
                                query_text=query,
                                intent=intent,
                                sources=sources_for_tracking,
                                db=db
                            )
                        except Exception as e:
                            logger.warning("Failed to track user interest", error=str(e))
                        
                        processing_time = int((time.time() - start_time) * 1000)
                        
                        return RAGResult(
                            answer=answer,
                            sources=sources[:limit],
                            confidence=confidence,
                            intent=intent,
                            processing_time_ms=processing_time
                        )
                else:
                    # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫ –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                    logger.debug("No recommendations found, falling back to regular search", user_id=str(user_id))
                    intent = "search"  # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫
            
            logger.info(
                "Intent classified",
                query=query[:50],
                intent=intent,
                confidence=confidence
            )
            
            # 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await self._generate_embedding(query)
            
            if not query_embedding:
                logger.warning("Failed to generate embedding, falling back to FTS only")
            
            # 3. Hybrid search (Qdrant + PostgreSQL FTS + Neo4j GraphRAG)
            if query_embedding:
                search_results = await self._hybrid_search(
                    query, query_embedding, tenant_id, limit * 2, channel_ids, db, user_id=str(user_id)
                )
            else:
                # Fallback –Ω–∞ FTS + GraphRAG (–±–µ–∑ –≤–µ–∫—Ç–æ—Ä–æ–≤)
                fts_results = await self._search_postgres_fts(
                    query, tenant_id, limit * 2, channel_ids, db
                )
                graph_results = await self._search_neo4j_graph(query, str(user_id), tenant_id=tenant_id, limit=limit * 2)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                post_scores = {}
                for result in fts_results:
                    post_id = result['post_id']
                    post_scores[post_id] = {
                        'post_id': post_id,
                        'payload': result,
                        'hybrid_score': result['score'] * 0.7
                    }
                
                for result in graph_results:
                    post_id = result.get('post_id')
                    if post_id:
                        score = result.get('graph_score', 0.8) * 0.3
                        if post_id in post_scores:
                            post_scores[post_id]['hybrid_score'] += score
                        else:
                            post_scores[post_id] = {
                                'post_id': post_id,
                                'payload': result,
                                'hybrid_score': score
                            }
                
                search_results = sorted(
                    post_scores.values(),
                    key=lambda x: x['hybrid_score'],
                    reverse=True
                )[:limit * 2]
            
            if not search_results:
                logger.warning("No search results found", query=query[:50])
                # –ü—Ä–æ–±—É–µ–º –≤–Ω–µ—à–Ω–∏–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ SearXNG
                searxng_response = await self.searxng_service.search(
                    query, str(user_id), lang="ru"
                )
                
                if searxng_response.results:
                    external_sources = [
                        RAGSource(
                            post_id=f"external_{idx}",
                            channel_id="external",
                            channel_title=result.title,
                            channel_username=None,
                            content=result.snippet,
                            score=0.5,
                            permalink=str(result.url)
                        )
                        for idx, result in enumerate(searxng_response.results[:3])
                    ]
                    
                    result = RAGResult(
                        answer=f"–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –≤–Ω–µ—à–Ω–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:\n\n" + 
                               "\n".join([f"‚Ä¢ {s.title}: {s.content[:200]}" for s in searxng_response.results[:3]]),
                        sources=external_sources,
                        confidence=0.4,
                        intent=intent,
                        processing_time_ms=int((time.time() - start_time) * 1000)
                    )
                else:
                    result = RAGResult(
                        answer="–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–∞–Ω–∞–ª–∞—Ö.",
                        sources=[],
                        confidence=0.0,
                        intent=intent,
                        processing_time_ms=int((time.time() - start_time) * 1000)
                    )
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∞–∂–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                try:
                    from models.database import RAGQueryHistory
                    rag_history = RAGQueryHistory(
                        user_id=user_id,
                        query_text=query,
                        query_type=intent,
                        intent=intent,
                        confidence=confidence,
                        response_text=result.answer[:5000] if isinstance(result.answer, str) else str(result.answer)[:5000],
                        sources_count=len(result.sources),
                        processing_time_ms=result.processing_time_ms,
                        audio_file_id=audio_file_id,
                        transcription_text=transcription_text,
                        transcription_provider="salutespeech" if transcription_text else None
                    )
                    db.add(rag_history)
                    db.commit()
                    logger.debug("RAG query saved to history (no results)", user_id=str(user_id), query_id=str(rag_history.id))
                except Exception as e:
                    logger.warning("Failed to save RAG query to history", error=str(e))
                
                return result
            
            # 4. Context7: –û–±–æ–≥–∞—â–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ SearXNG (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            enrichment_applied = False
            if await self._should_enrich_with_searxng(search_results, confidence, query):
                logger.info(
                    "Enriching answer with external sources",
                    query=query[:50],
                    results_count=len(search_results),
                    confidence=confidence
                )
                
                # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –±–∞–∑–æ–≤—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
                context, sources = await self._assemble_context(search_results, db)
                
                # –û–±–æ–≥–∞—â–∞–µ–º –≤–Ω–µ—à–Ω–∏–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
                enriched_sources, confidence_boost = await self._enrich_with_searxng(
                    query=query,
                    user_id=str(user_id),
                    existing_sources=sources,
                    lang="ru"
                )
                
                # Context7: –î–æ–±–∞–≤–ª—è–µ–º –≤–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ context –¥–ª—è LLM
                external_sources_in_context = [
                    source for source in enriched_sources 
                    if source.channel_id == "external"
                ]
                
                if external_sources_in_context:
                    external_context_parts = []
                    for idx, source in enumerate(external_sources_in_context, 1):
                        # Context7: –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è inline –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                        if source.permalink:
                            external_context_parts.append(
                                f"[–í–Ω–µ—à–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ {idx}] [{source.channel_title}]({source.permalink}): {source.content}"
                            )
                        else:
                            external_context_parts.append(
                                f"[–í–Ω–µ—à–Ω–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫ {idx}] {source.channel_title}: {source.content}"
                            )
                    
                    if external_context_parts:
                        context += "\n\n" + "–í–Ω–µ—à–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:\n" + "\n\n".join(external_context_parts)
                    
                    logger.debug(
                        "External sources added to context",
                        external_count=len(external_sources_in_context),
                        context_length=len(context)
                    )
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ confidence
                sources = enriched_sources
                confidence = min(1.0, confidence + confidence_boost)
                enrichment_applied = True
                
                logger.info(
                    "Enrichment applied",
                    query=query[:50],
                    sources_count=len(sources),
                    confidence_boost=confidence_boost,
                    final_confidence=confidence
                )
            else:
                # 4. –°–±–æ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–±–µ–∑ –æ–±–æ–≥–∞—â–µ–Ω–∏—è)
                context, sources = await self._assemble_context(search_results, db)
            
            # 5. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è LangChain
            # Context7: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ dict –≤ LangChain Message –æ–±—ä–µ–∫—Ç—ã
            history_messages = []
            if conversation_history:
                for msg in conversation_history:
                    if msg.get("role") == "user":
                        history_messages.append(HumanMessage(content=msg.get("content", "")))
                    elif msg.get("role") == "assistant":
                        history_messages.append(AIMessage(content=msg.get("content", "")))
            
            # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LangChain intent router —Å conversation history
            router_input = {
                "query": query,
                "context": context,
                "intent": intent,
                "conversation_history": history_messages if history_messages else []
            }
            
            answer = await self.intent_router.ainvoke(router_input)
            
            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤
            try:
                from models.database import RAGQueryHistory
                from datetime import timezone
                
                processing_time_ms = int((time.time() - start_time) * 1000)
                
                rag_history = RAGQueryHistory(
                    user_id=user_id,
                    query_text=query,
                    query_type=intent,
                    intent=intent,
                    confidence=confidence,
                    response_text=answer if isinstance(answer, str) else str(answer)[:5000],  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
                    sources_count=len(sources),
                    processing_time_ms=processing_time_ms,
                    audio_file_id=audio_file_id,
                    transcription_text=transcription_text,
                    transcription_provider="salutespeech" if transcription_text else None
                )
                db.add(rag_history)
                db.commit()
                
                logger.debug(
                    "RAG query saved to history",
                    user_id=str(user_id),
                    query_id=str(rag_history.id),
                    intent=intent
                )
            except Exception as e:
                logger.warning("Failed to save RAG query to history", error=str(e))
                # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
            
            # 7. Context7: –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            try:
                from services.user_interest_service import get_user_interest_service
                interest_service = get_user_interest_service(redis_client=self.redis_client)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—ã –∏–∑ –ø–æ—Å—Ç–æ–≤ —á–µ—Ä–µ–∑ PostEnrichment
                sources_for_tracking = []
                for source in sources:
                    post_topics = []
                    try:
                        post_uuid = UUID(source.post_id)
                        # –ü–æ–ª—É—á–∞–µ–º enrichment —Å —Ç–µ–≥–∞–º–∏/—Ç–µ–º–∞–º–∏
                        enrichment = db.query(PostEnrichment).filter(
                            PostEnrichment.post_id == post_uuid,
                            PostEnrichment.kind == 'tags'
                        ).first()
                        
                        if enrichment and enrichment.data:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–≥–∏ –∏–∑ data->'tags' –∏–ª–∏ –∏–∑ legacy –ø–æ–ª—è tags
                            tags = enrichment.data.get('tags', [])
                            if not tags and enrichment.tags:
                                tags = enrichment.tags
                            
                            if isinstance(tags, list):
                                post_topics = [str(tag) for tag in tags if tag]
                    except Exception as e:
                        logger.debug("Error extracting topics from post", post_id=source.post_id, error=str(e))
                    
                    # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ–º –∏–∑ enrichment, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                    if not post_topics:
                        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ: –ø–µ—Ä–≤—ã–µ 2-3 —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                        words = query.lower().split()[:3]
                        if words:
                            post_topics = [' '.join(words)]
                    
                    if post_topics:
                        sources_for_tracking.append({'topics': post_topics})
                
                await interest_service.track_query(
                    user_id=user_id,
                    query_text=query,
                    intent=intent,
                    sources=sources_for_tracking,
                    db=db
                )
            except Exception as e:
                logger.warning("Failed to track user interest", error=str(e))
            
            processing_time = int((time.time() - start_time) * 1000)
            
            logger.info(
                "RAG query completed",
                query=query[:50],
                intent=intent,
                sources_count=len(sources),
                confidence=confidence,
                enrichment_applied=enrichment_applied,
                processing_time_ms=processing_time
            )
            
            return RAGResult(
                answer=answer,
                sources=sources[:limit],
                confidence=confidence,
                intent=intent,
                processing_time_ms=processing_time
            )
        
        except Exception as e:
            logger.error("Error in RAG query", error=str(e), query=query[:50])
            error_result = RAGResult(
                answer="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
                sources=[],
                confidence=0.0,
                intent="search",
                processing_time_ms=int((time.time() - start_time) * 1000)
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            try:
                from models.database import RAGQueryHistory
                rag_history = RAGQueryHistory(
                    user_id=user_id,
                    query_text=query,
                    query_type="search",
                    intent="search",
                    confidence=0.0,
                    response_text=error_result.answer[:5000],
                    sources_count=0,
                    processing_time_ms=error_result.processing_time_ms,
                    audio_file_id=audio_file_id,
                    transcription_text=transcription_text,
                    transcription_provider="salutespeech" if transcription_text else None
                )
                db.add(rag_history)
                db.commit()
                logger.debug("RAG query saved to history (error case)", user_id=str(user_id), query_id=str(rag_history.id))
            except Exception as save_error:
                logger.warning("Failed to save RAG query to history (error case)", error=str(save_error))
            
            return error_result


# ============================================================================
# SINGLETON INSTANCE
# ============================================================================

_rag_service: Optional[RAGService] = None


def get_rag_service(
    qdrant_url: Optional[str] = None,
    redis_client: Optional[Any] = None
) -> RAGService:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ singleton —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ RAGService."""
    global _rag_service
    if _rag_service is None:
        qdrant_url = qdrant_url or getattr(settings, 'qdrant_url', 'http://qdrant:6333')
        _rag_service = RAGService(
            qdrant_url=qdrant_url,
            redis_client=redis_client
        )
    return _rag_service

