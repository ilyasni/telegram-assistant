# Исправление критических ошибок в парсинге и сохранении новостей

**Дата**: 2025-01-22  
**Context7**: Глубокая проверка и исправление всех ошибок в цепочке парсинга

---

## Context

Проведена полная проверка цепочки парсинга и сохранения постов с использованием Context7 best practices. Обнаружены и исправлены критические ошибки.

---

## Критические исправления

### Исправление 1: Счетчик `processed` увеличивался до сохранения в БД

**Проблема**: 
- `processed` увеличивался сразу после подготовки данных поста, до фактического сохранения в БД
- Это приводило к неправильному отслеживанию успешных сохранений
- `last_parsed_at` обновлялся даже если сохранение в БД провалилось

**Исправление**:
- `processed` теперь устанавливается ТОЛЬКО после успешного `save_batch_atomic`
- Используется `inserted_count` из результата сохранения (реальное количество сохраненных/обновленных постов)
- При ошибке сохранения `processed = 0`

**Файл**: `telethon-ingest/services/channel_parser.py`

**Код до исправления**:
```python
# processed увеличивался до сохранения
processed += 1  # ❌ Неправильно - еще не сохранено в БД
```

**Код после исправления**:
```python
# Context7: НЕ увеличиваем processed здесь - это будет сделано только после успешного сохранения в БД
# processed будет обновлен после успешного save_batch_atomic

# ... после save_batch_atomic ...

if success:
    # Context7: КРИТИЧНО - увеличиваем processed ТОЛЬКО после успешного сохранения в БД
    # inserted_count - это количество реально сохраненных/обновленных постов
    processed = inserted_count
else:
    # Context7: При ошибке сохранения processed остается 0
    processed = 0
```

---

### Исправление 2: Обновление `last_parsed_at` только после успешного сохранения

**Проблема**: 
- `last_parsed_at` обновлялся даже при ошибке сохранения всех батчей
- Это приводило к пропуску постов при следующем парсинге

**Исправление**:
- Добавлен флаг `has_successful_save` для отслеживания успешного сохранения хотя бы одного батча
- `last_parsed_at` обновляется только если:
  1. Был хотя бы один успешный save, ИЛИ
  2. Не было постов для сохранения (messages_processed = 0)

**Файл**: `telethon-ingest/services/channel_parser.py` (строки 379-427)

---

## Проверенные компоненты

### 1. ✅ Обработка ошибок Telethon

**Проверено**:
- ✅ `FloodWaitError` обрабатывается через `fetch_messages_with_retry`
- ✅ `TimeoutError` и сетевые ошибки обрабатываются с retry
- ✅ Неповторяемые ошибки (UnauthorizedError, AuthKeyError) не ретраятся

**Файл**: `telethon-ingest/services/telethon_retry.py`

---

### 2. ✅ SQL запросы

**Проверено**:
- ✅ `NULLIF(:forward_from_peer_id, '')::jsonb` - правильный синтаксис для PostgreSQL
- ✅ Все JSONB поля правильно сериализуются через `json.dumps()`
- ✅ `ON CONFLICT DO UPDATE SET` обновляет все необходимые поля

**Файл**: `telethon-ingest/services/atomic_db_saver.py`

---

### 3. ✅ Обработка транзакций

**Проверено**:
- ✅ Транзакции откатываются при ошибках (`async with db_session.begin()`)
- ✅ Проверка состояния транзакции перед началом новых операций
- ✅ Отдельные транзакции для сохранения альбомов (после основного сохранения)

**Файлы**: 
- `telethon-ingest/services/channel_parser.py`
- `telethon-ingest/services/atomic_db_saver.py`

---

## Проверка цепочки после исправлений

### Сценарий 1: Успешное сохранение постов

1. ✅ Парсинг сообщений
2. ✅ Подготовка данных постов (`posts_data`)
3. ✅ Сохранение через `save_batch_atomic`
4. ✅ `success = True`, `inserted_count > 0`
5. ✅ `processed = inserted_count` (реальное количество сохраненных постов)
6. ✅ `has_successful_save = True`
7. ✅ `last_parsed_at` обновляется

### Сценарий 2: Ошибка при сохранении

1. ✅ Парсинг сообщений
2. ✅ Подготовка данных постов (`posts_data`)
3. ❌ Ошибка при `save_batch_atomic`
4. ✅ `success = False`, `inserted_count = 0`
5. ✅ `processed = 0`
6. ✅ `has_successful_save = False`
7. ✅ `last_parsed_at` НЕ обновляется
8. ✅ При следующем парсинге те же посты будут обработаны снова

### Сценарий 3: Частичное сохранение (несколько батчей)

1. ✅ Батч 1: успешно сохранен → `processed = 10`, `has_successful_save = True`
2. ❌ Батч 2: ошибка сохранения → `processed = 0`
3. ✅ `has_successful_save = True` (был хотя бы один успешный save)
4. ✅ `last_parsed_at` обновляется
5. ✅ При следующем парсинге Батч 2 будет обработан снова

---

## Метрики для мониторинга

### Prometheus метрики

```promql
# Успешные сохранения
rate(db_posts_insert_success_total[5m])

# Ошибки сохранения
rate(db_posts_insert_failures_total[5m])

# Латентность сохранения
histogram_quantile(0.95, db_batch_commit_latency_seconds_bucket)
```

### Логи для проверки

```bash
# Проверка успешных сохранений
docker logs telegram-assistant-telethon-ingest-1 --since 10m | grep "Atomic batch save successful"

# Проверка ошибок сохранения
docker logs telegram-assistant-telethon-ingest-1 --since 10m | grep "Atomic batch save failed"

# Проверка обновления last_parsed_at
docker logs telegram-assistant-telethon-ingest-1 --since 10m | grep -E "(Updated last_parsed_at|Skipping last_parsed_at)"
```

---

## Выводы

✅ **Все критические ошибки исправлены**:
- Счетчик `processed` теперь отражает реальное количество сохраненных постов
- `last_parsed_at` обновляется только после успешного сохранения
- Ошибки при сохранении не приводят к пропуску постов
- Обработка ошибок Telethon корректна

✅ **Цепочка парсинга работает надежно**:
- Посты сохраняются только после успешного commit в БД
- При ошибках посты не теряются - будут обработаны при следующем парсинге
- Метрики и логирование позволяют отслеживать все этапы парсинга

---

## Следующие шаги

1. ✅ Мониторинг метрик в Prometheus/Grafana
2. ✅ Проверка логов на наличие ошибок
3. ✅ Тестирование на реальных каналах
4. ✅ Проверка что новые посты появляются в БД

