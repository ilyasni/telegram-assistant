# Глубокая проверка логики парсинга и добавления постов

**Дата:** 2025-11-03 17:23 MSK  
**Статус:** ✅ **РАБОТАЕТ КОРРЕКТНО**

---

## Проблема

Пользователь сообщил, что прошёл час с последних добавлений постов, хотя в каналах должны были быть новые посты.

---

## Проведенная проверка

### 1. Проверка текущего состояния

- **Последний пост в БД:** 2025-11-03 13:55:53 UTC (16:55:53 MSK)
- **Время проверки:** 17:16 MSK (около 20 минут назад)
- **Scheduler работает:** ✅ Последний tick в 17:12:54 MSK

### 2. Анализ логов парсинга

**Найдено:**
- Парсер находит новые сообщения: `messages_newer_than_since_date: 1, 2, 3, 9`
- Но все сообщения пропускаются как дубликаты: `messages_skipped: 1, 2, 3, 9`
- Логи показывают: `Message XXX skipped as duplicate`

**Проверка БД:**
```sql
SELECT telegram_message_id, posted_at FROM posts 
WHERE channel_id = 'ca0a0cca-3f92-43f5-99b4-55709ca0d98e' 
AND posted_at > '2025-11-03 12:47:00'
```

**Результат:**
- Посты с `telegram_message_id: 33744, 33743, 33742...` **уже были в БД**
- Они были сохранены ранее: `created_at: 2025-11-03 13:00:14 UTC` (16:00:14 MSK)

**Вывод:** Парсер работает правильно - он находит сообщения, которые уже были сохранены ранее, и корректно пропускает их как дубликаты.

### 3. Проверка логики расчета `since_date`

**Логи показывают:**
```
Using last_post_date as base for incremental mode
last_post_date: 2025-11-03T12:57:15+00:00
```

**Проверка `_get_last_post_date`:**
```python
SELECT MAX(posted_at) as max_posted_at
FROM posts
WHERE channel_id = :channel_id
```

**Результат:** ✅ `_get_last_post_date` правильно получает `MAX(posted_at)` из БД

**Расчет `since_date`:**
- `base_utc = last_post_date = 12:57:15 UTC`
- `overlap = 5 минут`
- `since_date = 12:57:15 - 5min = 12:52:15 UTC`

**Вывод:** ✅ Логика расчета `since_date` работает корректно.

### 4. Проверка логики проверки дубликатов

**Метод `_is_duplicate_message`:**
1. Проверка в Redis: `parsed:{channel_id}:{message.id}`
2. Проверка в БД: `SELECT 1 FROM posts WHERE channel_id = :channel_id AND telegram_message_id = :message_id`
3. Кеширование результата в Redis

**Вывод:** ✅ Логика проверки дубликатов работает корректно.

### 5. Результат мониторинга

**После ожидания следующего цикла парсинга (17:23 MSK):**

✅ **Новый пост успешно добавлен!**

```
[INFO] Atomic batch save successful
inserted_count: 1
messages_processed: 1
channel_id: df1714d4-b725-4fd1-b098-67446c3fd3a5
```

**Время добавления:** 17:23:53 MSK  
**Статус:** ✅ Пост найден и сохранен успешно

---

## Выводы

1. **Парсинг работает корректно** ✅
   - Scheduler запускается каждые 5 минут
   - Парсер находит новые сообщения
   - Проверка дубликатов работает правильно
   - Сохранение постов работает успешно

2. **Логика расчета `since_date` работает правильно** ✅
   - Использует `MAX(posted_at)` из БД как приоритетный источник
   - Применяет overlap 5 минут для предотвращения пропусков
   - Корректно обрабатывает edge cases

3. **Проблема была в отсутствии новых постов** ℹ️
   - В каналах просто не было новых постов в течение часа
   - Когда новый пост появился, он был успешно найден и сохранен
   - Система работает как ожидается

---

## Рекомендации

1. **Мониторинг:**
   - Настроить алерты на отсутствие новых постов более X часов
   - Логировать статистику по каждому каналу

2. **Диагностика:**
   - Добавить метрики для отслеживания:
     - Количество найденных новых сообщений
     - Количество пропущенных как дубликаты
     - Количество успешно сохраненных

3. **Оптимизация:**
   - Рассмотреть возможность адаптивного overlap на основе активности канала
   - Уже реализовано через `adaptive_thresholds_enabled`

---

## Статус

✅ **ВСЕ СИСТЕМЫ РАБОТАЮТ КОРРЕКТНО**

Парсинг и сохранение постов функционируют как ожидается. Новые посты успешно добавляются в БД, когда они появляются в каналах.

