#!/usr/bin/env python3
"""
–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö worker tasks —Å supervisor pattern –¥–ª—è –∞–≤—Ç–æ–ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞.
"""

import asyncio
import sys
import os
import logging

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
)
logger = logging.getLogger(__name__)

from supervisor import TaskSupervisor, TaskConfig
from tasks.tagging_task import TaggingTask
from tasks.enrichment_task import EnrichmentWorker
from tasks.indexing_task import IndexingTask
from tasks.tag_persistence_task import TagPersistenceTask
from tasks.crawl_trigger_task import CrawlTriggerTask

async def create_tagging_task():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ tagging task."""
    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")
    # –ü–æ best practices TaggingTask –Ω–µ —Ç—Ä–µ–±—É–µ—Ç DATABASE_URL –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ redis_url
    task = TaggingTask(redis_url)
    await task.start()
    # Context7: –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∏–∑ start() - –∑–∞–¥–∞—á–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –≤ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–º —Ü–∏–∫–ª–µ

async def create_enrichment_task():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ enrichment task."""
    # Enrichment task —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    from tasks.enrichment_task import main as enrichment_main
    await enrichment_main()

async def create_indexing_task():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ indexing task."""
    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")
    qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
    neo4j_url = os.getenv("NEO4J_URL", "bolt://localhost:7687")
    
    task = IndexingTask(redis_url, qdrant_url, neo4j_url)
    await task.start()

async def create_tag_persistence_task():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ tag persistence task."""
    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")
    database_url = os.getenv("DATABASE_URL", "postgresql://postgres:postgres@localhost:5432/postgres")
    
    task = TagPersistenceTask(redis_url, database_url)
    await task.start()

async def create_crawl_trigger_task():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ crawl trigger task."""
    redis_url = os.getenv("REDIS_URL", "redis://redis:6379")
    
    # –¢—Ä–∏–≥–≥–µ—Ä–Ω—ã–µ —Ç–µ–≥–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    trigger_tags = [
        'longread', 'research', 'paper', 'release', 'law',
        'deepdive', 'analysis', 'report', 'study', 'whitepaper'
    ]
    
    task = CrawlTriggerTask(
        redis_url=redis_url,
        trigger_tags=trigger_tags
    )
    await task.start()

async def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö tasks —Å supervisor."""
    print("üöÄ Starting worker with supervisor...")
    
    # [C7-ID: METRICS-REGISTRATION] –ò–º–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
    # –≠—Ç–∏ –∏–º–ø–æ—Ä—Ç—ã –Ω—É–∂–Ω—ã –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –º–µ—Ç—Ä–∏–∫–∏ –±—ã–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ /metrics endpoint
    import metrics
    from ai_providers.gigachain_adapter import tagging_requests_total, tagging_latency_seconds
    from ai_providers.embedding_service import embedding_requests_total, embedding_latency_seconds
    from tasks.tagging_task import tagging_processed_total
    from tasks.indexing_task import indexing_processed_total
    
    # –ó–∞–ø—É—Å–∫ HTTP —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫
    from prometheus_client import start_http_server
    metrics_port = int(os.getenv("METRICS_PORT", "8001"))
    print(f"Starting metrics server on port {metrics_port}", flush=True)
    try:
        start_http_server(metrics_port)
        print(f"Metrics server started on port {metrics_port}", flush=True)
        logger.info(f"Metrics server started on port {metrics_port}")
    except OSError as e:
        if e.errno == 98:  # Address already in use
            print(f"Metrics server already running on port {metrics_port}", flush=True)
            logger.warning(f"Metrics server already running on port {metrics_port}")
        else:
            print(f"Error starting metrics server: {e}", flush=True)
            raise
    
    supervisor = TaskSupervisor()
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è tasks
    supervisor.register_task(TaskConfig(
        name="tagging",
        task_func=create_tagging_task,
        max_retries=5,
        initial_backoff=1.0,
        max_backoff=60.0,
        backoff_multiplier=2.0
    ))
    
    supervisor.register_task(TaskConfig(
        name="enrichment",
        task_func=create_enrichment_task,
        max_retries=5,
        initial_backoff=1.0,
        max_backoff=60.0,
        backoff_multiplier=2.0
    ))
    
    supervisor.register_task(TaskConfig(
        name="indexing",
        task_func=create_indexing_task,
        max_retries=5,
        initial_backoff=1.0,
        max_backoff=60.0,
        backoff_multiplier=2.0
    ))
    
    supervisor.register_task(TaskConfig(
        name="tag_persistence",
        task_func=create_tag_persistence_task,
        max_retries=5,
        initial_backoff=1.0,
        max_backoff=60.0,
        backoff_multiplier=2.0
    ))
    
    supervisor.register_task(TaskConfig(
        name="crawl_trigger",
        task_func=create_crawl_trigger_task,
        max_retries=5,
        initial_backoff=1.0,
        max_backoff=60.0,
        backoff_multiplier=2.0
    ))
    
    try:
        await supervisor.start_all()
    except KeyboardInterrupt:
        print("üõë Stopping supervisor...")
        await supervisor.stop_all()
    except Exception as e:
        print(f"‚ùå Supervisor error: {e}")
        await supervisor.stop_all()
        raise

if __name__ == "__main__":
    asyncio.run(main())
