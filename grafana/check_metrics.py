#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç—Ä–∏–∫ –≤ –¥–∞—à–±–æ—Ä–¥–∞—Ö –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –≤ Prometheus
"""

import json
import re
import subprocess
from pathlib import Path
from collections import defaultdict

DASHBOARDS_DIR = Path("/opt/telegram-assistant/grafana/dashboards")

# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏–∑ Prometheus
def get_available_metrics():
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏–∑ Prometheus"""
    try:
        result = subprocess.run(
            ['docker', 'exec', 'telegram-assistant-grafana-1', 'curl', '-s',
             'http://prometheus:9090/api/v1/label/__name__/values'],
            capture_output=True,
            text=True,
            timeout=10
        )
        if result.returncode == 0:
            data = json.loads(result.stdout)
            return set(data.get('data', []))
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {e}")
    return set()

def extract_metrics_from_expr(expr):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–º–µ–Ω–∞ –º–µ—Ç—Ä–∏–∫ –∏–∑ PromQL –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
    metrics = set()
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–µ—Ç—Ä–∏–∫ (–∏–º–µ–Ω–∞ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å –±—É–∫–≤—ã –∏–ª–∏ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è)
    pattern = r'\b([a-zA-Z_][a-zA-Z0-9_]*)\s*(?=\{|\[|$|\s)'
    # –ò—Å–∫–ª—é—á–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã
    excluded = {
        'sum', 'rate', 'increase', 'histogram_quantile', 'by', 'le', 'and', 'or',
        'up', 'count', 'avg', 'max', 'min', 'stddev', 'stdvar', 'topk', 'bottomk',
        'quantile', 'group', 'without', 'on', 'ignoring', 'offset', 'start', 'end'
    }
    
    for match in re.finditer(pattern, expr):
        metric = match.group(1)
        if metric not in excluded and not metric.isdigit():
            metrics.add(metric)
    
    return metrics

def main():
    available_metrics = get_available_metrics()
    print(f"üìä –í—Å–µ–≥–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –≤ Prometheus: {len(available_metrics)}\n")
    
    issues = defaultdict(list)
    
    for dashboard_file in DASHBOARDS_DIR.glob("*.json"):
        if ".bak" in dashboard_file.name:
            continue
        
        try:
            with open(dashboard_file, 'r', encoding='utf-8') as f:
                dashboard = json.load(f)
            
            dashboard_metrics = set()
            for panel in dashboard.get('panels', []):
                for target in panel.get('targets', []):
                    expr = target.get('expr', '')
                    if expr:
                        metrics = extract_metrics_from_expr(expr)
                        dashboard_metrics.update(metrics)
            
            missing = dashboard_metrics - available_metrics
            if missing:
                issues[dashboard_file.name] = sorted(missing)
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {dashboard_file.name}: {e}")
    
    if issues:
        print("‚ö†Ô∏è  –î–∞—à–±–æ—Ä–¥—ã —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏:\n")
        for dashboard, missing in sorted(issues.items()):
            print(f"üìã {dashboard}:")
            for metric in missing[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"   - {metric}")
            if len(missing) > 10:
                print(f"   ... –∏ –µ—â—ë {len(missing) - 10} –º–µ—Ç—Ä–∏–∫")
            print()
    else:
        print("‚úÖ –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –¥–∞—à–±–æ—Ä–¥–∞—Ö —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ Prometheus!")
    
    return len(issues)

if __name__ == '__main__':
    exit(main())

